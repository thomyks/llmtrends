id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,extracted_entities,assigned_concept,matched_keyword,similarity_score
2502.12918,Harish Doraiswamy,"Sriram Dharwada, Himanshu Devrani, Jayant Haritsa, Harish Doraiswamy",Query Rewriting via LLMs,,,,,cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  When complex SQL queries suffer slow executions despite query optimization,
DBAs typically invoke automated query rewriting tools to recommend ``lean''
equivalents that are conducive to faster execution. The rewritings are usually
achieved via transformation rules, but these rules are limited in scope and
difficult to update in a production system. Recently, LLM-based techniques have
also been suggested, but they are prone to semantic and syntactic errors.
  We investigate here how the remarkable cognitive capabilities of LLMs can be
leveraged for performant query rewriting while incorporating safeguards and
optimizations to ensure correctness and efficiency. Our study shows that these
goals can be progressively achieved through incorporation of (a) an ensemble
suite of basic prompts, (b) database-sensitive prompts via redundancy removal
and selectivity-based rewriting rules, and (c) LLM token probability-guided
rewrite paths. Further, a suite of logic-based and statistical tools can be
used to check for semantic violations in the rewrites prior to DBA
consideration.
  We have implemented the above LLM-infused techniques in the LITHE system, and
evaluated complex analytic queries from standard benchmarks on contemporary
database platforms. The results show significant performance improvements for
slow queries, with regard to both abstract costing and actual execution, over
both SOTA techniques and the native query optimizer. For instance, with TPC-DS
on PostgreSQL, the geometric mean of the runtime speedups for slow queries was
as high as 18.4 over the native optimizer, whereas SOTA delivered 6 in
comparison.
  Overall, LITHE is a promising step toward viable LLM-based advisory tools for
ameliorating enterprise query performance.
","[{'version': 'v1', 'created': 'Tue, 18 Feb 2025 14:59:37 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Mar 2025 07:55:40 GMT'}]",2025-03-19,"[['Dharwada', 'Sriram', ''], ['Devrani', 'Himanshu', ''], ['Haritsa', 'Jayant', ''], ['Doraiswamy', 'Harish', '']]","[{'text': 'LLM-based techniques', 'label': 'LLM-based'}, {'text': 'LLMs', 'label': 'LLM-based'}, {'text': 'basic prompts', 'label': 'Prompting'}, {'text': 'database-sensitive prompts', 'label': 'Prompting'}]",LLM-based,LLMs,0.817711353302002
2503.15129,Man Fai Wong,"Man Fai Wong, Chee Wei Tan","Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code
  Generation by Large Language Models",,,10.1109/TBDATA.2024.3524104,,cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper studies how AI-assisted programming and large language models
(LLM) improve software developers' ability via AI tools (LLM agents) like
Github Copilot and Amazon CodeWhisperer, while integrating human feedback to
enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance
text-to-code generation. Additionally, we demonstrate that our Bayesian
optimization framework supports AI alignment in code generation by distributing
the feedback collection burden, highlighting the value of collecting human
feedback of good quality. Our empirical evaluations demonstrate the efficacy of
this approach, showcasing how LLM agents can be effectively trained for
improved text-to-code generation. Our Bayesian optimization framework can be
designed for general domain-specific languages, promoting the alignment of
large language model capabilities with human feedback in AI-assisted
programming for code generation.
","[{'version': 'v1', 'created': 'Wed, 19 Mar 2025 11:44:47 GMT'}]",2025-03-20,"[['Wong', 'Man Fai', ''], ['Tan', 'Chee Wei', '']]","[{'text': 'Github Copilot', 'label': 'Open-source LLMs'}, {'text': 'LLM agents', 'label': 'LLM-based'}]",LLM-based,LLM agents,0.7279455661773682
