id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,extracted_entities,assigned_concept,matched_keyword,similarity_score
2311.17643,Alexander Becker,"Alexander Becker, Rodrigo Caye Daudt, Dominik Narnhofer, Torben
  Peters, Nando Metzger, Jan Dirk Wegner, Konrad Schindler","Thera: Aliasing-Free Arbitrary-Scale Super-Resolution with Neural Heat
  Fields",,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Recent approaches to arbitrary-scale single image super-resolution (ASR) use
neural fields to represent continuous signals that can be sampled at arbitrary
resolutions. However, point-wise queries of neural fields do not naturally
match the point spread function (PSF) of pixels, which may cause aliasing in
the super-resolved image. Existing methods attempt to mitigate this by
approximating an integral version of the field at each scaling factor,
compromising both fidelity and generalization. In this work, we introduce
neural heat fields, a novel neural field formulation that inherently models a
physically exact PSF. Our formulation enables analytically correct
anti-aliasing at any desired output resolution, and -- unlike supersampling --
at no additional cost. Building on this foundation, we propose Thera, an
end-to-end ASR method that substantially outperforms existing approaches, while
being more parameter-efficient and offering strong theoretical guarantees. The
project page is at https://therasr.github.io.
","[{'version': 'v1', 'created': 'Wed, 29 Nov 2023 14:01:28 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Mar 2024 19:17:34 GMT'}, {'version': 'v3', 'created': 'Sun, 9 Mar 2025 12:22:00 GMT'}]",2025-03-11,"[['Becker', 'Alexander', ''], ['Daudt', 'Rodrigo Caye', ''], ['Narnhofer', 'Dominik', ''], ['Peters', 'Torben', ''], ['Metzger', 'Nando', ''], ['Wegner', 'Jan Dirk', ''], ['Schindler', 'Konrad', '']]","[{'text': 'neural fields', 'label': 'Neural Language Model'}, {'text': 'neural heat fields', 'label': 'Neural Language Model'}, {'text': 'Thera', 'label': 'Foundation Model'}]",Neural Language Model,neural fields,0.5002090334892273
2412.19054,Ngoc Hai Trinh,Pham Ky Anh and Trinh Ngoc Hai and Nguyen Van Manh,"Regularized neural network for general variational inequalities
  involving monotone couples of operators in Hilbert spaces",,,,,math.OC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, based on the Tikhonov regularization technique, we study a
monotone general variational inequality (GVI) by considering an associated
strongly monotone GVI, depending on a regularization parameter $\alpha,$ such
that the latter admits a unique solution $x_\alpha$ which tends to some
solution of the initial GVI, as $\alpha \to 0.$ However, instead of solving the
regularized GVI for each $\alpha$, which may be very expensive, we consider a
neural network (also known as a dynamical system) associated with the
regularized GVI and establish the existence and the uniqueness of the strong
global solution to the corresponding Cauchy problem. An explicit discretization
of this neural network leads to strongly convergent iterative regularization
algorithms for monotone general variational inequality. Numerical tests are
performed to show the effectiveness of the proposed methods.
  This work extends our recent results in [Anh, Hai, Optim. Eng. 25 (2024)
2295-2313] to more general setting.
","[{'version': 'v1', 'created': 'Thu, 26 Dec 2024 04:39:37 GMT'}, {'version': 'v2', 'created': 'Sun, 9 Mar 2025 01:47:34 GMT'}]",2025-03-11,"[['Anh', 'Pham Ky', ''], ['Hai', 'Trinh Ngoc', ''], ['Van Manh', 'Nguyen', '']]","[{'text': 'neural network', 'label': 'Neural Language Model'}, {'text': 'neural network', 'label': 'Neural Language Model'}]",Neural Language Model,neural network,0.5788917541503906
