id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,extracted_entities,assigned_concept,matched_keyword,similarity_score
2501.10360,Kartik Narayan,"Kartik Narayan, Vibashan VS, Vishal M. Patel",FaceXBench: Evaluating Multimodal LLMs on Face Understanding,Project Page: https://kartik-3004.github.io/facexbench/,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal Large Language Models (MLLMs) demonstrate impressive
problem-solving abilities across a wide range of tasks and domains. However,
their capacity for face understanding has not been systematically studied. To
address this gap, we introduce FaceXBench, a comprehensive benchmark designed
to evaluate MLLMs on complex face understanding tasks. FaceXBench includes
5,000 multimodal multiple-choice questions derived from 25 public datasets and
a newly created dataset, FaceXAPI. These questions cover 14 tasks across 6
broad categories, assessing MLLMs' face understanding abilities in bias and
fairness, face authentication, recognition, analysis, localization and tool
retrieval. Using FaceXBench, we conduct an extensive evaluation of 26
open-source MLLMs alongside 2 proprietary models, revealing the unique
challenges in complex face understanding tasks. We analyze the models across
three evaluation settings: zero-shot, in-context task description, and
chain-of-thought prompting. Our detailed analysis reveals that current MLLMs,
including advanced models like GPT-4o, and GeminiPro 1.5, show significant room
for improvement. We believe FaceXBench will be a crucial resource for
developing MLLMs equipped to perform sophisticated face understanding. Code:
https://github.com/Kartik-3004/facexbench
","[{'version': 'v1', 'created': 'Fri, 17 Jan 2025 18:59:55 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Mar 2025 18:19:52 GMT'}]",2025-03-12,"[['Narayan', 'Kartik', ''], ['VS', 'Vibashan', ''], ['Patel', 'Vishal M.', '']]","[{'text': 'Multimodal Large Language Models', 'label': 'Large Language Model'}, {'text': 'MLLMs', 'label': 'Large Language Model'}, {'text': 'MLLMs', 'label': 'Large Language Model'}, {'text': 'MLLMs', 'label': 'Large Language Model'}, {'text': 'bias and\nfairness', 'label': 'Model Bias and Fairness'}, {'text': 'MLLMs', 'label': 'Large Language Model'}, {'text': 'zero-shot', 'label': 'Zero-shot Learning'}, {'text': 'chain-of-thought prompting', 'label': 'Prompting'}, {'text': 'MLLMs', 'label': 'Large Language Model'}, {'text': 'GPT-4o', 'label': 'GPT-4'}, {'text': 'MLLMs', 'label': 'Large Language Model'}]",GPT-4,GPT-4o,0.9017629027366638
