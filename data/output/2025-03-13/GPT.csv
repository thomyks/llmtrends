id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,extracted_entities,assigned_concept,matched_keyword,similarity_score
2402.08658,David Haag,"David Haag, Devender Kumar, Sebastian Gruber, Dominik Hofer, Mahdi
  Sareban, Gunnar Treff, Josef Niebauer, Christopher Bull, Albrecht Schmidt,
  Jan David Smeddinck","The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time
  Adaptive Interventions: Fostering Physical Activity in a Conceptual Cardiac
  Rehabilitation Setting",,,10.1145/3706598.3713307,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We evaluated the viability of using Large Language Models (LLMs) to trigger
and personalize content in Just-in-Time Adaptive Interventions (JITAIs) in
digital health. As an interaction pattern representative of context-aware
computing, JITAIs are being explored for their potential to support sustainable
behavior change, adapting interventions to an individual's current context and
needs. Challenging traditional JITAI implementation models, which face severe
scalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs
in the use case of heart-healthy activity in cardiac rehabilitation. Using
three personas representing patients affected by CVD with varying severeness
and five context sets per persona, we generated 450 JITAI decisions and
messages. These were systematically evaluated against those created by 10
laypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated
JITAIs surpassed human-generated intervention suggestions, outperforming both
LayPs and HCPs across all metrics (i.e., appropriateness, engagement,
effectiveness, and professionalism). These results highlight the potential of
LLMs to enhance JITAI implementations in personalized health interventions,
demonstrating how generative AI could revolutionize context-aware computing.
","[{'version': 'v1', 'created': 'Tue, 13 Feb 2024 18:39:36 GMT'}, {'version': 'v2', 'created': 'Mon, 15 Apr 2024 09:08:44 GMT'}, {'version': 'v3', 'created': 'Wed, 26 Feb 2025 08:57:38 GMT'}]",2025-02-27,"[['Haag', 'David', ''], ['Kumar', 'Devender', ''], ['Gruber', 'Sebastian', ''], ['Hofer', 'Dominik', ''], ['Sareban', 'Mahdi', ''], ['Treff', 'Gunnar', ''], ['Niebauer', 'Josef', ''], ['Bull', 'Christopher', ''], ['Schmidt', 'Albrecht', ''], ['Smeddinck', 'Jan David', '']]","[{'text': 'GPT-4', 'label': 'GPT'}, {'text': 'GPT-4-generated', 'label': 'GPT'}]",GPT,GPT-4,0.857287585735321
2405.14860,Joshua Engels,"Joshua Engels, Eric J. Michaud, Isaac Liao, Wes Gurnee, Max Tegmark",Not All Language Model Features Are One-Dimensionally Linear,"Accepted to ICLR 2025. Code and data at
  https://github.com/JoshEngels/MultiDimensionalFeatures",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent work has proposed that language models perform computation by
manipulating one-dimensional representations of concepts (""features"") in
activation space. In contrast, we explore whether some language model
representations may be inherently multi-dimensional. We begin by developing a
rigorous definition of irreducible multi-dimensional features based on whether
they can be decomposed into either independent or non-co-occurring
lower-dimensional features. Motivated by these definitions, we design a
scalable method that uses sparse autoencoders to automatically find
multi-dimensional features in GPT-2 and Mistral 7B. These auto-discovered
features include strikingly interpretable examples, e.g. circular features
representing days of the week and months of the year. We identify tasks where
these exact circles are used to solve computational problems involving modular
arithmetic in days of the week and months of the year. Next, we provide
evidence that these circular features are indeed the fundamental unit of
computation in these tasks with intervention experiments on Mistral 7B and
Llama 3 8B, and we examine the continuity of the days of the week feature in
Mistral 7B. Overall, our work argues that understanding multi-dimensional
features is necessary to mechanistically decompose some model behaviors.
","[{'version': 'v1', 'created': 'Thu, 23 May 2024 17:59:04 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Oct 2024 14:23:17 GMT'}, {'version': 'v3', 'created': 'Thu, 27 Feb 2025 03:03:59 GMT'}]",2025-02-28,"[['Engels', 'Joshua', ''], ['Michaud', 'Eric J.', ''], ['Liao', 'Isaac', ''], ['Gurnee', 'Wes', ''], ['Tegmark', 'Max', '']]","[{'text': 'GPT-2', 'label': 'GPT'}, {'text': 'Mistral 7B', 'label': 'Mistral'}, {'text': 'Mistral 7B', 'label': 'Mistral'}, {'text': 'Llama 3 8B', 'label': 'Llama'}, {'text': 'Mistral 7B', 'label': 'Mistral'}]",GPT,GPT-2,0.8734456300735474
2407.07064,Nicolas E. Diaz Ferreyra PhD,"Catherine Tony, Nicol\'as E. D\'iaz Ferreyra, Markus Mutas, Salem
  Dhiff and Riccardo Scandariato","Prompting Techniques for Secure Code Generation: A Systematic
  Investigation","Work partially supported by the EU-funded project Sec4AI4Sec:
  Cybersecurity for AI-Augmented Systems (grant no. 101120393) - ACCEPTED at
  ACM Transactions on Software Engineering and Methodology (Feb. 2025)",,,,cs.SE cs.AI cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) are gaining momentum in software development
with prompt-driven programming enabling developers to create code from natural
language (NL) instructions. However, studies have questioned their ability to
produce secure code and, thereby, the quality of prompt-generated software.
Alongside, various prompting techniques that carefully tailor prompts have
emerged to elicit optimal responses from LLMs. Still, the interplay between
such prompting strategies and secure code generation remains under-explored and
calls for further investigations. OBJECTIVE: In this study, we investigate the
impact of different prompting techniques on the security of code generated from
NL instructions by LLMs. METHOD: First we perform a systematic literature
review to identify the existing prompting techniques that can be used for code
generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,
and GPT-4 models for secure code generation. For this, we used an existing
dataset consisting of 150 NL security-relevant code-generation prompts.
RESULTS: Our work (i) classifies potential prompting techniques for code
generation (ii) adapts and evaluates a subset of the identified techniques for
secure code generation tasks and (iii) observes a reduction in security
weaknesses across the tested LLMs, especially after using an existing technique
called Recursive Criticism and Improvement (RCI), contributing valuable
insights to the ongoing discourse on LLM-generated code security.
","[{'version': 'v1', 'created': 'Tue, 9 Jul 2024 17:38:03 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Feb 2025 14:28:11 GMT'}]",2025-02-27,"[['Tony', 'Catherine', ''], ['Ferreyra', 'Nicolás E. Díaz', ''], ['Mutas', 'Markus', ''], ['Dhiff', 'Salem', ''], ['Scandariato', 'Riccardo', '']]","[{'text': 'LLMs', 'label': 'Large Language Model'}, {'text': 'prompting techniques', 'label': 'Prompting'}, {'text': 'LLMs', 'label': 'Large Language Model'}, {'text': 'prompting techniques', 'label': 'Prompting'}, {'text': 'LLMs', 'label': 'Large Language Model'}, {'text': 'prompting techniques', 'label': 'Prompting'}, {'text': 'GPT-3', 'label': 'GPT'}, {'text': 'GPT-3', 'label': 'GPT'}, {'text': 'GPT-4', 'label': 'GPT'}, {'text': 'prompting techniques', 'label': 'Prompting'}, {'text': 'LLMs', 'label': 'Large Language Model'}]",GPT,GPT-3,0.8771116137504578
