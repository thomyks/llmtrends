{"id": "1011.4237", "submitter": "Lo\\\"ic Michel", "authors": "Lo\\\"ic Michel", "title": "A variational and symplectic framework for model-free control:\n  preliminary results", "comments": "7 pages, 13 figures - submitted to IEEE CCTA'25", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The model-free control approach is an advanced control law that requires few\ninformation about the process to control. Since its introduction in 2008,\nnumerous applications have been successfully considered, highlighting\nattractive robustness properties towards tracking efficiency and disturbance\nrejection. In this work, a variational approach of the model-free control is\nproposed in order to extend its robustness capabilities. An adaptive\nformulation of the controller is proposed using the calculus of variations\nwithin a symplectic framework, that aims to consider the control law as an\noptimization problem toward the auto-tuning of its main key parameter. The\nproposed formulation provides a coupling between the model-free control law and\na variational integrator to improve the robustness of the tracking towards\nprocess changes and emphasize closed-loop stabilization. Some illustrative\nexamples are discussed to highlight the rightness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 17:14:59 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 10:39:13 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Michel", "Lo\u00efc", ""]], "extracted_entities": [{"text": "control law", "label": "Scaling law"}, {"text": "control law", "label": "Scaling law"}, {"text": "model-free control law", "label": "Scaling law"}], "human_readable_topic": "Parameter-Efficient Fine-Tuning of Pre-Trained Models"}
{"id": "1802.04233", "submitter": "Thomas Lasko", "authors": "Jacek M. Bajor, Diego A. Mesa, Travis J. Osterman, Thomas A. Lasko", "title": "Embedding Complexity In the Data Representation Instead of In the Model:\n  A Case Study Using Heterogeneous Medical Data", "comments": "9 pages, 5 figures. This version only removed conference submission\n  info", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records have become popular sources of data for secondary\nresearch, but their use is hampered by the amount of effort it takes to\novercome the sparsity, irregularity, and noise that they contain. Modern\nlearning architectures can remove the need for expert-driven feature\nengineering, but not the need for expert-driven preprocessing to abstract away\nthe inherent messiness of clinical data. This preprocessing effort is often the\ndominant component of a typical clinical prediction project. In this work we\npropose using semantic embedding methods to directly couple the raw, messy\nclinical data to downstream learning architectures with truly minimal\npreprocessing. We examine this step from the perspective of capturing and\nencoding complex data dependencies in the data representation instead of in the\nmodel, which has the nice benefit of allowing downstream processing to be done\nwith fast, lightweight, and simple models accessible to researchers without\nmachine learning expertise. We demonstrate with three typical clinical\nprediction tasks that the highly compressed, embedded data representations\ncapture a large amount of useful complexity, although in some cases the\ncompression is not completely lossless.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:31:24 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:25:00 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Bajor", "Jacek M.", ""], ["Mesa", "Diego A.", ""], ["Osterman", "Travis J.", ""], ["Lasko", "Thomas A.", ""]], "extracted_entities": [{"text": "semantic embedding methods", "label": "Embedding"}], "human_readable_topic": "Molecular and Protein Representation Learning"}
{"id": "1804.10646", "submitter": "Ben Webster", "authors": "Michael McBreen and Ben Webster", "title": "Homological Mirror Symmetry for Hypertoric Varieties I", "comments": "41 pages. v4: Final published version", "journal-ref": "Geom. Topol. 28 (2024) 1005-1063", "doi": "10.2140/gt.2024.28.1005", "report-no": null, "categories": "math.AG math.RT math.SG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider homological mirror symmetry in the context of hypertoric\nvarieties, showing that appropriate categories of B-branes (that is, coherent\nsheaves) on an additive hypertoric variety match a category of A-branes on a\nDolbeault hypertoric manifold for the same underlying combinatorial data. For\ntechnical reasons, the category of A-branes we consider is the modules over a\ndeformation quantization (that is, DQ-modules). We consider objects in this\ncategory equipped with an analogue of a Hodge structure, which corresponds to a\n$\\mathbb{G}_m$-action on the dual side of the mirror symmetry.\n  This result is based on hands-on calculations in both categories. We analyze\ncoherent sheaves by constructing a tilting generator, using the characteristic\n$p$ approach of Kaledin; the result is a sum of line bundles, which can be\ndescribed using a simple combinatorial rule. The endomorphism algebra $H$ of\nthis tilting generator has a simple quadratic presentation in the grading\ninduced by $\\mathbb{G}_m$-equivariance. In fact, we can confirm it is Koszul,\nand compute its Koszul dual $H^!$.\n  We then show that this same algebra appears as an Ext-algebra of simple\nA-branes in a Dolbeault hypertoric manifold. The $\\mathbb{G}_m$-equivariant\ngrading on coherent sheaves matches a Hodge grading in this category.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 18:52:14 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 19:19:20 GMT"}, {"version": "v3", "created": "Sat, 2 Oct 2021 03:11:14 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 15:44:11 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["McBreen", "Michael", ""], ["Webster", "Ben", ""]], "extracted_entities": [{"text": "deformation quantization", "label": "quantisation"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "1811.10466", "submitter": "Marco Bellini", "authors": "Nicola Biagi, Luca S. Costanzo, Marco Bellini, Alessandro Zavatta", "title": "Entangling macroscopic light states by delocalized photon addition", "comments": "5 pages, 5 figures", "journal-ref": "Phys. Rev. Lett. 124, 033604 (2020)", "doi": "10.1103/PhysRevLett.124.033604", "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the experimental generation of tunable entanglement between\ndistinct field modes by the delocalized addition of a single photon. We show\nthat one can preserve a high degree of entanglement even between\nmacroscopically populated modes and illustrate this concept by adding a single\nphoton to two modes containing identical coherent states of growing amplitude.\nDiscorrelation, a new joint statistical property of multimode quantum states,\nis also experimentally demonstrated here for the first time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:58:16 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 16:05:36 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Biagi", "Nicola", ""], ["Costanzo", "Luca S.", ""], ["Bellini", "Marco", ""], ["Zavatta", "Alessandro", ""]], "extracted_entities": [{"text": "Discorrelation", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2005.05518", "submitter": "Pawan Poojary", "authors": "Pawan Poojary and Randall Berry", "title": "Impact of Fake Agents on Information Cascades", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": "10.1109/ISIT44484.2020.9174217", "report-no": null, "categories": "cs.SI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online markets, agents often learn from other's actions in addition to\ntheir private information. Such observational learning can lead to herding or\ninformation cascades in which agents eventually ignore their private\ninformation and \"follow the crowd\". Models for such cascades have been well\nstudied for Bayes-rational agents that arrive sequentially and choose pay-off\noptimal actions. This paper additionally considers the presence of fake agents\nthat take a fixed action in order to influence subsequent rational agents\ntowards their preferred action. We characterize how the fraction of such fake\nagents impacts the behavior of rational agents given a fixed quality of private\ninformation. Our model results in a Markov chain with a countably infinite\nstate space, for which we give an iterative method to compute an agent's\nchances of herding and its welfare (expected pay-off). Our main result shows a\ncounter-intuitive phenomenon: there exist infinitely many scenarios where an\nincrease in the fraction of fake agents in fact reduces the chances of their\npreferred outcome. Moreover, this increase causes a significant improvement in\nthe welfare of every rational agent. Hence, this increase is not only\ncounter-productive for the fake agents but is also beneficial to the rational\nagents.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 02:03:38 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2023 01:18:29 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 21:54:48 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Poojary", "Pawan", ""], ["Berry", "Randall", ""]], "extracted_entities": [{"text": "welfare", "label": "Model Bias and Fairness"}], "human_readable_topic": "Privacy-Preserving Large Language Models"}
{"id": "2011.02796", "submitter": "Zhihua Tian", "authors": "Zhihua Tian, Rui Zhang, Xiaoyang Hou, Lingjuan Lyu, Tianyi Zhang, Jian\n  Liu, Kui Ren", "title": "FederBoost: Private Federated Learning for GBDT", "comments": "12 pages, 4 figures", "journal-ref": "IEEE Transactions on Dependable and Secure Computing ( Volume: 21,\n  Issue: 3, May-June 2024, Pages: 1274 - 1285)", "doi": "10.1109/TDSC.2023.3276365", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) has been an emerging trend in machine learning and\nartificial intelligence. It allows multiple participants to collaboratively\ntrain a better global model and offers a privacy-aware paradigm for model\ntraining since it does not require participants to release their original\ntraining data. However, existing FL solutions for vertically partitioned data\nor decision trees require heavy cryptographic operations. In this paper, we\npropose a framework named FederBoost for private federated learning of gradient\nboosting decision trees (GBDT). It supports running GBDT over both vertically\nand horizontally partitioned data. Vertical FederBoost does not require any\ncryptographic operation and horizontal FederBoost only requires lightweight\nsecure aggregation. The key observation is that the whole training process of\nGBDT relies on the ordering of the data instead of the values. We fully\nimplement FederBoost and evaluate its utility and efficiency through extensive\nexperiments performed on three public datasets. Our experimental results show\nthat both vertical and horizontal FederBoost achieve the same level of accuracy\nwith centralized training where all data are collected in a central server, and\nthey are 4-5 orders of magnitude faster than the state-of-the-art solutions for\nfederated decision tree training; hence offering practical solutions for\nindustrial applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:05:12 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2022 03:38:34 GMT"}, {"version": "v3", "created": "Wed, 21 Dec 2022 10:21:34 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 11:38:05 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Tian", "Zhihua", ""], ["Zhang", "Rui", ""], ["Hou", "Xiaoyang", ""], ["Lyu", "Lingjuan", ""], ["Zhang", "Tianyi", ""], ["Liu", "Jian", ""], ["Ren", "Kui", ""]], "extracted_entities": [{"text": "Federated Learning", "label": "Few-shot Learning"}, {"text": "federated learning", "label": "Few-shot Learning"}], "human_readable_topic": "Federated Learning for Private Data"}
{"id": "2101.02753", "submitter": "Arturo Samana R", "authors": "C. De Conti (1), V. dos S. Ferreira (2), A.R. Samana (3), C.A. Barbero\n  (4), and F. Krmpoti\\'c (4) ((1) UNESP, Rosana, SP, Brazil, (2) UERJ, Rio de\n  Janeiro, Brazil, (3) UESC, Ilh\\'eus, Brazil, (4) IFLP-CONICET, La Plata,\n  Argentina)", "title": "Neutrinoless $\\beta\\beta$-Decay in DCEQTDA", "comments": "37 pages,4 figures", "journal-ref": "Eur. Phys. J. A (2025) 61:34", "doi": "10.1140/epja/s10050-025-01484-x", "report-no": null, "categories": "nucl-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently developed a nuclear model, which is a natural extension of\nthe $pn$-QRPA model, specially designed to describe double charge exchange\n(DCE) processes generated by two-body DCE transition operators. It is based on\nthe Quasiparticle Tamm-Dancoff Approximation (QTDA) for $pn$ and $2p2n$\nexcitations in intermediate and final nuclei, respectively, and will be called\nDCEQTDA.\n  As such, this model, having the same number of free parameters as the\n$pn$-QRPA, also brings into play the excitations of four quasiparticles to\nbuild up the final nuclear states, which are then used to evaluate the nuclear\nmatrix elements (NMEs) for all $0^+$ and $2^+$ final states, including\nresonances, and not just for the ground state as in $pn$-QRPA. In addition, it\nallows us to evaluate: (a) the values of $Q_{\\beta\\beta}$, (b) the excitation\nenergies in final nuclei, and (c) the DCE sum rules, which are fulfilled in the\nDCEQTDA. So far, this model has been used mainly to calculate double beta\ndecays with the emission of two neutrinos ($2\\nu\\beta\\beta$-decay). Here, we\nextend it to the study of these processes when no neutrinos are emitted\n($0\\nu\\beta\\beta$-decay), evaluating them in a series of nuclei, but paying\nspecial attention to (i) $^{76}$Se, which have been measured recently in the\nGERDA and MAJORANA experiments, and (ii) $^{124}$Te, for which the first direct\nobservation of the double electron capture $2\\nu$ has been performed with the\nXENON1T dark matter detector. We obtain good agreement with the data for both\nthe ground state and the excited states. The validity of the DCEQTDA model is\nchecked by comparing the calculation with the experimental data for the\n$2\\nu\\beta\\beta$ NMEs, and for the $Q_{\\beta\\beta}$, in a series of nuclei.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 20:32:22 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 23:18:06 GMT"}, {"version": "v3", "created": "Sun, 6 Mar 2022 14:59:14 GMT"}, {"version": "v4", "created": "Tue, 13 Dec 2022 15:06:22 GMT"}, {"version": "v5", "created": "Sun, 22 Jan 2023 20:19:29 GMT"}, {"version": "v6", "created": "Tue, 25 Feb 2025 18:30:38 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["De Conti", "C.", ""], ["Ferreira", "V. dos S.", ""], ["Samana", "A. R.", ""], ["Barbero", "C. A.", ""], ["Krmpoti\u0107", "F.", ""]], "extracted_entities": [{"text": "$pn$-QRPA model", "label": "AI model"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2104.05914", "submitter": "Yang Li", "authors": "Yang Li, Di Wang, and Jos\\'e M. F. Moura", "title": "GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph\n  Sequence Attention", "comments": null, "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 2025", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting graph-based, time-dependent data has broad practical applications\nbut presents challenges. Effective models must capture both spatial and\ntemporal dependencies in the data, while also incorporating auxiliary\ninformation to enhance prediction accuracy. In this paper, we identify\nlimitations in current state-of-the-art models regarding temporal dependency\nhandling. To overcome this, we introduce GSA-Forecaster, a new deep learning\nmodel designed for forecasting in graph-based, time-dependent contexts.\nGSA-Forecaster utilizes graph sequence attention, a new attention mechanism\nproposed in this paper, to effectively manage temporal dependencies.\nGSA-Forecaster integrates the data's graph structure directly into its\narchitecture, addressing spatial dependencies. Additionally, it incorporates\nauxiliary information to refine its predictions further. We validate its\nperformance using real-world graph-based, time-dependent datasets, where it\ndemonstrates superior effectiveness compared to existing state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 03:19:10 GMT"}, {"version": "v2", "created": "Sat, 16 Oct 2021 05:13:33 GMT"}, {"version": "v3", "created": "Mon, 29 Aug 2022 17:10:07 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 14:22:25 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Li", "Yang", ""], ["Wang", "Di", ""], ["Moura", "Jos\u00e9 M. F.", ""]], "extracted_entities": [{"text": "graph sequence attention", "label": "Attention mechanism"}, {"text": "new attention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Temporal Graph Embeddings and Analysis"}
{"id": "2105.00984", "submitter": "Benjamin Monmege", "authors": "Benjamin Monmege, Julie Parreaux, Pierre-Alain Reynier", "title": "Playing Stochastically in Weighted Timed Games to Emulate Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weighted timed games are two-player zero-sum games played in a timed\nautomaton equipped with integer weights. We consider optimal reachability\nobjectives, in which one of the players, that we call Min, wants to reach a\ntarget location while minimising the cumulated weight. While knowing if Min has\na strategy to guarantee a value lower than a given threshold is known to be\nundecidable (with two or more clocks), several conditions, one of them being\ndivergence, have been given to recover decidability. In such weighted timed\ngames (like in untimed weighted games in the presence of negative weights), Min\nmay need finite memory to play (close to) optimally. This is thus tempting to\ntry to emulate this finite memory with other strategic capabilities. In this\nwork, we allow the players to use stochastic decisions, both in the choice of\ntransitions and of timing delays. We give a definition of the expected value in\nweighted timed games. We then show that, in divergent weighted timed games as\nwell as in (untimed) weighted games (that we call shortest-path games in the\nfollowing), the stochastic value is indeed equal to the classical\n(deterministic) value, thus proving that Min can guarantee the same value while\nonly using stochastic choices, and no memory.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:33:28 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2023 10:56:01 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2023 15:25:23 GMT"}, {"version": "v4", "created": "Wed, 13 Dec 2023 09:34:15 GMT"}, {"version": "v5", "created": "Wed, 14 Aug 2024 15:05:03 GMT"}, {"version": "v6", "created": "Wed, 18 Dec 2024 08:44:42 GMT"}, {"version": "v7", "created": "Tue, 25 Feb 2025 13:52:09 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Monmege", "Benjamin", ""], ["Parreaux", "Julie", ""], ["Reynier", "Pierre-Alain", ""]], "extracted_entities": [{"text": "Min", "label": "AI model"}, {"text": "Min", "label": "AI model"}, {"text": "Min", "label": "AI model"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2105.07228", "submitter": "Tizian Wenzel", "authors": "Tizian Wenzel, Gabriele Santin, Bernard Haasdonk", "title": "Analysis of Structured Deep Kernel Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we leverage a recent deep kernel representer theorem to\nconnect kernel based learning and (deep) neural networks in order to understand\ntheir interplay. In particular, we show that the use of special types of\nkernels yields models reminiscent of neural networks that are founded in the\nsame theoretical framework of classical kernel methods, while benefiting from\nthe computational advantages of deep neural networks. Especially the introduced\nStructured Deep Kernel Networks (SDKNs) can be viewed as neural networks (NNs)\nwith optimizable activation functions obeying a representer theorem. This link\nallows us to analyze also NNs within the framework of kernel networks. We prove\nanalytic properties of the SDKNs which show their universal approximation\nproperties in three different asymptotic regimes of unbounded number of\ncenters, width and depth. Especially in the case of unbounded depth, more\naccurate constructions can be achieved using fewer layers compared to\ncorresponding constructions for ReLU neural networks. This is made possible by\nleveraging properties of kernel approximation.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 14:10:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 16:21:07 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wenzel", "Tizian", ""], ["Santin", "Gabriele", ""], ["Haasdonk", "Bernard", ""]], "extracted_entities": [{"text": "kernel based learning", "label": "Zero-shot Learning"}, {"text": "NNs", "label": "AI model"}], "human_readable_topic": "Deep Learning Neural Networks"}
{"id": "2107.10175", "submitter": "Vivekananda Roy", "authors": "Run Wang, Somak Dutta, and Vivekananda Roy", "title": "Bayesian iterative screening in ultra-high dimensional linear\n  regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variable selection in ultra-high dimensional linear regression is often\npreceded by a screening step to significantly reduce the dimension. Here we\ndevelop a Bayesian variable screening method (BITS) guided by the posterior\nmodel probabilities. BITS can successfully integrate prior knowledge, if any,\non effect sizes, and the number of true variables. BITS iteratively includes\npotential variables with the highest posterior probability accounting for the\nalready selected variables. It is implemented by a fast Cholesky update\nalgorithm and is shown to have the screening consistency property. BITS is\nbuilt based on a model with Gaussian errors, yet, the screening consistency is\nproved to hold under more general tail conditions. The notion of posterior\nscreening consistency allows the resulting model to provide a good starting\npoint for further Bayesian variable selection methods. A new screening\nconsistent stopping rule based on posterior probability is developed.\nSimulation studies and real data examples are used to demonstrate scalability\nand fine screening performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:01:13 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 20:20:58 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Wang", "Run", ""], ["Dutta", "Somak", ""], ["Roy", "Vivekananda", ""]], "extracted_entities": [{"text": "scalability", "label": "Scaling law"}], "human_readable_topic": "Parameter-Efficient Fine-Tuning of Pre-Trained Models"}
{"id": "2107.14566", "submitter": "Ot\\'avio Gomide", "authors": "Ot\\'avio M. L. Gomide, Marcel Guardia, Tere M. Seara, Chongchun Zeng", "title": "On small breathers of nonlinear Klein-Gordon equations via exponentially\n  small homoclinic splitting", "comments": null, "journal-ref": "Invent. math. (2025).", "doi": "10.1007/s00222-025-01327-y", "report-no": null, "categories": "math.AP math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breathers are nontrivial time-periodic and spatially localized solutions of\nnonlinear dispersive partial differential equations (PDEs). Families of\nbreathers have been found for certain integrable PDEs but are believed to be\nrare in non-integrable ones such as nonlinear Klein-Gordon equations. In this\npaper we show that small amplitude breathers of \\emph{any} temporal frequency\ndo not exist for semilinear Klein-Gordon equations with generic analytic odd\nnonlinearities.\n  A breather with small amplitude exists only when its temporal frequency is\nclose to be resonant with the linear Klein-Gordon dispersion relation. Our main\nresult is that, for such frequencies, we rigorously identify the leading order\nterm in the exponentially small (with respect to the small amplitude)\nobstruction to the existence of small breathers in terms of the so-called\n\\emph{Stokes constant}, which depends on the nonlinearity analytically, but is\nindependent of the frequency. This gives a rigorous justification of a formal\nasymptotic argument by Kruskal and Segur \\cite{KS87} in the analysis of small\nbreathers.\n  We rely on the spatial dynamics approach where breathers can be seen as\nhomoclinic orbits. The birth of such small homoclinics is analyzed via a\nsingular perturbation setting where a Bogdanov-Takens type bifurcation is\ncoupled to infinitely many rapidly oscillatory directions. The leading order\nterm of the exponentially small splitting between the stable/unstable invariant\nmanifolds is obtained through a careful analysis of the analytic continuation\nof their parameterizations. This requires the study of another limit equation\nin the complexified evolution variable, the so-called \\emph{inner equation}.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2021 11:54:02 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2023 15:02:20 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 14:10:22 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Gomide", "Ot\u00e1vio M. L.", ""], ["Guardia", "Marcel", ""], ["Seara", "Tere M.", ""], ["Zeng", "Chongchun", ""]], "extracted_entities": [{"text": "Breathers", "label": "LLMs"}, {"text": "breathers", "label": "LLMs"}, {"text": "breathers", "label": "LLMs"}, {"text": "breathers", "label": "LLMs"}, {"text": "breathers", "label": "LLMs"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2110.14240", "submitter": "Xiaolin Song", "authors": "Haojin Liao, Xiaolin Song, Sicheng Zhao, Shanghang Zhang, Xiangyu Yue,\n  Xingxu Yao, Yueming Zhang, Tengfei Xing, Pengfei Xu, Qiang Wang", "title": "3rd Place Solution for VisDA 2021 Challenge -- Universally Domain\n  Adaptive Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Domain Adaptation (VisDA) 2021 Challenge calls for unsupervised\ndomain adaptation (UDA) methods that can deal with both input distribution\nshift and label set variance between the source and target domains. In this\nreport, we introduce a universal domain adaptation (UniDA) method by\naggregating several popular feature extraction and domain adaptation schemes.\nFirst, we utilize VOLO, a Transformer-based architecture with state-of-the-art\nperformance in several visual tasks, as the backbone to extract effective\nfeature representations. Second, we modify the open-set classifier of OVANet to\nrecognize the unknown class with competitive accuracy and robustness. As shown\nin the leaderboard, our proposed UniDA method ranks the 3rd place with 48.49%\nACC and 70.8% AUROC in the VisDA 2021 Challenge.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2021 07:48:29 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 13:41:26 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liao", "Haojin", ""], ["Song", "Xiaolin", ""], ["Zhao", "Sicheng", ""], ["Zhang", "Shanghang", ""], ["Yue", "Xiangyu", ""], ["Yao", "Xingxu", ""], ["Zhang", "Yueming", ""], ["Xing", "Tengfei", ""], ["Xu", "Pengfei", ""], ["Wang", "Qiang", ""]], "extracted_entities": [{"text": "VOLO", "label": "Transformer-based model"}, {"text": "OVANet", "label": "Transformer-based model"}], "human_readable_topic": "Unsupervised Domain Adaptation Methods"}
{"id": "2111.05667", "submitter": "Tomoaki Niiyama", "authors": "Tomoaki Niiyama and Satoshi Sunada", "title": "Power-law fluctuations near critical point in semiconductor lasers with\n  delayed feedback", "comments": "12 pages, 12 figures", "journal-ref": "Phys. Rev. Res., 4, 043205, (2022)", "doi": "10.1103/PhysRevResearch.4.043205", "report-no": null, "categories": "physics.optics nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the analogy between laser oscillation and second-order phase transition\nwas indicated in the 1970s, dynamical fluctuations on lasing threshold inherent\nin critical phenomena have gained significant interest. Here, we numerically\nand experimentally demonstrate that a semiconductor laser subject to delayed\noptical feedback can exhibit unusual large intensity fluctuations characterized\nby power-law distributions. Such an intensity fluctuation consists of distinct\nintermittent bursts of light intensity, whose peak values attain tens of times\nthe intensity of the maximum gain mode. This burst behavior emerges when a\nlaser with a long time delay (over 100 ns) and an optimal feedback strength\noperates around the lasing threshold. The intensity and waiting time statistics\nfollow power-law-like distributions. This implies the emergence of\nnonequilibrium critical phenomena, namely self-organized criticality. In\naddition to numerical results, we report experimental results that suggest the\npower-law intensity dynamics in a semiconductor laser with delayed feedback.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2021 12:19:42 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 11:17:24 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Niiyama", "Tomoaki", ""], ["Sunada", "Satoshi", ""]], "extracted_entities": [{"text": "power-law distributions", "label": "Scaling law"}, {"text": "power-law-like distributions", "label": "Scaling law"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2112.06460", "submitter": "Juyong Jiang", "authors": "Juyong Jiang, Peiyan Zhang, Yingtao Luo, Chaozhuo Li, Jae Boum Kim,\n  Kai Zhang, Senzhang Wang, Sunghun Kim, Philip S. Yu", "title": "Improving Sequential Recommendations via Bidirectional Temporal Data\n  Augmentation with Pre-training", "comments": "Accepted by TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential recommendation systems are integral to discerning temporal user\npreferences. Yet, the task of learning from abbreviated user interaction\nsequences poses a notable challenge. Data augmentation has been identified as a\npotent strategy to enhance the informational richness of these sequences.\nTraditional augmentation techniques, such as item randomization, may disrupt\nthe inherent temporal dynamics. Although recent advancements in reverse\nchronological pseudo-item generation have shown promise, they can introduce\ntemporal discrepancies when assessed in a natural chronological context. In\nresponse, we introduce a sophisticated approach, Bidirectional temporal data\nAugmentation with pre-training (BARec). Our approach leverages bidirectional\ntemporal augmentation and knowledge-enhanced fine-tuning to synthesize\nauthentic pseudo-prior items that retain user preferences and capture deeper\nitem semantic correlations, thus boosting the model's expressive power. Our\ncomprehensive experimental analysis on five benchmark datasets confirms the\nsuperiority of BARec across both short and elongated sequence contexts.\nMoreover, theoretical examination and case study offer further insight into the\nmodel's logical processes and interpretability. The source code for our study\nis publicly available at https://github.com/juyongjiang/BARec.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2021 07:33:28 GMT"}, {"version": "v2", "created": "Sun, 1 May 2022 06:01:36 GMT"}, {"version": "v3", "created": "Tue, 5 Jul 2022 09:25:36 GMT"}, {"version": "v4", "created": "Thu, 7 Jul 2022 02:33:02 GMT"}, {"version": "v5", "created": "Tue, 26 Mar 2024 03:44:29 GMT"}, {"version": "v6", "created": "Mon, 24 Feb 2025 18:44:15 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Jiang", "Juyong", ""], ["Zhang", "Peiyan", ""], ["Luo", "Yingtao", ""], ["Li", "Chaozhuo", ""], ["Kim", "Jae Boum", ""], ["Zhang", "Kai", ""], ["Wang", "Senzhang", ""], ["Kim", "Sunghun", ""], ["Yu", "Philip S.", ""]], "extracted_entities": [{"text": "knowledge-enhanced fine-tuning", "label": "Fine-tuning"}, {"text": "BARec", "label": "Generative Pre-trained Transformer (GPT)"}], "human_readable_topic": "Temporal Knowledge Graph Embeddings"}
{"id": "2202.01085", "submitter": "Robert Hu", "authors": "Robert Hu, Siu Lun Chau, Dino Sejdinovic, Joan Alexis Glaun\\`es", "title": "Giga-scale Kernel Matrix Vector Multiplication on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.MS cs.NA stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel matrix-vector multiplication (KMVM) is a foundational operation in\nmachine learning and scientific computing. However, as KMVM tends to scale\nquadratically in both memory and time, applications are often limited by these\ncomputational constraints. In this paper, we propose a novel approximation\nprocedure coined \\textit{Faster-Fast and Free Memory Method} ($\\fthreem$) to\naddress these scaling issues of KMVM for tall~($10^8\\sim 10^9$) and\nskinny~($D\\leq7$) data. Extensive experiments demonstrate that $\\fthreem$ has\nempirical \\emph{linear time and memory} complexity with a relative error of\norder $10^{-3}$ and can compute a full KMVM for a billion points \\emph{in under\na minute} on a high-end GPU, leading to a significant speed-up in comparison to\nexisting CPU methods. We demonstrate the utility of our procedure by applying\nit as a drop-in for the state-of-the-art GPU-based linear solver FALKON,\n\\emph{improving speed 1.5-5.5 times} at the cost of $<1\\%$ drop in accuracy. We\nfurther demonstrate competitive results on \\emph{Gaussian Process regression}\ncoupled with significant speedups on a variety of real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2022 15:28:15 GMT"}, {"version": "v2", "created": "Wed, 25 May 2022 14:19:48 GMT"}, {"version": "v3", "created": "Wed, 12 Oct 2022 22:01:20 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 00:50:28 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Hu", "Robert", ""], ["Chau", "Siu Lun", ""], ["Sejdinovic", "Dino", ""], ["Glaun\u00e8s", "Joan Alexis", ""]], "extracted_entities": [{"text": "KMVM", "label": "Foundation Model"}, {"text": "KMVM", "label": "Foundation Model"}, {"text": "KMVM", "label": "Foundation Model"}, {"text": "KMVM", "label": "Foundation Model"}, {"text": "FALKON", "label": "Foundation Model"}], "human_readable_topic": "Memory-Efficient Zeroth-Order Optimizers"}
{"id": "2202.11805", "submitter": "Yevgeny Liokumovich Dr", "authors": "Larry Guth, Yevgeny Liokumovich", "title": "Parametric inequalities and Weyl law for the volume spectrum", "comments": "Proof of Prop. 2.7 corrected. To appear in Geometry and Topology", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG math.GT math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Weyl law for the volume spectrum in a compact Riemannian\nmanifold conjectured by Gromov can be derived from parametric generalizations\nof two famous inequalities: isoperimetric inequality and coarea inequality. We\nprove two such generalizations in low dimensions and obtain the Weyl law for\n1-cycles in 3-manifolds. We also give a new proof of the Almgren isomorphism\ntheorem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2022 22:11:09 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2023 23:11:50 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 20:31:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Guth", "Larry", ""], ["Liokumovich", "Yevgeny", ""]], "extracted_entities": [{"text": "Weyl law", "label": "Scaling law"}, {"text": "isoperimetric inequality", "label": "Scaling law"}, {"text": "coarea inequality", "label": "Scaling law"}, {"text": "Weyl law", "label": "Scaling law"}], "human_readable_topic": "Riemannian Manifolds and Conformal Metrics"}
{"id": "2206.05390", "submitter": "Alzayat Saleh", "authors": "Alzayat Saleh, Marcus Sheaves, Dean Jerry, and Mostafa Rahimi Azghadi", "title": "Overcoming Annotation Bottlenecks in Underwater Fish Segmentation: A\n  Robust Self-Supervised Learning Approach", "comments": "11 pages, 7 figures. Published at Signal, Image and Video Processing\n  journal", "journal-ref": "SIViP 19, 270 (2025)", "doi": "10.1007/s11760-025-03860-y", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate fish segmentation in underwater videos is challenging due to low\nvisibility, variable lighting, and dynamic backgrounds, making fully-supervised\nmethods that require manual annotation impractical for many applications. This\npaper introduces a novel self-supervised learning approach for fish\nsegmentation using Deep Learning. Our model, trained without manual annotation,\nlearns robust and generalizable representations by aligning features across\naugmented views and enforcing spatial-temporal consistency. We demonstrate its\neffectiveness on three challenging underwater video datasets: DeepFish,\nSeagrass, and YouTube-VOS, surpassing existing self-supervised methods and\nachieving segmentation accuracy comparable to fully-supervised methods without\nthe need for costly annotations. Trained on DeepFish, our model exhibits strong\ngeneralization, achieving high segmentation accuracy on the unseen Seagrass and\nYouTube-VOS datasets. Furthermore, our model is computationally efficient due\nto its parallel processing and efficient anchor sampling technique, making it\nsuitable for real-time applications and potential deployment on edge devices.\nWe present quantitative results using Jaccard Index and Dice coefficient, as\nwell as qualitative comparisons, showcasing the accuracy, robustness, and\nefficiency of our approach for advancing underwater video analysis\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2022 01:20:48 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 04:28:37 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Saleh", "Alzayat", ""], ["Sheaves", "Marcus", ""], ["Jerry", "Dean", ""], ["Azghadi", "Mostafa Rahimi", ""]], "extracted_entities": [{"text": "Deep Learning", "label": "Few-shot Learning"}], "human_readable_topic": "Deep Learning for Wildlife and Image Classification"}
{"id": "2206.11194", "submitter": "Guy Ropars", "authors": "Albert Le Floch and Guy Ropars", "title": "The structure of the Maxwell spot centroid", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dark entoptic Maxwell spot centroids seen through a blue filter, which\ncoincide with the blue cone-free areas centered on the foveas, are shown to\nexhibit a structure. When observing through the green part of a blue-green\nexchange filter in a foveascope, after a fixation through the blue part, a\nsmall orange disc is seen around the centre of the pale green memory afterimage\ncorresponding to the blue cone-free area. Using artificial pupils with\ndifferent diameters, we show that this small circular pattern corresponds to\nthe Airy disc due to the Fraunhofer diffraction through the pupil. Typically,\nfor an eye with a 3 millimeter diameter pupil, the Airy disc exhibits a\ndiameter of about 8 micrometers at the centre of the usual 100-150 micrometer\nMaxwell centroid. Fixation tests show that the towering central maximum of the\nAiry pattern irradiance corresponds to the preferred locus of the fixation of\nthe eye near the centre of the blue cone-free area of the fovea. The locus of\nfixation in human vision thus appears to be located in the only area of the\nfovea where the large chromatic dispersion is cancelled, optimising the eye\nacuity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2022 16:24:13 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 17:29:47 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Floch", "Albert Le", ""], ["Ropars", "Guy", ""]], "extracted_entities": [{"text": "fixation", "label": "Attention mechanism"}], "human_readable_topic": "Transformer Attention Mechanisms"}
{"id": "2206.12532", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia and Jorge Lor\\'ia", "title": "Inferring Effect Ordering Without Causal Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive models that estimate outcome probabilities are widely used to\nguide interventions in applications such as advertising, customer retention,\nand behavioral nudging. Although these outcome probabilities do not measure\ncausal effects, they are often treated as proxies for identifying individuals\nwith the highest intervention impact. We investigate when and why these\npredictions (which we refer to as scores) can reliably rank individuals by\ntheir causal effects in settings where direct effect estimation is infeasible.\nThe key mechanism underlying this approach is that scores serve as proxies for\na latent moderator that drives variation in causal effects. Building on this\nfoundation, we introduce three key conditions -- full latent moderation, full\nlatent mediation, and latent monotonicity -- that determine when scores can\nrecover causal-effect rankings and, in some cases, even outperform direct\neffect estimation. To support practical applications, we provide guidelines for\nassessing when scores are viable proxies, particularly in contexts lacking data\non new interventions or with delayed outcome measurements. Our findings\ndemonstrate that effect heterogeneity can be leveraged through predictive\nmodeling when the target variable being modeled captures a strong latent\nmoderator, expanding the scope of causal inference beyond traditional effect\nestimation and, in some cases, reducing the need for large-scale randomized\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2022 02:15:22 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2023 03:31:41 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2023 15:42:40 GMT"}, {"version": "v4", "created": "Fri, 16 Feb 2024 12:05:26 GMT"}, {"version": "v5", "created": "Thu, 15 Aug 2024 13:38:10 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2025 01:42:13 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Lor\u00eda", "Jorge", ""]], "extracted_entities": [{"text": "behavioral nudging", "label": "Prompting"}], "human_readable_topic": "Causal Analysis with Large Language Models"}
{"id": "2206.13618", "submitter": "Silpa Babu", "authors": "Silpa Babu, Sajan Goud Lingala, Namrata Vaswani", "title": "Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic\n  MRI", "comments": "I have a duplication submission in arXiv (arXiv:2212.09664)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a fast, memory-efficient, and general algorithm for\naccelerated/undersampled dynamic MRI by assuming an approximate LR model on the\nmatrix formed by the vectorized images of the sequence. By general, we mean\nthat our algorithm can be used for multiple accelerated dynamic MRI\napplications and multiple sampling rates (acceleration rates) and patterns with\na single choice of parameters (no parameter tuning). We show that our proposed\nalgorithms, alternating Gradient Descent (GD) and minimization for MRI\n(altGDmin-MRI and altGDmin-MRI2), outperform many existing approaches while\nalso being faster than all of them, on average. This claim is based on\ncomparisons on 8 different retrospectively undersampled single- or multi-coil\ndynamic MRI applications, undersampled using either 1D Cartesian or 2D\npseudo-radial undersampling at multiple sampling rates. All comparisons used\nthe same set of algorithm parameters. Our second contribution is a mini-batch\nand a fully online extension that can process new measurements and return\nreconstructions either as soon as measurements of a new image frame arrive, or\nafter a short delay.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2022 20:31:06 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2022 18:07:01 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 15:52:19 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Babu", "Silpa", ""], ["Lingala", "Sajan Goud", ""], ["Vaswani", "Namrata", ""]], "extracted_entities": [{"text": "no parameter tuning", "label": "Fine-tuning"}], "human_readable_topic": "Medical Imaging Reconstruction and Denoising"}
{"id": "2208.00797", "submitter": "Juan Zurita", "authors": "Juan Zurita, Charles E. Creffield and Gloria Platero", "title": "Fast quantum transfer mediated by topological domain walls", "comments": "24 pages, 17 figures; Figs. 6 and 17 and related text corrected", "journal-ref": "Quantum 7, 1043 (2023)", "doi": "10.22331/q-2023-06-22-1043", "report-no": null, "categories": "quant-ph cond-mat.mes-hall", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The duration of bidirectional transfer protocols in 1D topological models\nusually scales exponentially with distance. In this work, we propose transfer\nprotocols in multidomain SSH chains and Creutz ladders that lose the\nexponential dependence, greatly speeding up the process with respect to their\nsingle-domain counterparts, reducing the accumulation of errors and drastically\nincreasing their performance, even in the presence of symmetry-breaking\ndisorder. We also investigate how to harness the localization properties of the\nCreutz ladder-with two localized modes per domain wall-to choose the two states\nalong the ladder that will be swapped during the transfer protocol, without\ndisturbing the states located in the intermediate walls between them. This\nprovides a 1D network with all-to-all connectivity that can be helpful for\nquantum information purposes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2022 12:26:11 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2023 01:32:00 GMT"}, {"version": "v3", "created": "Tue, 30 May 2023 18:01:37 GMT"}, {"version": "v4", "created": "Tue, 20 Jun 2023 08:53:35 GMT"}, {"version": "v5", "created": "Wed, 11 Oct 2023 11:48:45 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2025 12:46:19 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zurita", "Juan", ""], ["Creffield", "Charles E.", ""], ["Platero", "Gloria", ""]], "extracted_entities": [{"text": "quantum information purposes", "label": "quantisation"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2208.10662", "submitter": "Alzayat Saleh", "authors": "Alzayat Saleh, Marcus Sheaves, Dean Jerry, Mostafa Rahimi Azghadi", "title": "How to Track and Segment Fish without Human Annotations: A\n  Self-Supervised Deep Learning Approach", "comments": "22 pages, 11 figures. Published at Pattern Analysis and Applications\n  journal", "journal-ref": "Pattern Anal Applic 27, 4 (2024)", "doi": "10.1007/s10044-024-01227-6", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tracking fish movements and sizes of fish is crucial to understanding their\necology and behaviour. Knowing where fish migrate, how they interact with their\nenvironment, and how their size affects their behaviour can help ecologists\ndevelop more effective conservation and management strategies to protect fish\npopulations and their habitats. Deep learning is a promising tool to analyze\nfish ecology from underwater videos. However, training deep neural networks\n(DNNs) for fish tracking and segmentation requires high-quality labels, which\nare expensive to obtain. We propose an alternative unsupervised approach that\nrelies on spatial and temporal variations in video data to generate noisy\npseudo-ground-truth labels. We train a multitask DNN using these pseudo-labels.\nOur framework consists of three stages: (1) an optical flow model generates the\npseudo labels using spatial and temporal consistency between frames, (2) a\nself-supervised model refines the pseudo-labels incrementally, and (3) a\nsegmentation network uses the refined labels for training. Consequently, we\nperform extensive experiments to validate our method on three public underwater\nvideo datasets and demonstrate its effectiveness for video annotation and\nsegmentation. We also evaluate its robustness to different imaging conditions\nand discuss its limitations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2022 01:01:27 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 04:20:12 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Saleh", "Alzayat", ""], ["Sheaves", "Marcus", ""], ["Jerry", "Dean", ""], ["Azghadi", "Mostafa Rahimi", ""]], "extracted_entities": [{"text": "Deep learning", "label": "Few-shot Learning"}, {"text": "optical flow model", "label": "AI model"}, {"text": "self-supervised model", "label": "AI model"}], "human_readable_topic": "Deep Learning for Wildlife and Image Classification"}
{"id": "2209.08651", "submitter": "Jean Dolbeault", "authors": "Jean Dolbeault and Maria J. Esteban and Alessio Figalli and Rupert L.\n  Frank and Michael Loss", "title": "Sharp stability for Sobolev and log-Sobolev inequalities, with optimal\n  dimensional dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP math.CA math.FA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove a sharp quantitative version for the stability of the Sobolev\ninequality with explicit constants. Moreover, the constants have the correct\nbehavior in the limit of large dimensions, which allows us to deduce an optimal\nquantitative stability estimate for the Gaussian log-Sobolev inequality with an\nexplicit dimension-free constant. Our proofs rely on several ingredients such\nas competing symmetries, a flow based on continuous Steiner symmetrization that\ninterpolates continuously between a function and its symmetric decreasing\nrearrangement, and refined estimates on the Sobolev functional in the\nneighborhood of the optimal Aubin--Talenti functions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2022 20:39:09 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2022 18:20:34 GMT"}, {"version": "v3", "created": "Thu, 29 Dec 2022 10:33:50 GMT"}, {"version": "v4", "created": "Sat, 15 Jul 2023 12:50:40 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2025 09:46:35 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Dolbeault", "Jean", ""], ["Esteban", "Maria J.", ""], ["Figalli", "Alessio", ""], ["Frank", "Rupert L.", ""], ["Loss", "Michael", ""]], "extracted_entities": [{"text": "continuous Steiner symmetrization", "label": "quantisation"}], "human_readable_topic": "Fractional Sobolev Embeddings"}
{"id": "2210.05715", "submitter": "Joseba Fernandez de Landa", "authors": "Joseba Fernandez de Landa and Rodrigo Agerri", "title": "Language Independent Stance Detection: Social Interaction-based\n  Embeddings and Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The large majority of the research performed on stance detection has been\nfocused on developing more or less sophisticated text classification systems,\neven when many benchmarks are based on social network data such as Twitter.\nThis paper aims to take on the stance detection task by placing the emphasis\nnot so much on the text itself but on the interaction data available on social\nnetworks. More specifically, we propose a new method to leverage social\ninformation such as friends and retweets by generating Relational Embeddings,\nnamely, dense vector representations of interaction pairs. Our experiments on\nseven publicly available datasets and four different languages (Basque,\nCatalan, Italian, and Spanish) show that combining our relational embeddings\nwith discriminative textual methods helps to substantially improve performance,\nobtaining state-of-the-art results for six out of seven evaluation settings,\noutperforming strong baselines based on Large Language Models, or other popular\ninteraction-based approaches such as DeepWalk or node2vec.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2022 18:13:43 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 09:17:32 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["de Landa", "Joseba Fernandez", ""], ["Agerri", "Rodrigo", ""]], "extracted_entities": [{"text": "Relational Embeddings", "label": "Embedding"}, {"text": "seven publicly available datasets", "label": "Open-source LLMs"}, {"text": "relational embeddings", "label": "Embedding"}, {"text": "Large Language Models", "label": "Large Language Model"}], "human_readable_topic": "Stance Detection in Natural Language Processing"}
{"id": "2211.12603", "submitter": "Tim Wylie", "authors": "Robert M. Alaniz and Bin Fu and Timothy Gomez and Elise Grizzell and\n  Andrew Rodriguez and Marco Rodriguez and Robert Schweller and Tim Wylie", "title": "Reachability in Restricted Chemical Reaction Networks", "comments": "This research was supported in part by National Science Foundation\n  Grants CCF-1817602 and CCF-2329918", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.ET nlin.AO q-bio.MN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The popularity of molecular computation has given rise to several models of\nabstraction, one of the more recent ones being Chemical Reaction Networks\n(CRNs). These are equivalent to other popular computational models, such as\nVector Addition Systems and Petri-Nets, and restricted versions are equivalent\nto Population Protocols. This paper continues the work on core\n\\emph{reachability} questions related to Chemical Reaction Networks; given two\nconfigurations, can one reach the other according to the system's rules? With\nno restrictions, reachability was recently shown to be Ackermann-complete,\nwhich resolved a decades-old problem.\n  In this work, we fully characterize monotone reachability problems based on\nvarious restrictions such as the allowed rule size, the number of rules that\nmay create a species ($k$-source), the number of rules that may consume a\nspecies ($k$-consuming), the volume, and whether the rules have an acyclic\nproduction order (\\emph{feed-forward}). We show PSPACE-completeness of\nreachability with only bimolecular reactions in two-source and two-consuming\nrules. This proves hardness of reachability in a restricted form of Population\nProtocols. This is accomplished using new techniques within the motion planning\nframework.\n  We give several important results for feed-forward CRNs, where rules are\nsingle-source or single-consuming. We show that reachability is solvable in\npolynomial time as long as the system does not contain special \\emph{void} or\n\\emph{autogenesis} rules. We then fully characterize all systems of this type\nand show that with void/autogenesis rules, or more than one source and one\nconsuming, the problems become NP-complete. Finally, we show several\ninteresting special cases of CRNs based on these restrictions or slight\nrelaxations and note future significant open questions related to this\ntaxonomy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2022 22:03:07 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 03:01:46 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Alaniz", "Robert M.", ""], ["Fu", "Bin", ""], ["Gomez", "Timothy", ""], ["Grizzell", "Elise", ""], ["Rodriguez", "Andrew", ""], ["Rodriguez", "Marco", ""], ["Schweller", "Robert", ""], ["Wylie", "Tim", ""]], "extracted_entities": [{"text": "Chemical Reaction Networks", "label": "LLMs"}, {"text": "Chemical Reaction Networks", "label": "LLMs"}], "human_readable_topic": "Reasoning Capabilities of Large Language Models"}
{"id": "2212.00142", "submitter": "Takuya Morozumi", "authors": "Nicholas J. Benoit, Yuta Kawamura, Saki Hamada, Takuya Morozumi,\n  Yusuke Shimizu, Kei Yamamoto", "title": "Determination of Majorana type-phases from the time evolution of lepton\n  numbers", "comments": "31 pages, 7 figures. The data for neutrinos used in sec.2 and Figures\n  2-3 are updated. sec.5 is revised. sec.6 and 7 are added including Fig.6 and\n  7. The version accepted for PTEP", "journal-ref": null, "doi": null, "report-no": "HUPD-2213", "categories": "hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have investigated an approach for determining the Majorana type-phases\nusing the time evolution of lepton family numbers.We show how the second-order\ntime derivative of the expectation values for the lepton family numbers depends\non the sum of the Majorana type-phases. Furthermore,others have connected the\nMajorana type-phases to the orientation of unitary triangles for the PMNS\nmatrix, and the usual Majorana phases. Theoretically,this allows for the\nextraction of the orientation of the triangles and the Majorana phases from\nlepton family numbers. We study three example situations. First, how to extract\nthe Majorana type-phases and the lightest neutrino mass for three massive\nneutrinos, and when a neutrino is massless. Second,the determination of the\nMajorana phase and the lightest neutrino mass for a two generation toy\nmodel.Third, simplified realizations of the type I seesaw model with two gauge\nsinglet neutrinos and two families of lepton doublets.We calculate how the\nMajorana phases and Majorana type-phases are related to CP violation for\nleptogenesis at high energies. At first,the effective Majorana mass matrix is\nparametrized with real and positive diagonal elements. In this basis, the phase\nof the off-diagonal elements are related to the CP violating phases in the PMNS\nmatrix. We explicitly show the relation between the single Majorana phase and\nthe phase of the effective Majorana mass matrix for the toy model with two\ngenerations of active neutrinos. Then for the model with two gauge singlet\nneutrinos and two families of lepton doublets, we study the effective Majorana\nmass matrix generated by the seesaw model.In that model,we can show how the\nMajorana phase at low energy is related to the two CP violating phases of the\nseesaw matrix.That relation between the phases depends on the lepton number\nasymmetries of the heavy Majorana neutrinos decays for the toy models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2022 22:26:39 GMT"}, {"version": "v2", "created": "Sun, 4 Dec 2022 06:50:20 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2022 16:18:16 GMT"}, {"version": "v4", "created": "Fri, 27 Dec 2024 13:38:33 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 15:39:02 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Benoit", "Nicholas J.", ""], ["Kawamura", "Yuta", ""], ["Hamada", "Saki", ""], ["Morozumi", "Takuya", ""], ["Shimizu", "Yusuke", ""], ["Yamamoto", "Kei", ""]], "extracted_entities": [{"text": "toy\nmodel", "label": "AI model"}, {"text": "seesaw model", "label": "AI model"}, {"text": "toy model", "label": "AI model"}, {"text": "seesaw model", "label": "AI model"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2212.03796", "submitter": "Vladimir Rastunkov", "authors": "Vanio Markov, Vladimir Rastunkov, Amol Deshmukh, Daniel Fry, Charlee\n  Stefanski", "title": "Implementation and Learning of Quantum Hidden Markov Models", "comments": "39 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we use the theory of quantum channels and open quantum\nsystems to provide an efficient unitary characterization of a class of\nstochastic generators known as quantum hidden Markov models (QHMMs). By\nutilizing the unitary characterization, we demonstrate that any QHMM can be\nimplemented as a quantum circuit with mid-circuit measurement. We prove that\nQHMMs are more compact and more expressive definitions of stochastic process\nlanguages compared to the equivalent classical hidden Markov models (HMMs).\nStarting with the formulation of QHMMs as quantum channels, we employ\nStinespring's construction to represent these models as unitary quantum\ncircuits with mid-circuit measurement. By utilizing the unitary\nparameterization of QHMMs, we define a formal QHMM learning model. The model\nformalizes the empirical distributions of target stochastic process languages,\ndefines hypothesis space of quantum circuits, and introduces an empirical\nstochastic divergence measure - hypothesis fitness - as a success criterion for\nlearning. We demonstrate that the learning model has a smooth search landscape\ndue to the continuity of Stinespring's dilation. The smooth mapping between the\nhypothesis and fitness spaces enables the development of efficient heuristic\nand gradient descent learning algorithms.\n  We propose two practical learning algorithms for QHMMs. The first algorithm\nis a hyperparameter-adaptive evolutionary search. The second algorithm learns\nthe QHMM as a quantum ansatz circuit using a multi-parameter non-linear\noptimization technique.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2022 17:25:02 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2023 17:14:36 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2024 17:23:48 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 02:42:47 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Markov", "Vanio", ""], ["Rastunkov", "Vladimir", ""], ["Deshmukh", "Amol", ""], ["Fry", "Daniel", ""], ["Stefanski", "Charlee", ""]], "extracted_entities": [{"text": "unitary characterization", "label": "quantisation"}, {"text": "QHMMs", "label": "LLMs"}, {"text": "unitary characterization", "label": "quantisation"}, {"text": "mid-circuit measurement", "label": "quantisation"}, {"text": "QHMMs", "label": "LLMs"}, {"text": "QHMMs", "label": "LLMs"}, {"text": "mid-circuit measurement", "label": "quantisation"}, {"text": "QHMMs", "label": "LLMs"}, {"text": "QHMMs", "label": "LLMs"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2212.05948", "submitter": "Farhad Shirani Chaharsooghi", "authors": "Marian Temprana Alonso, Xuyang Liu, Hamidreza Aghasi, Farhad Shirani", "title": "Non-Linear Analog Processing in MIMO Systems with Coarse Quantization", "comments": "arXiv admin note: substantial text overlap with arXiv:2208.04450", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.SY eess.SP eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog to digital converters (ADCs) are a major contributor to the power\nconsumption of multiple-input multiple-output (MIMO) receivers in large\nbandwidth millimeter-wave systems. Prior works have considered two mitigating\nsolutions to reduce the ADC power consumption: i) decreasing the number of ADCs\nvia analog and hybrid beamforming, and ii) decreasing the ADC resolution, i.e.,\nutilizing one-bit and few-bit ADCs. These mitigating solutions lead to\nperformance loss in terms of achievable rates due to increased quantization\nerror. In this work, the use of nonlinear analog operators such as envelope\ndetectors and polynomial operators, prior to sampling and quantization is\nconsidered, as a way to reduce the aforementioned rate-loss. The receiver\narchitecture consists of linear combiners, nonlinear analog operators, and\nfew-bit ADCs. The fundamental performance limits of the resulting communication\nsystem, in terms of achievable rates, are investigated under various\nassumptions on the set of implementable analog operators. Extensive numerical\nevaluations are provided to evaluate the set of achievable rates and the power\nconsumption of the proposed receiver architectures. Circuit simulations and\nmeasurement results, based on both 22 nm FDSOI CMOS technology and 65 nm Bulk\nCMOS transistor technologies, are provided to justify the power efficiency of\nthe proposed receiver architectures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2022 15:04:43 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2024 19:47:37 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 02:50:39 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Alonso", "Marian Temprana", ""], ["Liu", "Xuyang", ""], ["Aghasi", "Hamidreza", ""], ["Shirani", "Farhad", ""]], "extracted_entities": [{"text": "quantization\nerror", "label": "quantisation"}, {"text": "quantization", "label": "quantisation"}], "human_readable_topic": "Uncategorized"}
{"id": "2212.10100", "submitter": "Matteo Carlesso", "authors": "Qiongyuan Wu and Mario A. Ciampini and Mauro Paternostro and Matteo\n  Carlesso", "title": "Quantifying protocol efficiency: a thermodynamic figure of merit for\n  classical and quantum state-transfer protocols", "comments": null, "journal-ref": "Phys. Rev. Research 5, 023117 (2023)", "doi": "10.1103/PhysRevResearch.5.023117", "report-no": null, "categories": "quant-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Manipulating quantum systems undergoing non-Gaussian dynamics in a fast and\naccurate manner is becoming fundamental to many quantum applications. Here, we\nfocus on classical and quantum protocols transferring a state across a\ndouble-well potential. The classical protocols are achieved by deforming the\npotential, while the quantum ones are assisted by a counter-diabatic driving.\nWe show that quantum protocols perform more quickly and accurately. Finally, we\ndesign a figure of merit for the performance of the transfer protocols --\nnamely, the protocol grading -- that depends only on fundamental physical\nquantities, and which accounts for the quantum speed limit, the fidelity and\nthe thermodynamic of the process. We test the protocol grading with classical\nand quantum protocols, and show that quantum protocols have higher protocol\ngrading than the classical ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2022 09:19:51 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 10:37:56 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wu", "Qiongyuan", ""], ["Ciampini", "Mario A.", ""], ["Paternostro", "Mauro", ""], ["Carlesso", "Matteo", ""]], "extracted_entities": [{"text": "quantum protocols", "label": "quantisation"}, {"text": "quantum protocols", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2301.00389", "submitter": "Zhi Yuan Wu", "authors": "Zhiyuan Wu, Sheng Sun, Yuwei Wang, Min Liu, Quyang Pan, Xuefeng Jiang,\n  Bo Gao", "title": "FedICT: Federated Multi-task Distillation for Multi-access Edge\n  Computing", "comments": "Accepted by IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS", "journal-ref": null, "doi": "10.1109/TPDS.2023.3289444", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest in intelligent services and privacy protection for\nmobile devices has given rise to the widespread application of federated\nlearning in Multi-access Edge Computing (MEC). Diverse user behaviors call for\npersonalized services with heterogeneous Machine Learning (ML) models on\ndifferent devices. Federated Multi-task Learning (FMTL) is proposed to train\nrelated but personalized ML models for different devices, whereas previous\nworks suffer from excessive communication overhead during training and neglect\nthe model heterogeneity among devices in MEC. Introducing knowledge\ndistillation into FMTL can simultaneously enable efficient communication and\nmodel heterogeneity among clients, whereas existing methods rely on a public\ndataset, which is impractical in reality. To tackle this dilemma, Federated\nMultI-task Distillation for Multi-access Edge CompuTing (FedICT) is proposed.\nFedICT direct local-global knowledge aloof during bi-directional distillation\nprocesses between clients and the server, aiming to enable multi-task clients\nwhile alleviating client drift derived from divergent optimization directions\nof client-side local models. Specifically, FedICT includes Federated Prior\nKnowledge Distillation (FPKD) and Local Knowledge Adjustment (LKA). FPKD is\nproposed to reinforce the clients' fitting of local data by introducing prior\nknowledge of local data distributions. Moreover, LKA is proposed to correct the\ndistillation loss of the server, making the transferred local knowledge better\nmatch the generalized representation. Experiments on three datasets show that\nFedICT significantly outperforms all compared benchmarks in various data\nheterogeneous and model architecture settings, achieving improved accuracy with\nless than 1.2% training communication overhead compared with FedAvg and no more\nthan 75% training communication round compared with FedGKT.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2023 11:50:58 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2023 14:33:46 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 08:43:49 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Wu", "Zhiyuan", ""], ["Sun", "Sheng", ""], ["Wang", "Yuwei", ""], ["Liu", "Min", ""], ["Pan", "Quyang", ""], ["Jiang", "Xuefeng", ""], ["Gao", "Bo", ""]], "extracted_entities": [{"text": "Federated Multi-task Learning", "label": "Few-shot Learning"}, {"text": "FMTL", "label": "Few-shot Learning"}, {"text": "Federated\nMultI-task Distillation", "label": "Knowledge distillation"}, {"text": "Federated Prior\nKnowledge Distillation", "label": "Knowledge distillation"}, {"text": "FPKD", "label": "Knowledge distillation"}], "human_readable_topic": "Wireless Networks and Federated Learning"}
{"id": "2301.07275", "submitter": "Yinqian Sun", "authors": "Yinqian Sun, Feifei Zhao, Zhuoya Zhao and Yi Zeng", "title": "Multi-compartment Neuron and Population Encoding Powered Spiking Neural\n  Network for Deep Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Inspired by the brain's information processing using binary spikes, spiking\nneural networks (SNNs) offer significant reductions in energy consumption and\nare more adept at incorporating multi-scale biological characteristics. In\nSNNs, spiking neurons serve as the fundamental information processing units.\nHowever, in most models, these neurons are typically simplified, focusing\nprimarily on the leaky integrate-and-fire (LIF) point neuron model while\nneglecting the structural properties of biological neurons. This simplification\nhampers the computational and learning capabilities of SNNs. In this paper, we\npropose a brain-inspired deep distributional reinforcement learning algorithm\nbased on SNNs, which integrates a bio-inspired multi-compartment neuron (MCN)\nmodel with a population coding approach. The proposed MCN model simulates the\nstructure and function of apical dendritic, basal dendritic, and somatic\ncompartments, achieving computational power comparable to that of biological\nneurons. Additionally, we introduce an implicit fractional embedding method\nbased on population coding of spiking neurons. We evaluated our model on Atari\ngames, and the experimental results demonstrate that it surpasses the vanilla\nFQF model, which utilizes traditional artificial neural networks (ANNs), as\nwell as the Spiking-FQF models that are based on ANN-to-SNN conversion methods.\nAblation studies further reveal that the proposed multi-compartment neuron\nmodel and the quantile fraction implicit population spike representation\nsignificantly enhance the performance of MCS-FQF while also reducing power\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2023 02:45:38 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 02:49:20 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Sun", "Yinqian", ""], ["Zhao", "Feifei", ""], ["Zhao", "Zhuoya", ""], ["Zeng", "Yi", ""]], "extracted_entities": [{"text": "implicit fractional embedding method", "label": "Embedding"}], "human_readable_topic": "Spiking Neural Networks for Image and Language Processing"}
{"id": "2301.09138", "submitter": "Raoul Heese", "authors": "Raoul Heese, Thore Gerlach, Sascha M\\\"ucke, Sabine M\\\"uller, Matthias\n  Jakobs, Nico Piatkowski", "title": "Explaining Quantum Circuits with Shapley Values: Towards Explainable\n  Quantum Machine Learning", "comments": "41 pages, 27 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods of artificial intelligence (AI) and especially machine learning (ML)\nhave been growing ever more complex, and at the same time have more and more\nimpact on people's lives. This leads to explainable AI (XAI) manifesting itself\nas an important research field that helps humans to better comprehend ML\nsystems. In parallel, quantum machine learning (QML) is emerging with the\nongoing improvement of quantum computing hardware combined with its increasing\navailability via cloud services. QML enables quantum-enhanced ML in which\nquantum mechanics is exploited to facilitate ML tasks, typically in the form of\nquantum-classical hybrid algorithms that combine quantum and classical\nresources. Quantum gates constitute the building blocks of gate-based quantum\nhardware and form circuits that can be used for quantum computations. For QML\napplications, quantum circuits are typically parameterized and their parameters\nare optimized classically such that a suitably defined objective function is\nminimized. Inspired by XAI, we raise the question of the explainability of such\ncircuits by quantifying the importance of (groups of) gates for specific goals.\nTo this end, we apply the well-established concept of Shapley values. The\nresulting attributions can be interpreted as explanations for why a specific\ncircuit works well for a given task, improving the understanding of how to\nconstruct parameterized (or variational) quantum circuits, and fostering their\nhuman interpretability in general. An experimental evaluation on simulators and\ntwo superconducting quantum hardware devices demonstrates the benefits of the\nproposed framework for classification, generative modeling, transpilation, and\noptimization. Furthermore, our results shed some light on the role of specific\ngates in popular QML approaches.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2023 15:17:12 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2023 06:27:20 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 13:02:59 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Heese", "Raoul", ""], ["Gerlach", "Thore", ""], ["M\u00fccke", "Sascha", ""], ["M\u00fcller", "Sabine", ""], ["Jakobs", "Matthias", ""], ["Piatkowski", "Nico", ""]], "extracted_entities": [{"text": "quantum mechanics", "label": "quantisation"}, {"text": "transpilation", "label": "Embedding"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2302.05742", "submitter": "Luciano Marzufero Ph.D.", "authors": "Fabio Bagagiolo, Rossana Capuani, Luciano Marzufero", "title": "A single player and a mass of agents: a pursuit evasion-like game", "comments": null, "journal-ref": "ESAIM: Control, Optimisation and Calculus of Variations, 30, 17\n  (2024)", "doi": "10.1051/cocv/2024009", "report-no": null, "categories": "math.OC math.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a finite-horizon differential game of pursuit-evasion like, between\na single player and a mass of agents. The player and the mass directly control\ntheir own evolution, which for the mass is given by a first order PDE of\ntransport equation type. Using also an adapted concept of non-anticipating\nstrategies, we derive an infinite dimensional Isaacs equation, and by dynamic\nprogramming techniques we prove that the value function is the unique viscosity\nsolution on a suitable invariant subset of a Hilbert space.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2023 16:48:31 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2024 12:31:55 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 21:05:06 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Bagagiolo", "Fabio", ""], ["Capuani", "Rossana", ""], ["Marzufero", "Luciano", ""]], "extracted_entities": [{"text": "first order PDE", "label": "BERT"}], "human_readable_topic": "Reinforcement Learning with Transformers"}
{"id": "2302.06239", "submitter": "Andrea Brugnoli", "authors": "Andrea Brugnoli, Ramy Rashad, Yi Zhang, Stefano Stramigioli", "title": "Finite element hybridization of port-Hamiltonian systems", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this contribution, we extend the hybridization framework for the Hodge\nLaplacian [Awanou et al., Hybridization and postprocessing in finite element\nexterior calculus, 2023] to port-Hamiltonian systems describing linear wave\npropagation phenomena. To this aim, a dual field mixed Galerkin discretization\nis introduced, in which one variable is approximated via conforming finite\nelement spaces, whereas the second is completely local. This scheme is\nequivalent to the second order mixed Galerkin formulation and retains a\ndiscrete power balance and discrete conservation laws. The mixed formulation is\nalso equivalent to the hybrid formulation. The hybrid system can be efficiently\nsolved using a static condensation procedure in discrete time. The size\nreduction achieved thanks to the hybridization is greater than the one obtained\nfor the Hodge Laplacian as one field is completely discarded. Numerical\nexperiments on the 3D wave and Maxwell equations show the convergence of the\nmethod and the size reduction achieved by the hybridization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2023 10:23:37 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2023 10:32:26 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2024 13:21:17 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 10:26:30 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Brugnoli", "Andrea", ""], ["Rashad", "Ramy", ""], ["Zhang", "Yi", ""], ["Stramigioli", "Stefano", ""]], "extracted_entities": [{"text": "discrete conservation laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2303.00245", "submitter": "Jennifer Wilson", "authors": "Jeremy Miller, Peter Patzt, and Jennifer C. H. Wilson", "title": "On rank filtrations of algebraic K-theory and Steinberg modules", "comments": "35 pages, 2 figures. Accepted at JEMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT math.KT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by his work on the stable rank filtration of algebraic K-theory\nspectra, Rognes defined a simplicial complex called the common basis complex\nand conjectured that this complex is highly connected for local rings and\nEuclidean domains. We prove this conjecture in the case of fields. Our methods\ngive a novel description of this common basis complex of a PID as an iterated\nbar construction on an equivariant monoid built out of Tits buildings. We also\nidentify the Koszul dual of a certain equivariant ring assembled out of\nSteinberg modules.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2023 05:56:39 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 04:08:38 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Miller", "Jeremy", ""], ["Patzt", "Peter", ""], ["Wilson", "Jennifer C. H.", ""]], "extracted_entities": [{"text": "Rognes", "label": "RoBERTa"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2303.09069", "submitter": "S. Ole Warnaar", "authors": "S. Ole Warnaar", "title": "An $\\mathrm{A}_2$ Bailey tree and $\\mathrm{A}_2^{(1)}$\n  Rogers-Ramanujan-type identities", "comments": "51 pages, key figure added to better explain the structure of the A_2\n  Bailey tree. JEMS, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math-ph math.MP math.NT math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\mathrm{A}_2$ Bailey chain of Andrews, Schilling and the author is\nextended to a four-parameter $\\mathrm{A}_2$ Bailey tree. As main application of\nthis tree, we prove the Kanade-Russell conjecture for a three-parameter family\nof Rogers-Ramanujan-type identities related to the principal characters of the\naffine Lie algebra $\\mathrm{A}_2^{(1)}$. Combined with known $q$-series\nresults, this further implies an $\\mathrm{A}_2^{(1)}$-analogue of the\ncelebrated Andrews-Gordon $q$-series identities. We also use the $\\mathrm{A}_2$\nBailey tree to prove a Rogers-Selberg-type identity for the characters of the\nprincipal subspaces of $\\mathrm{A}_2^{(1)}$ indexed by arbitrary level-$k$\ndominant integral weights $\\lambda$. This generalises a result of Feigin,\nFeigin, Jimbo, Miwa and Mukhin for $\\lambda=k\\Lambda_0$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2023 04:03:00 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2023 06:10:12 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 00:57:36 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Warnaar", "S. Ole", ""]], "extracted_entities": [{"text": "Andrews", "label": "ALBERT"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2303.10559", "submitter": "Kang Liao", "authors": "Kang Liao, Lang Nie, Shujuan Huang, Chunyu Lin, Jing Zhang, Yao Zhao,\n  Moncef Gabbouj, Dacheng Tao", "title": "Deep Learning for Camera Calibration and Beyond: A Survey", "comments": "Github repository:\n  https://github.com/KangLiao929/Awesome-Deep-Camera-Calibration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera calibration involves estimating camera parameters to infer geometric\nfeatures from captured sequences, which is crucial for computer vision and\nrobotics. However, conventional calibration is laborious and requires dedicated\ncollection. Recent efforts show that learning-based solutions have the\npotential to be used in place of the repeatability works of manual\ncalibrations. Among these solutions, various learning strategies, networks,\ngeometric priors, and datasets have been investigated. In this paper, we\nprovide a comprehensive survey of learning-based camera calibration techniques,\nby analyzing their strengths and limitations. Our main calibration categories\ninclude the standard pinhole camera model, distortion camera model, cross-view\nmodel, and cross-sensor model, following the research trend and extended\napplications. As there is no unified benchmark in this community, we collect a\nholistic calibration dataset that can serve as a public platform to evaluate\nthe generalization of existing methods. It comprises both synthetic and\nreal-world data, with images and videos captured by different cameras in\ndiverse scenes. Toward the end of this paper, we discuss the challenges and\nprovide further research directions. To our knowledge, this is the first survey\nfor the learning-based camera calibration (spanned 10 years). The summarized\nmethods, datasets, and benchmarks are available and will be regularly updated\nat https://github.com/KangLiao929/Awesome-Deep-Camera-Calibration.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2023 04:00:05 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2024 08:57:38 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 02:40:11 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Liao", "Kang", ""], ["Nie", "Lang", ""], ["Huang", "Shujuan", ""], ["Lin", "Chunyu", ""], ["Zhang", "Jing", ""], ["Zhao", "Yao", ""], ["Gabbouj", "Moncef", ""], ["Tao", "Dacheng", ""]], "extracted_entities": [{"text": "standard pinhole camera model", "label": "AI model"}, {"text": "distortion camera model", "label": "AI model"}, {"text": "cross-view\nmodel", "label": "AI model"}, {"text": "cross-sensor model", "label": "AI model"}], "human_readable_topic": "6D Object Pose Estimation in Robotics"}
{"id": "2303.14731", "submitter": "Mrinal Kanti Roychowdhury", "authors": "Amit Priyadarshi, Mrinal K. Roychowdhury, Manuj Verma", "title": "Quantization dimensions for inhomogeneous bi-Lipschitz Iterated Function\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $\\nu$ be a Borel probability measure on a $d$-dimensional Euclidean space\n$\\mathbb{R}^d$, $d\\geq 1$, with a compact support, and let $(p_0, p_1, p_2,\n\\ldots, p_N)$ be a probability vector with $p_j>0$ for $0\\leq j\\leq N$. Let\n$\\{S_j: 1\\leq j\\leq N\\}$ be a set of contractive mappings on $\\mathbb{R}^d$.\nThen, a Borel probability measure $\\mu$ on $\\mathbb R^d$ such that\n$\\mu=\\sum_{j=1}^N p_j\\mu\\circ S_j^{-1}+p_0\\nu$ is called an inhomogeneous\nmeasure, also known as a condensation measure on $\\mathbb{R}^d$. For a given\n$r\\in (0, +\\infty)$, the quantization dimension of order $r$, if it exists,\ndenoted by $D_r(\\mu)$, of a Borel probability measure $\\mu$ on $\\mathbb{R}^d$\nrepresents the speed at which the $n$th quantization error of order $r$\napproaches to zero as the number of elements $n$ in an optimal set of $n$-means\nfor $\\mu$ tends to infinity. In this paper, we investigate the quantization\ndimension for such a condensation measure.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2023 14:22:15 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 18:46:48 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Priyadarshi", "Amit", ""], ["Roychowdhury", "Mrinal K.", ""], ["Verma", "Manuj", ""]], "extracted_entities": [{"text": "quantization dimension", "label": "quantisation"}, {"text": "quantization\ndimension", "label": "quantisation"}], "human_readable_topic": "Quantization and Manifold Embeddings"}
{"id": "2305.06075", "submitter": "Mario Rom\\'an", "authors": "Mario Rom\\'an, Pawe{\\l} Soboci\\'nski", "title": "String Diagrams for Premonoidal Categories", "comments": "20 pages. Fixes typos and adds new examples. Extended version of the\n  first chapters of 'Promonads and String Diagrams for Effectful Categories'\n  from the first-named author, arXiv:2205.07664, presented at Applied Category\n  Theory 2022", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Premonoidal categories are monoidal categories without the interchange law\nwhile effectful categories are premonoidal categories with a chosen monoidal\nsubcategory of interchanging morphisms. In the same sense that string diagrams,\npioneered by Joyal and Street, are an internal language for monoidal\ncategories, we show that string diagrams with an added \"runtime object\",\npioneered by Alan Jeffrey, are an internal language for effectful categories\nand can be used as string diagrams for effectful, premonoidal, and Freyd\ncategories.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2023 11:55:41 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2024 16:20:26 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 17:15:28 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Rom\u00e1n", "Mario", ""], ["Soboci\u0144ski", "Pawe\u0142", ""]], "extracted_entities": [{"text": "string diagrams", "label": "Embedding"}, {"text": "string diagrams", "label": "Embedding"}], "human_readable_topic": "Legal Language Models Evaluation"}
{"id": "2305.14749", "submitter": "Chaitanya K. Joshi", "authors": "Chaitanya K. Joshi, Arian R. Jamasb, Ramon Vi\\~nas, Charles Harris,\n  Simon V. Mathis, Alex Morehead, Rishabh Anand, Pietro Li\\`o", "title": "gRNAde: Geometric Deep Learning for 3D RNA inverse design", "comments": "ICLR 2025 camera-ready version (Spotlight presentation). Previously\n  titled 'Multi-State RNA Design with Geometric Multi-Graph Neural Networks',\n  presented at ICML 2023 Computational Biology Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational RNA design tasks are often posed as inverse problems, where\nsequences are designed based on adopting a single desired secondary structure\nwithout considering 3D conformational diversity. We introduce gRNAde, a\ngeometric RNA design pipeline operating on 3D RNA backbones to design sequences\nthat explicitly account for structure and dynamics. gRNAde uses a multi-state\nGraph Neural Network and autoregressive decoding to generates candidate RNA\nsequences conditioned on one or more 3D backbone structures where the\nidentities of the bases are unknown. On a single-state fixed backbone re-design\nbenchmark of 14 RNA structures from the PDB identified by Das et al. (2010),\ngRNAde obtains higher native sequence recovery rates (56% on average) compared\nto Rosetta (45% on average), taking under a second to produce designs compared\nto the reported hours for Rosetta. We further demonstrate the utility of gRNAde\non a new benchmark of multi-state design for structurally flexible RNAs, as\nwell as zero-shot ranking of mutational fitness landscapes in a retrospective\nanalysis of a recent ribozyme. Experimental wet lab validation on 10 different\nstructured RNA backbones finds that gRNAde has a success rate of 50% at\ndesigning pseudoknotted RNA structures, a significant advance over 35% for\nRosetta. Open source code and tutorials are available at:\nhttps://github.com/chaitjo/geometric-rna-design\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2023 05:46:56 GMT"}, {"version": "v2", "created": "Thu, 25 May 2023 14:53:11 GMT"}, {"version": "v3", "created": "Sun, 28 May 2023 22:44:27 GMT"}, {"version": "v4", "created": "Sun, 31 Mar 2024 10:03:17 GMT"}, {"version": "v5", "created": "Sat, 25 May 2024 23:11:45 GMT"}, {"version": "v6", "created": "Sun, 6 Oct 2024 06:39:41 GMT"}, {"version": "v7", "created": "Tue, 25 Feb 2025 08:17:35 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Joshi", "Chaitanya K.", ""], ["Jamasb", "Arian R.", ""], ["Vi\u00f1as", "Ramon", ""], ["Harris", "Charles", ""], ["Mathis", "Simon V.", ""], ["Morehead", "Alex", ""], ["Anand", "Rishabh", ""], ["Li\u00f2", "Pietro", ""]], "extracted_entities": [{"text": "zero-shot ranking", "label": "Zero-shot Learning"}], "human_readable_topic": "Molecular and Protein Representation Learning"}
{"id": "2305.16735", "submitter": "Xiaochun Meng", "authors": "James W. Taylor and Xiaochun Meng", "title": "Angular Combining of Forecasts of Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When multiple forecasts are available for a probability distribution,\nforecast combining enables a pragmatic synthesis of the information to extract\nthe wisdom of the crowd. The linear opinion pool has been widely used, whereby\nthe combining is applied to the probabilities of the distributional forecasts.\nHowever, it has been argued that this will tend to deliver overdispersed\ndistributions, prompting the combination to be applied, instead, to the\nquantiles of the distributional forecasts. Results from different applications\nare mixed, leaving it as an empirical question whether to combine probabilities\nor quantiles. In this paper, we present an alternative approach. Looking at the\ndistributional forecasts, combining the probabilities can be viewed as vertical\ncombining, with quantile combining seen as horizontal combining. Our proposal\nis to allow combining to take place on an angle between the extreme cases of\nvertical and horizontal combining. We term this angular combining. The angle is\na parameter that can be optimized using a proper scoring rule. For\nimplementation, we provide a pragmatic numerical approach and a simulation\nalgorithm. Among our theoretical results, we show that, as with vertical and\nhorizontal averaging, angular averaging results in a distribution with mean\nequal to the average of the means of the distributions that are being combined.\nWe also show that angular averaging produces a distribution with lower variance\nthan vertical averaging, and, under certain assumptions, greater variance than\nhorizontal averaging. We provide empirical results for distributional forecasts\nof Covid mortality, macroeconomic survey data, and electricity prices.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2023 08:38:44 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 00:30:25 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Taylor", "James W.", ""], ["Meng", "Xiaochun", ""]], "extracted_entities": [{"text": "prompting", "label": "Prompting"}], "human_readable_topic": "Time Series Prediction and Forecasting Models"}
{"id": "2305.18002", "submitter": "Kristian Uldall Kristiansen", "authors": "K. U. Kristiansen, A. H. Sarantaris", "title": "On a tropicalization of planar polynomial ODEs with finitely many\n  structurally stable phase portraits", "comments": "Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, concepts from the emerging field of tropical geometry have been\nused to identify different scaling regimes in chemical reaction networks where\ndimension reduction may take place. In this paper, we try to formalize these\nideas further in the context of planar polynomial ODEs. In particular, we\ndevelop a theory of a tropical dynamical system, based upon a differential\ninclusion, that has a set of discontinuities on a subset of the associated\ntropical curve. The development is inspired by an approach of Peter Szmolyan\nthat uses the connection of tropical geometry with logarithmic paper. In this\npaper, we define a phaseportrait, a notion of equivalence and characterize\nstructural stability. Furthermore, we demonstrate the results on several\nexamples, including a(n) (generalized) autocatalator model. Our main result is\nthat there are finitely many equivalence classes of structurally stable phase\nportraits and we enumerate these ($15$ in total) in the context of the\ngeneralized autocatalator model. We believe that the property of finitely many\nstructurally stable phase portraits underlines the potential of the tropical\napproach, also in higher dimension, as a method to obtain and identify skeleton\nmodels in chemical reaction networks in extreme parameter regimes.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2023 10:25:56 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2023 18:09:36 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 09:50:19 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Kristiansen", "K. U.", ""], ["Sarantaris", "A. H.", ""]], "extracted_entities": [{"text": "generalized autocatalator model", "label": "AI model"}], "human_readable_topic": "Symbolic Regression and Equation Discovery"}
{"id": "2305.18564", "submitter": "Amru Hussein", "authors": "Hind Al Baba, Bilal Al Taki, Amru Hussein", "title": "Remark on the local well-posedness of compressible non-Newtonian fluids\n  with initial vacuum", "comments": "17 pages", "journal-ref": null, "doi": "10.1007/s00021-024-00901-3", "report-no": null, "categories": "math.AP math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss in this short note the local-in-time strong well-posedness of the\ncompressible Navier-Stokes system for non-Newtonian fluids on the three\ndimensional torus. We show that the result established recently by Kalousek,\nM\\'{a}cha, and Ne\\v{c}asova in \\doi{10.1007/s00208-021-02301-8} can be extended\nto the case where vanishing density is allowed initially. Our proof builds on\nthe framework developed by Cho, Choe, and Kim in\n\\doi{10.1016/j.matpur.2003.11.004} for compressible Navier-Stokes equations in\nthe case of Newtonian fluids. To adapt their method, special attention is given\nto the elliptic regularity of a challenging nonlinear elliptic system. We show\nparticular results in this direction, however, the main result of this paper is\nproven in the general case when elliptic $W^{2,p}$-regularity is imposed as an\nassumption. Also, we give a finite time blow-up criterion.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2023 18:54:32 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2023 10:38:08 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2024 09:15:17 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 14:33:14 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Baba", "Hind Al", ""], ["Taki", "Bilal Al", ""], ["Hussein", "Amru", ""]], "extracted_entities": [{"text": "special attention", "label": "Attention mechanism"}], "human_readable_topic": "Fractional Sobolev Embeddings"}
{"id": "2306.00396", "submitter": "Qihang Fan", "authors": "Qihang Fan and Huaibo Huang and Xiaoqiang Zhou and Ran He", "title": "Lightweight Vision Transformer with Bidirectional Interaction", "comments": "The paper is accepted by NeurIPS2023", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in vision backbones have significantly improved their\nperformance by simultaneously modeling images' local and global contexts.\nHowever, the bidirectional interaction between these two contexts has not been\nwell explored and exploited, which is important in the human visual system.\nThis paper proposes a Fully Adaptive Self-Attention (FASA) mechanism for vision\ntransformer to model the local and global information as well as the\nbidirectional interaction between them in context-aware ways. Specifically,\nFASA employs self-modulated convolutions to adaptively extract local\nrepresentation while utilizing self-attention in down-sampled space to extract\nglobal representation. Subsequently, it conducts a bidirectional adaptation\nprocess between local and global representation to model their interaction. In\naddition, we introduce a fine-grained downsampling strategy to enhance the\ndown-sampled self-attention mechanism for finer-grained global perception\ncapability. Based on FASA, we develop a family of lightweight vision backbones,\nFully Adaptive Transformer (FAT) family. Extensive experiments on multiple\nvision tasks demonstrate that FAT achieves impressive performance. Notably, FAT\naccomplishes a 77.6% accuracy on ImageNet-1K using only 4.5M parameters and\n0.7G FLOPs, which surpasses the most advanced ConvNets and Transformers with\nsimilar model size and computational costs. Moreover, our model exhibits faster\nspeed on modern GPU compared to other models. Code will be available at\nhttps://github.com/qhfan/FAT.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2023 06:56:41 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 03:16:17 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Fan", "Qihang", ""], ["Huang", "Huaibo", ""], ["Zhou", "Xiaoqiang", ""], ["He", "Ran", ""]], "extracted_entities": [{"text": "Fully Adaptive Self-Attention (FASA)", "label": "Attention mechanism"}, {"text": "self-attention", "label": "Attention mechanism"}, {"text": "down-sampled self-attention mechanism", "label": "Attention mechanism"}, {"text": "FASA", "label": "Attention mechanism"}, {"text": "Transformers", "label": "Transformers"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2306.00693", "submitter": "Ning Ding", "authors": "Ning Ding, Yehui Tang, Zhongqian Fu, Chao Xu, Kai Han, Yunhe Wang", "title": "GPT4Image: Large Pre-trained Models Help Vision Models Learn Better on\n  Perception Task", "comments": "GitHub:\n  https://github.com/huawei-noah/Efficient-Computing/tree/master/GPT4Image/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upsurge in pre-trained large models started by ChatGPT has swept across\nthe entire deep learning community. Such powerful models demonstrate advanced\ngenerative ability and multimodal understanding capability, which quickly set\nnew state of the arts on a variety of benchmarks. The pre-trained LLM usually\nplays the role as a universal AI model that can conduct various tasks like\narticle analysis and image comprehension. However, due to the prohibitively\nhigh memory and computational cost of implementing such a large model, the\nconventional models (such as CNN and ViT) are still essential for many visual\nperception tasks. In this paper, we propose to enhance the representation\nability of ordinary vision models on perception tasks (e.g. image\nclassification) by taking advantage of the off-the-shelf large pre-trained\nmodels. We present a new learning framework, dubbed GPT4Image, where the\nknowledge of the large pre-trained models are extracted to help CNNs and ViTs\nlearn better representations and achieve higher performance. Firstly, we curate\na high quality description set by prompting a multimodal LLM to generate\ndescriptions for training images. Then, these detailed descriptions are fed\ninto a pre-trained encoder to extract text embeddings that encodes the rich\nsemantics of images. During training, text embeddings will serve as extra\nsupervising signal and be aligned with image representations learned by vision\nmodels. The alignment process helps vision models achieve better performance\nwith the aid of pre-trained LLMs. We conduct extensive experiments to verify\nthe effectiveness of the proposed algorithm on various visual perception tasks\nfor heterogeneous model architectures.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2023 14:02:45 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2023 13:59:25 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 12:49:05 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Ding", "Ning", ""], ["Tang", "Yehui", ""], ["Fu", "Zhongqian", ""], ["Xu", "Chao", ""], ["Han", "Kai", ""], ["Wang", "Yunhe", ""]], "extracted_entities": [{"text": "ChatGPT", "label": "ChatGPT"}, {"text": "GPT4Image", "label": "GPT"}, {"text": "prompting", "label": "Prompting"}, {"text": "text embeddings", "label": "Embedding"}, {"text": "text embeddings", "label": "Embedding"}], "human_readable_topic": "Video Understanding with Large Multimodal Models"}
{"id": "2306.04347", "submitter": "Andreas Opedal", "authors": "Andreas Opedal, Niklas Stoehr, Abulhair Saparov, Mrinmaya Sachan", "title": "World Models for Math Story Problems", "comments": "ACL Findings 2023", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Solving math story problems is a complex task for students and NLP models\nalike, requiring them to understand the world as described in the story and\nreason over it to compute an answer. Recent years have seen impressive\nperformance on automatically solving these problems with large pre-trained\nlanguage models and innovative techniques to prompt them. However, it remains\nunclear if these models possess accurate representations of mathematical\nconcepts. This leads to lack of interpretability and trustworthiness which\nimpedes their usefulness in various applications. In this paper, we consolidate\nprevious work on categorizing and representing math story problems and develop\nMathWorld, which is a graph-based semantic formalism specific for the domain of\nmath story problems. With MathWorld, we can assign world models to math story\nproblems which represent the situations and actions introduced in the text and\ntheir mathematical relationships. We combine math story problems from several\nexisting datasets and annotate a corpus of 1,019 problems and 3,204 logical\nforms with MathWorld. Using this data, we demonstrate the following use cases\nof MathWorld: (1) prompting language models with synthetically generated\nquestion-answer pairs to probe their reasoning and world modeling abilities,\nand (2) generating new problems by using the world models as a design space.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2023 11:25:20 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 10:11:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Opedal", "Andreas", ""], ["Stoehr", "Niklas", ""], ["Saparov", "Abulhair", ""], ["Sachan", "Mrinmaya", ""]], "extracted_entities": [{"text": "prompting", "label": "Prompting"}], "human_readable_topic": "Reasoning and Problem Solving with Large Language Models"}
{"id": "2306.09617", "submitter": "Sheryl Melara-Duron", "authors": "Sheryl Melara-Duron, R. Gait\\'an, J. M. Lamprea", "title": "Two dark matter candidates in a doublet-triplet Higgs model", "comments": "22 pages, 8 figures, published version", "journal-ref": "Eur. Phys. J. Plus 140, 154(2025)", "doi": "10.1140/epjp/s13360-025-06099-1", "report-no": null, "categories": "hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a Standard Model extension that provides a bicomponent dark matter\nscenario as well as a mechanism for the generation of left-handed neutrino\nmasses. We extend the Standard Model scalar sector by adding an inert $SU(2)_L$\ndoublet with hypercharge $Y= 1/2$ and a triplet with hypercharge $Y=0$. These\nscalars provide dark matter candidates in two dark sectors stabilised by\ndiscrete symmetries.\n  We consider the contribution of both candidates to the total relic abundance\nin order to recover the desert regions in their standard alone cases. In\naddition, we add an active scalar $SU(2)_L$ triplet with hypercharge $Y=1$ in\norder to generate light neutrino masses. We analyse the results of dark matter\nphenomenology for the model and the neutrino mass generation through the\ntype-II seesaw mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2023 04:15:00 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2023 21:43:45 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 17:18:34 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Melara-Duron", "Sheryl", ""], ["Gait\u00e1n", "R.", ""], ["Lamprea", "J. M.", ""]], "extracted_entities": [{"text": "Standard Model", "label": "Foundation Model"}, {"text": "Standard Model", "label": "Foundation Model"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2307.04996", "submitter": "Shovon Sengupta", "authors": "Ghanshyam Verma, Shovon Sengupta, Simon Simanta, Huan Chen, Janos A.\n  Perge, Devishree Pillai, John P. McCrae, Paul Buitelaar", "title": "Empowering recommender systems using automatically generated Knowledge\n  Graphs and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personalized recommender systems play a crucial role in direct marketing,\nparticularly in financial services, where delivering relevant content can\nenhance customer engagement and promote informed decision-making. This study\nexplores interpretable knowledge graph (KG)-based recommender systems by\nproposing two distinct approaches for personalized article recommendations\nwithin a multinational financial services firm. The first approach leverages\nReinforcement Learning (RL) to traverse a KG constructed from both structured\n(tabular) and unstructured (textual) data, enabling interpretability through\nPath Directed Reasoning (PDR). The second approach employs the XGBoost\nalgorithm, with post-hoc explainability techniques such as SHAP and ELI5 to\nenhance transparency. By integrating machine learning with automatically\ngenerated KGs, our methods not only improve recommendation accuracy but also\nprovide interpretable insights, facilitating more informed decision-making in\ncustomer relationship management.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2023 03:24:54 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 05:03:54 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Verma", "Ghanshyam", ""], ["Sengupta", "Shovon", ""], ["Simanta", "Simon", ""], ["Chen", "Huan", ""], ["Perge", "Janos A.", ""], ["Pillai", "Devishree", ""], ["McCrae", "John P.", ""], ["Buitelaar", "Paul", ""]], "extracted_entities": [{"text": "Reinforcement Learning", "label": "Few-shot Learning"}], "human_readable_topic": "Personalized Recommendation Systems"}
{"id": "2307.08423", "submitter": "Xuan Zhang", "authors": "Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen\n  Xie, Meng Liu, Yuchao Lin, Zhao Xu, Keqiang Yan, Keir Adams, Maurice Weiler,\n  Xiner Li, Tianfan Fu, Yucheng Wang, Alex Strasser, Haiyang Yu, YuQing Xie,\n  Xiang Fu, Shenglong Xu, Yi Liu, Yuanqi Du, Alexandra Saxton, Hongyi Ling,\n  Hannah Lawrence, Hannes St\\\"ark, Shurui Gui, Carl Edwards, Nicholas Gao,\n  Adriana Ladera, Tailin Wu, Elyssa F. Hofgard, Aria Mansouri Tehrani, Rui\n  Wang, Ameya Daigavane, Montgomery Bohde, Jerry Kurtin, Qian Huang, Tuong\n  Phung, Minkai Xu, Chaitanya K. Joshi, Simon V. Mathis, Kamyar\n  Azizzadenesheli, Ada Fang, Al\\'an Aspuru-Guzik, Erik Bekkers, Michael\n  Bronstein, Marinka Zitnik, Anima Anandkumar, Stefano Ermon, Pietro Li\\`o,\n  Rose Yu, Stephan G\\\"unnemann, Jure Leskovec, Heng Ji, Jimeng Sun, Regina\n  Barzilay, Tommi Jaakkola, Connor W. Coley, Xiaoning Qian, Xiaofeng Qian, Tess\n  Smidt, Shuiwang Ji", "title": "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in artificial intelligence (AI) are fueling a new paradigm of\ndiscoveries in natural sciences. Today, AI has started to advance natural\nsciences by improving, accelerating, and enabling our understanding of natural\nphenomena at a wide range of spatial and temporal scales, giving rise to a new\narea of research known as AI for science (AI4Science). Being an emerging\nresearch paradigm, AI4Science is unique in that it is an enormous and highly\ninterdisciplinary area. Thus, a unified and technical treatment of this field\nis needed yet challenging. This work aims to provide a technically thorough\naccount of a subarea of AI4Science; namely, AI for quantum, atomistic, and\ncontinuum systems. These areas aim at understanding the physical world from the\nsubatomic (wavefunctions and electron density), atomic (molecules, proteins,\nmaterials, and interactions), to macro (fluids, climate, and subsurface) scales\nand form an important subarea of AI4Science. A unique advantage of focusing on\nthese areas is that they largely share a common set of challenges, thereby\nallowing a unified and foundational treatment. A key common challenge is how to\ncapture physics first principles, especially symmetries, in natural systems by\ndeep learning methods. We provide an in-depth yet intuitive account of\ntechniques to achieve equivariance to symmetry transformations. We also discuss\nother common technical challenges, including explainability,\nout-of-distribution generalization, knowledge transfer with foundation and\nlarge language models, and uncertainty quantification. To facilitate learning\nand education, we provide categorized lists of resources that we found to be\nuseful. We strive to be thorough and unified and hope this initial effort may\ntrigger more community interests and efforts to further advance AI4Science.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2023 12:14:14 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2023 18:25:03 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2024 15:56:41 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 18:45:58 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhang", "Xuan", ""], ["Wang", "Limei", ""], ["Helwig", "Jacob", ""], ["Luo", "Youzhi", ""], ["Fu", "Cong", ""], ["Xie", "Yaochen", ""], ["Liu", "Meng", ""], ["Lin", "Yuchao", ""], ["Xu", "Zhao", ""], ["Yan", "Keqiang", ""], ["Adams", "Keir", ""], ["Weiler", "Maurice", ""], ["Li", "Xiner", ""], ["Fu", "Tianfan", ""], ["Wang", "Yucheng", ""], ["Strasser", "Alex", ""], ["Yu", "Haiyang", ""], ["Xie", "YuQing", ""], ["Fu", "Xiang", ""], ["Xu", "Shenglong", ""], ["Liu", "Yi", ""], ["Du", "Yuanqi", ""], ["Saxton", "Alexandra", ""], ["Ling", "Hongyi", ""], ["Lawrence", "Hannah", ""], ["St\u00e4rk", "Hannes", ""], ["Gui", "Shurui", ""], ["Edwards", "Carl", ""], ["Gao", "Nicholas", ""], ["Ladera", "Adriana", ""], ["Wu", "Tailin", ""], ["Hofgard", "Elyssa F.", ""], ["Tehrani", "Aria Mansouri", ""], ["Wang", "Rui", ""], ["Daigavane", "Ameya", ""], ["Bohde", "Montgomery", ""], ["Kurtin", "Jerry", ""], ["Huang", "Qian", ""], ["Phung", "Tuong", ""], ["Xu", "Minkai", ""], ["Joshi", "Chaitanya K.", ""], ["Mathis", "Simon V.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Fang", "Ada", ""], ["Aspuru-Guzik", "Al\u00e1n", ""], ["Bekkers", "Erik", ""], ["Bronstein", "Michael", ""], ["Zitnik", "Marinka", ""], ["Anandkumar", "Anima", ""], ["Ermon", "Stefano", ""], ["Li\u00f2", "Pietro", ""], ["Yu", "Rose", ""], ["G\u00fcnnemann", "Stephan", ""], ["Leskovec", "Jure", ""], ["Ji", "Heng", ""], ["Sun", "Jimeng", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""], ["Coley", "Connor W.", ""], ["Qian", "Xiaoning", ""], ["Qian", "Xiaofeng", ""], ["Smidt", "Tess", ""], ["Ji", "Shuiwang", ""]], "extracted_entities": [{"text": "uncertainty quantification", "label": "quantisation"}], "human_readable_topic": "AI-Driven Scientific Discovery and Automation"}
{"id": "2307.09762", "submitter": "Abhishek Ajayakumar", "authors": "Abhishek Ajayakumar, Soumyendu Raha", "title": "Improving Surrogate Model Robustness to Perturbations for Dynamical\n  Systems Through Machine Learning and Data Assimilation", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world systems are modelled using complex ordinary differential\nequations (ODEs). However, the dimensionality of these systems can make them\nchallenging to analyze. Dimensionality reduction techniques like Proper\nOrthogonal Decomposition (POD) can be used in such cases. However, these\nreduced order models are susceptible to perturbations in the input. We propose\na novel framework that combines machine learning and data assimilation\ntechniques to improving surrogate models to handle perturbations in input data\neffectively. Through rigorous experiments on dynamical systems modelled on\ngraphs, we demonstrate that our framework substantially improves the accuracy\nof surrogate models under input perturbations. Furthermore, we evaluate the\nframework's efficacy on alternative surrogate models, including neural ODEs,\nand the empirical results consistently show enhanced performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2023 05:45:05 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2023 14:09:43 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 16:27:20 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Ajayakumar", "Abhishek", ""], ["Raha", "Soumyendu", ""]], "extracted_entities": [{"text": "machine learning", "label": "Few-shot Learning"}], "human_readable_topic": "Manifold Learning and Dimensionality Reduction"}
{"id": "2307.10067", "submitter": "Philipp Gersing", "authors": "Philipp Gersing and Matteo Barigozzi and Christoph Rust and Manfred\n  Deistler", "title": "The Canonical Decomposition of Factor Models: Weak Factors are\n  Everywhere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two approaches to time series approximate factor models: the static\nfactor model, where the factors are loaded contemporaneously by the common\ncomponent, and the Generalised Dynamic Factor Model, where the factors are\nloaded with lags. In this paper we derive a canonical decomposition which nests\nboth models by introducing the weak common component which is the difference\nbetween the dynamic- and the static common component. Such component is driven\nby potentially infinitely many non-pervasive weak factors which live in the\ndynamically common space (not to be confused with rate-weak factors, being\npervasive but associated with a slower rate). Our result shows that the\nrelation between the two approaches is far more rich and complex than what\nusually assumed. We exemplify why the weak common component shall not be\nneglected by means of theoretical and empirical examples. Furthermore, we\npropose a simple estimation procedure for the canonical decomposition. Our\nempirical estimates on US macroeconomic data reveal that the weak common\ncomponent can account for a large part of the variation of individual\nvariables. Furthermore in a pseudo real-time forecasting evaluation for\nindustrial production and inflation, we show that gains can be obtained from\nconsidering the dynamic approach over the static approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2023 23:08:49 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2024 15:49:18 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 16:11:03 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Gersing", "Philipp", ""], ["Barigozzi", "Matteo", ""], ["Rust", "Christoph", ""], ["Deistler", "Manfred", ""]], "extracted_entities": [{"text": "Generalised Dynamic Factor Model", "label": "AI model"}], "human_readable_topic": "Time Series Prediction and Forecasting Models"}
{"id": "2307.13658", "submitter": "Nicholas Perello", "authors": "Przemyslaw Grabowicz, Adrian Byrne, Cyrus Cousins, Nicholas Perello,\n  Yair Zick", "title": "Towards an AI Accountability Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose establishing an office to oversee AI systems by introducing a\ntiered system of explainability and benchmarking requirements for commercial AI\nsystems. We examine how complex high-risk technologies have been successfully\nregulated at the national level. Specifically, we draw parallels to the\nexisting regulation for the U.S. medical device industry and the pharmaceutical\nindustry (regulated by the FDA), the proposed legislation for AI in the\nEuropean Union (the AI Act), and the existing U.S. anti-discrimination\nlegislation. To promote accountability and user trust, AI accountability\nmechanisms shall introduce standarized measures for each category of intended\nhigh-risk use of AI systems to enable structured comparisons among such AI\nsystems. We suggest using explainable AI techniques, such as input influence\nmeasures, as well as fairness statistics and other performance measures of\nhigh-risk AI systems. We propose to standardize internal benchmarking and\nautomated audits to transparently characterize high-risk AI systems. The\nresults of such audits and benchmarks shall be clearly and transparently\ncommunicated and explained to enable meaningful comparisons of competing AI\nsystems via a public AI registry. Such standardized audits, benchmarks, and\ncertificates shall be specific to intended high-risk use of respective AI\nsystems and could constitute conformity assessment for AI systems, e.g., in the\nEuropean Union's AI Act.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2023 17:09:28 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 18:17:19 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Grabowicz", "Przemyslaw", ""], ["Byrne", "Adrian", ""], ["Cousins", "Cyrus", ""], ["Perello", "Nicholas", ""], ["Zick", "Yair", ""]], "extracted_entities": [{"text": "AI Act", "label": "AI Ethics"}, {"text": "AI accountability\nmechanisms", "label": "AI Ethics"}, {"text": "fairness statistics", "label": "Model Bias and Fairness"}, {"text": "AI Act", "label": "AI Ethics"}], "human_readable_topic": "Cybersecurity Risks and Vulnerabilities in AI Models"}
{"id": "2308.01134", "submitter": "Farzin Salek", "authors": "Farzin Salek, Andreas Winter", "title": "New Protocols for Conference Key and Multipartite Entanglement\n  Distillation", "comments": "Final version accepted with journal", "journal-ref": null, "doi": "10.1109/TIT.2025.3546794", "report-no": null, "categories": "quant-ph cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach two interconnected problems of quantum information processing in\nnetworks: Conference key agreement and entanglement distillation, both in the\nso-called source model where the given resource is a multipartite quantum state\nand the players interact over public classical channels to generate the desired\ncorrelation. The first problem is the distillation of a conference key when the\nsource state is shared between a number of legal players and an eavesdropper;\nthe eavesdropper, apart from starting off with this quantum side information,\nalso observes the public communication between the players. The second is the\ndistillation of Greenberger-Horne-Zeilinger (GHZ) states by means of local\noperations and classical communication (LOCC) from the given mixed state. These\nproblem settings extend our previous paper [IEEE Trans. Inf. Theory\n68(2):976-988, 2022], and we generalise its results: using a quantum version of\nthe task of communication for omniscience, we derive novel lower bounds on the\ndistillable conference key from any multipartite quantum state by means of\nnon-interacting communication protocols. Secondly, we establish novel lower\nbounds on the yield of GHZ states from multipartite mixed states. Namely, we\npresent two methods to produce bipartite entanglement between sufficiently many\nnodes so as to produce GHZ states. Next, we show that the conference key\nagreement protocol can be made coherent under certain conditions, enabling the\ndirect generation of multipartite GHZ states.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2023 13:23:29 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:46:59 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Salek", "Farzin", ""], ["Winter", "Andreas", ""]], "extracted_entities": [{"text": "entanglement distillation", "label": "Knowledge distillation"}, {"text": "distillation", "label": "Knowledge distillation"}, {"text": "bipartite entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2308.09372", "submitter": "Tobias Nauen", "authors": "Tobias Christian Nauen, Sebastian Palacio, Federico Raue, Andreas\n  Dengel", "title": "Which Transformer to Favor: A Comparative Analysis of Efficiency in\n  Vision Transformers", "comments": "v3: new models, analysis of scaling behaviors; v4: WACV 2025 camera\n  ready version, appendix added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention in Transformers comes with a high computational cost because\nof their quadratic computational complexity, but their effectiveness in\naddressing problems in language and vision has sparked extensive research aimed\nat enhancing their efficiency. However, diverse experimental conditions,\nspanning multiple input domains, prevent a fair comparison based solely on\nreported results, posing challenges for model selection. To address this gap in\ncomparability, we perform a large-scale benchmark of more than 45 models for\nimage classification, evaluating key efficiency aspects, including accuracy,\nspeed, and memory usage. Our benchmark provides a standardized baseline for\nefficiency-oriented transformers. We analyze the results based on the Pareto\nfront -- the boundary of optimal models. Surprisingly, despite claims of other\nmodels being more efficient, ViT remains Pareto optimal across multiple\nmetrics. We observe that hybrid attention-CNN models exhibit remarkable\ninference memory- and parameter-efficiency. Moreover, our benchmark shows that\nusing a larger model in general is more efficient than using higher resolution\nimages. Thanks to our holistic evaluation, we provide a centralized resource\nfor practitioners and researchers, facilitating informed decisions when\nselecting or developing efficient transformers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2023 08:06:49 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2024 09:21:33 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2024 10:44:53 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 10:51:07 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Nauen", "Tobias Christian", ""], ["Palacio", "Sebastian", ""], ["Raue", "Federico", ""], ["Dengel", "Andreas", ""]], "extracted_entities": [{"text": "Self-attention", "label": "Attention mechanism"}, {"text": "Transformers", "label": "Transformers"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2308.12219", "submitter": "Jiasheng Ye", "authors": "Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu", "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and\n  Instruction-Finetuning", "comments": "add results on reasoning and multimodality; add discussions on latest\n  progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent surge of generative AI has been fueled by the generative power of\ndiffusion probabilistic models and the scalable capabilities of large language\nmodels. Despite their potential, it remains elusive whether diffusion language\nmodels can solve general language tasks comparable to their autoregressive\ncounterparts. This paper demonstrates that scaling diffusion models w.r.t.\ndata, sizes, and tasks can effectively make them strong language learners. We\nbuild competent diffusion language models at scale by first acquiring knowledge\nfrom massive data via masked language modeling pretraining thanks to their\nintrinsic connections. We then reprogram pretrained masked language models into\ndiffusion language models via diffusive adaptation, wherein task-specific\nfinetuning and instruction finetuning are explored to unlock their versatility\nin solving general language tasks. Experiments show that scaling diffusion\nlanguage models consistently improves performance across downstream language\ntasks. We further discover that instruction finetuning can elicit zero-shot and\nfew-shot in-context learning abilities that help tackle many unseen tasks by\nfollowing natural language instructions, and show promise in advanced and\nchallenging abilities such as reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2023 16:01:12 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2023 16:32:31 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 05:09:09 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Ye", "Jiasheng", ""], ["Zheng", "Zaixiang", ""], ["Bao", "Yu", ""], ["Qian", "Lihua", ""], ["Gu", "Quanquan", ""]], "extracted_entities": [{"text": "large language\nmodels", "label": "Large Language Model"}, {"text": "diffusion language\nmodels", "label": "Large Language Model"}, {"text": "diffusion language models", "label": "Large Language Model"}, {"text": "diffusion language models", "label": "Large Language Model"}, {"text": "task-specific\nfinetuning", "label": "Fine-tuning"}, {"text": "instruction finetuning", "label": "Fine-tuning"}, {"text": "diffusion\nlanguage models", "label": "Large Language Model"}, {"text": "instruction finetuning", "label": "Fine-tuning"}], "human_readable_topic": "Improving Instruction Following in Large Language Models"}
{"id": "2308.14321", "submitter": "Yanjun Gao", "authors": "Yanjun Gao, Ruizhe Li, Emma Croxford, John Caskey, Brian W Patterson,\n  Matthew Churpek, Timothy Miller, Dmitriy Dligach, Majid Afshar", "title": "Leveraging Medical Knowledge Graphs Into Large Language Models for\n  Diagnosis Prediction: Design and Application Study", "comments": "Published in JMIR AI", "journal-ref": null, "doi": "10.2196/58670", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Electronic Health Records (EHRs) and routine documentation practices play a\nvital role in patients' daily care, providing a holistic record of health,\ndiagnoses, and treatment. However, complex and verbose EHR narratives overload\nhealthcare providers, risking diagnostic inaccuracies. While Large Language\nModels (LLMs) have showcased their potential in diverse language tasks, their\napplication in the healthcare arena needs to ensure the minimization of\ndiagnostic errors and the prevention of patient harm. In this paper, we outline\nan innovative approach for augmenting the proficiency of LLMs in the realm of\nautomated diagnosis generation, achieved through the incorporation of a medical\nknowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the\nclinical diagnostic reasoning process. We derive the KG from the National\nLibrary of Medicine's Unified Medical Language System (UMLS), a robust\nrepository of biomedical knowledge. Our method negates the need for\npre-training and instead leverages the KG as an auxiliary instrument aiding in\nthe interpretation and summarization of complex medical concepts. Using\nreal-world hospital datasets, our experimental results demonstrate that the\nproposed approach of combining LLMs with KG has the potential to improve the\naccuracy of automated diagnosis generation. More importantly, our approach\noffers an explainable diagnostic pathway, edging us closer to the realization\nof AI-augmented diagnostic decision support systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2023 06:05:18 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 02:12:44 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Gao", "Yanjun", ""], ["Li", "Ruizhe", ""], ["Croxford", "Emma", ""], ["Caskey", "John", ""], ["Patterson", "Brian W", ""], ["Churpek", "Matthew", ""], ["Miller", "Timothy", ""], ["Dligach", "Dmitriy", ""], ["Afshar", "Majid", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Large Language Models in Healthcare Applications"}
{"id": "2308.14328", "submitter": "Yuanjiang Cao", "authors": "Yuanjiang Cao and Quan Z. Sheng and Julian McAuley and Lina Yao", "title": "Reinforcement Learning for Generative AI: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep Generative AI has been a long-standing essential topic in the machine\nlearning community, which can impact a number of application areas like text\ngeneration and computer vision. The major paradigm to train a generative model\nis maximum likelihood estimation, which pushes the learner to capture and\napproximate the target data distribution by decreasing the divergence between\nthe model distribution and the target distribution. This formulation\nsuccessfully establishes the objective of generative tasks, while it is\nincapable of satisfying all the requirements that a user might expect from a\ngenerative model. Reinforcement learning, serving as a competitive option to\ninject new training signals by creating new objectives that exploit novel\nsignals, has demonstrated its power and flexibility to incorporate human\ninductive bias from multiple angles, such as adversarial learning,\nhand-designed rules and learned reward model to build a performant model.\nThereby, reinforcement learning has become a trending research field and has\nstretched the limits of generative AI in both model design and application. It\nis reasonable to summarize and conclude advances in recent years with a\ncomprehensive review. Although there are surveys in different application areas\nrecently, this survey aims to shed light on a high-level review that spans a\nrange of application areas. We provide a rigorous taxonomy in this area and\nmake sufficient coverage on various models and applications. Notably, we also\nsurveyed the fast-developing large language model area. We conclude this survey\nby showing the potential directions that might tackle the limit of current\nmodels and expand the frontiers for generative AI.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2023 06:15:14 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2023 01:58:02 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 06:26:55 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Cao", "Yuanjiang", ""], ["Sheng", "Quan Z.", ""], ["McAuley", "Julian", ""], ["Yao", "Lina", ""]], "extracted_entities": [{"text": "maximum likelihood estimation", "label": "Zero-shot Learning"}, {"text": "Reinforcement learning", "label": "Few-shot Learning"}, {"text": "adversarial learning", "label": "Few-shot Learning"}, {"text": "reinforcement learning", "label": "Few-shot Learning"}], "human_readable_topic": "Generative AI and Variational Models"}
{"id": "2309.02926", "submitter": "Guozhu Meng", "authors": "Tong Liu, Zizhuang Deng, Guozhu Meng, Yuekang Li, Kai Chen", "title": "Demystifying RCE Vulnerabilities in LLM-Integrated Apps", "comments": null, "journal-ref": "Proceedings of the 2024 on ACM SIGSAC Conference on Computer and\n  Communications Security (CCS '24)", "doi": "10.1145/3658644.3690338", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  LLMs show promise in transforming software development, with a growing\ninterest in integrating them into more intelligent apps. Frameworks like\nLangChain aid LLM-integrated app development, offering code execution\nutility/APIs for custom actions. However, these capabilities theoretically\nintroduce Remote Code Execution (RCE) vulnerabilities, enabling remote code\nexecution through prompt injections. No prior research systematically\ninvestigates these frameworks' RCE vulnerabilities or their impact on\napplications and exploitation consequences. Therefore, there is a huge research\ngap in this field. In this study, we propose LLMSmith to detect, validate and\nexploit the RCE vulnerabilities in LLM-integrated frameworks and apps. To\nachieve this goal, we develop two novel techniques, including 1) a lightweight\nstatic analysis to examine LLM integration mechanisms, and construct call\nchains to identify RCE vulnerabilities in frameworks; 2) a systematical\nprompt-based exploitation method to verify and exploit the found\nvulnerabilities in LLM-integrated apps. This technique involves various\nstrategies to control LLM outputs, trigger RCE vulnerabilities and launch\nsubsequent attacks. Our research has uncovered a total of 20 vulnerabilities in\n11 LLM-integrated frameworks, comprising 19 RCE vulnerabilities and 1 arbitrary\nfile read/write vulnerability. Of these, 17 have been confirmed by the\nframework developers, with 11 vulnerabilities being assigned CVE IDs. For the\n51 apps potentially affected by RCE, we successfully executed attacks on 17\napps, 16 of which are vulnerable to RCE and 1 to SQL injection. Furthermore, we\nconduct a comprehensive analysis of these vulnerabilities and construct\npractical attacks to demonstrate the hazards in reality. Last, we propose\nseveral mitigation measures for both framework and app developers to counteract\nsuch attacks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2023 11:39:37 GMT"}, {"version": "v2", "created": "Sun, 8 Oct 2023 05:28:14 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2024 06:01:23 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 02:22:07 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liu", "Tong", ""], ["Deng", "Zizhuang", ""], ["Meng", "Guozhu", ""], ["Li", "Yuekang", ""], ["Chen", "Kai", ""]], "extracted_entities": [{"text": "LLMs", "label": "LLM"}, {"text": "LLMSmith", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Detecting Vulnerabilities in Code with Large Language Models"}
{"id": "2309.03863", "submitter": "Yannick Azhri Din Omar", "authors": "Yannick A. D. Omar, Zachary G. Lipel, Kranthi K. Mandadapu", "title": "The $(2+\\delta)$-dimensional theory of the electromechanics of lipid\n  membranes: II. Balance laws", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is the second of a three-part series that derives a\nself-consistent theoretical framework of the electromechanics of arbitrarily\ncurved lipid membranes. Existing continuum theories commonly treat lipid\nmembranes as strictly two-dimensional surfaces. While this approach is\nsuccessful in many purely mechanical applications, strict surface theories fail\nto capture the electric potential drop across lipid membranes, the effects of\nsurface charges, and electric fields within the membrane. Consequently, they do\nnot accurately resolve Maxwell stresses in the interior of the membrane and its\nproximity. Furthermore, surface theories are generally unable to capture the\neffects of distinct velocities and tractions at the interfaces between lipid\nmembranes and their surrounding bulk fluids. To address these shortcomings, we\napply a recently proposed dimension reduction method to the three-dimensional,\nelectromechanical balance laws. This approach allows us to derive an effective\nsurface theory without taking the limit of vanishing thickness, thus\nincorporating effects arising from the finite thickness of lipid membranes. We\nrefer to this effective surface theory as $(2 + \\delta)$-dimensional, where\n$\\delta$ indicates the thickness. The resulting $(2 + \\delta)$-dimensional\nequations of motion satisfy velocity and traction continuity conditions at the\nmembrane-bulk interfaces, capture the effects of Maxwell stresses, and can\ndirectly incorporate three-dimensional constitutive models.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2023 17:25:28 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 19:01:53 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Omar", "Yannick A. D.", ""], ["Lipel", "Zachary G.", ""], ["Mandadapu", "Kranthi K.", ""]], "extracted_entities": [{"text": "electromechanical balance laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2309.04606", "submitter": "Bohdan Kulchytskyy", "authors": "Ross Shillito, Florian Hopfmueller, Bohdan Kulchytskyy, Pooya Ronagh", "title": "Compact Pulse Schedules for High-Fidelity Single-Flux Quantum Qubit\n  Control", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the traditional approach to controlling superconducting qubits using\nmicrowave pulses, the field of pulse shaping has emerged in order to assist in\nthe removal of leakage and increase gate fidelity. However, the challenge of\nscaling microwave control electronics has created an opportunity to explore\nalternative methods such as single-flux quantum (SFQ) pulses. For qubits\ncontrolled by SFQ pulses, high fidelity gates can be achieved by optimizing the\nbinary control sequence. We extend the notion of the derivative removal by\nadiabatic gate (DRAG) framework a transmon qubit controlled by SFQ drivers. The\nproposed implementation of SFQ pulse sequences can be stored in 22 bits or\nfewer, with gate fidelities exceeding 99.99%. This modest memory requirement\ncould help reduce the footprint of the SFQ coprocessors and power dissipation\nwhile preserving their inherent advantages of scalability and\ncost-effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2023 21:33:00 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 05:18:10 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Shillito", "Ross", ""], ["Hopfmueller", "Florian", ""], ["Kulchytskyy", "Bohdan", ""], ["Ronagh", "Pooya", ""]], "extracted_entities": [{"text": "scalability", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2309.05907", "submitter": "Siyu Chen", "authors": "Siyu Chen, Robert-Jan Slager, Bartomeu Monserrat and Adrien Bouhon", "title": "High-chirality Weyl nodes in hexagonal ReO$_3$", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cond-mat.mes-hall", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The formation of two-band nodal points in gapless topological phases,\nreferred to as conventional Weyl nodes, relies solely on translational\nsymmetry. However, when coupled with other spatial and spatio-temporal\nsymmetries, unconventional Weyl nodes with high degeneracy, pronounced\nchirality, and complementary quaternion charges can manifest. In this work, we\nidentify ReO3 as an ideal unconventional Weyl semimetal in which rotation and\nscrew symmetries as well as their combination with time-reversal symmetry play\na crucial role. To show this, we first revisit in detail the algebraic\ndetermination of the chirality of Weyl nodes from the spinful irreducible\nrepresentations of the occupied and unoccupied bands, and then combine it with\nthe complementary C2T-symmetry-protected patch Euler class and non-Abelian\nframe charges that indicates the pinning of the Weyl nodes on C2T-invariant\nplanes. Supporting our findings with first-principles calculations, we\nfurthermore reveal very clear Fermi arc signatures of the high-chirality Weyl\nnodes at the Fermi level for different surface orientations. We finally\ninvestigate the effect of strain upon which the robustness of Weyl nodes\nclearly demonstrates their Chern (i.e. chirality conservation) and quaternionic\n(i.e. symmetry-plane pinning) topological nature.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2023 01:40:27 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 18:18:09 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Chen", "Siyu", ""], ["Slager", "Robert-Jan", ""], ["Monserrat", "Bartomeu", ""], ["Bouhon", "Adrien", ""]], "extracted_entities": [{"text": "ReO3", "label": "Mistral"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2309.06169", "submitter": "Qinpeng Cui", "authors": "Qinpeng Cui, Xinyi Zhang, Qiqi Bao and Qingmin Liao", "title": "Elucidating the solution space of extended reverse-time SDE for\n  diffusion models", "comments": "This paper has been accepted by WACV 2025 (Oral). The official\n  version lacked proper attribution to the co-authors, and this version has\n  been updated accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sampling from Diffusion Models can alternatively be seen as solving\ndifferential equations, where there is a challenge in balancing speed and image\nvisual quality. ODE-based samplers offer rapid sampling time but reach a\nperformance limit, whereas SDE-based samplers achieve superior quality, albeit\nwith longer iterations. In this work, we formulate the sampling process as an\nExtended Reverse-Time SDE (ER SDE), unifying prior explorations into ODEs and\nSDEs. Theoretically, leveraging the semi-linear structure of ER SDE solutions,\nwe offer exact solutions and approximate solutions for VP SDE and VE SDE,\nrespectively. Based on the approximate solution space of the ER SDE, referred\nto as one-step prediction errors, we yield mathematical insights elucidating\nthe rapid sampling capability of ODE solvers and the high-quality sampling\nability of SDE solvers. Additionally, we unveil that VP SDE solvers stand on\npar with their VE SDE counterparts. Based on these findings, leveraging the\ndual advantages of ODE solvers and SDE solvers, we devise efficient\nhigh-quality samplers, namely ER-SDE-Solvers. Experimental results demonstrate\nthat ER-SDE-Solvers achieve state-of-the-art performance across all stochastic\nsamplers while maintaining efficiency of deterministic samplers. Specifically,\non the ImageNet $128\\times128$ dataset, ER-SDE-Solvers obtain 8.33 FID in only\n20 function evaluations. Code is available at\n\\href{https://github.com/QinpengCui/ER-SDE-Solver}{https://github.com/QinpengCui/ER-SDE-Solver}\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2023 12:27:17 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2023 06:19:00 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 07:11:01 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Cui", "Qinpeng", ""], ["Zhang", "Xinyi", ""], ["Bao", "Qiqi", ""], ["Liao", "Qingmin", ""]], "extracted_entities": [{"text": "SDE-based samplers", "label": "LLM-based"}, {"text": "ER-SDE-Solvers", "label": "LLM-based"}, {"text": "ER-SDE-Solvers", "label": "LLM-based"}, {"text": "ER-SDE-Solvers", "label": "LLM-based"}], "human_readable_topic": "Diffusion Transformers for Image Generation"}
{"id": "2309.08991", "submitter": "Xin Li", "authors": "Xin Li, Jamir Marino, Darrick E. Chang and Benedetta Flebus", "title": "Solid-state platform for cooperative quantum dynamics driven by\n  correlated emission", "comments": null, "journal-ref": "Physical Review B 111, 064424,(2025)", "doi": "10.1103/PhysRevB.111.064424", "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditionally regarded as an obstacle to quantum coherence, recent\nbreakthroughs in quantum optics have shown that the dissipative interaction of\na qubit with its environment can be leveraged to protect quantum states and\nsynthesize many-body entanglement. Inspired by this progress, here we set the\nstage for the -- yet uncharted -- exploration of analogous cooperative\nphenomena in hybrid solid-state platforms. We develop a comprehensive formalism\nfor the quantum many-body dynamics of an ensemble of solid-state spin defects\ninteracting with the magnetic field fluctuations of a common solid-state\nreservoir. Our framework applies to any solid-state reservoir whose fluctuating\nspin, pseudospin, or charge degrees of freedom generate magnetic fields. To\nunderstand whether correlations induced by dissipative processes can play a\nrelevant role in a realistic experimental setup, we apply our model to a qubit\narray interacting via the spin fluctuations of a ferromagnetic bath. Our\nresults show that the low-temperature collective relaxation rates of the qubit\nensemble can display clear signatures of super- and subradiance, i.e., forms of\ncooperative dynamics traditionally achieved in atomic ensembles. We find that\nthe solid-state analog of these cooperative phenomena is robust against spatial\ndisorder in the qubit ensemble and thermal fluctuations of the magnetic\nreservoir, providing a route for their feasibility in near-term experiments.\nOur work lays the foundation for a multi-qubit approach to quantum sensing of\nsolid-state systems and the direct generation of many-body entanglement in\nspin-defect ensembles. Furthermore, we discuss how the tunability of\nsolid-state reservoirs opens up novel pathways for exploring cooperative\nphenomena in regimes beyond the reach of conventional quantum optics setups.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2023 13:12:42 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2023 03:27:19 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2024 17:03:29 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 17:14:56 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Li", "Xin", ""], ["Marino", "Jamir", ""], ["Chang", "Darrick E.", ""], ["Flebus", "Benedetta", ""]], "extracted_entities": [{"text": "many-body entanglement", "label": "quantisation"}, {"text": "many-body entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2309.11523", "submitter": "Qihang Fan", "authors": "Qihang Fan, Huaibo Huang, Mingrui Chen, Hongmin Liu and Ran He", "title": "RMT: Retentive Networks Meet Vision Transformers", "comments": "The paper is accepted by CVPR2024. Code is available at\n  https://github.com/qhfan/RMT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision Transformer (ViT) has gained increasing attention in the computer\nvision community in recent years. However, the core component of ViT,\nSelf-Attention, lacks explicit spatial priors and bears a quadratic\ncomputational complexity, thereby constraining the applicability of ViT. To\nalleviate these issues, we draw inspiration from the recent Retentive Network\n(RetNet) in the field of NLP, and propose RMT, a strong vision backbone with\nexplicit spatial prior for general purposes. Specifically, we extend the\nRetNet's temporal decay mechanism to the spatial domain, and propose a spatial\ndecay matrix based on the Manhattan distance to introduce the explicit spatial\nprior to Self-Attention. Additionally, an attention decomposition form that\nadeptly adapts to explicit spatial prior is proposed, aiming to reduce the\ncomputational burden of modeling global information without disrupting the\nspatial decay matrix. Based on the spatial decay matrix and the attention\ndecomposition form, we can flexibly integrate explicit spatial prior into the\nvision backbone with linear complexity. Extensive experiments demonstrate that\nRMT exhibits exceptional performance across various vision tasks. Specifically,\nwithout extra training data, RMT achieves **84.8%** and **86.1%** top-1 acc on\nImageNet-1k with **27M/4.5GFLOPs** and **96M/18.2GFLOPs**. For downstream\ntasks, RMT achieves **54.5** box AP and **47.2** mask AP on the COCO detection\ntask, and **52.8** mIoU on the ADE20K semantic segmentation task. Code is\navailable at https://github.com/qhfan/RMT\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2023 00:57:48 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2023 14:51:59 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2023 15:30:06 GMT"}, {"version": "v4", "created": "Sat, 4 Nov 2023 04:55:31 GMT"}, {"version": "v5", "created": "Sat, 2 Dec 2023 06:23:09 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2025 03:14:35 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Fan", "Qihang", ""], ["Huang", "Huaibo", ""], ["Chen", "Mingrui", ""], ["Liu", "Hongmin", ""], ["He", "Ran", ""]], "extracted_entities": [{"text": "Self-Attention", "label": "Attention mechanism"}, {"text": "RMT", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "temporal decay mechanism", "label": "Attention mechanism"}, {"text": "Self-Attention", "label": "Attention mechanism"}, {"text": "RMT", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "RMT", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "RMT", "label": "Generative Pre-trained Transformer (GPT)"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2309.11912", "submitter": "Arthur Herledan Le Merdy", "authors": "Arthur Herl\\'edan Le Merdy (LIP, ARIC, UMPA-ENSL), Benjamin Wesolowski\n  (CNRS, UMPA-ENSL)", "title": "The supersingular endomorphism ring problem given one endomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a supersingular elliptic curve E and a non-scalar endomorphism $\\alpha$\nof E, we prove that the endomorphism ring of E can be computed in classical\ntime about disc(Z[$\\alpha$])^1/4 , and in quantum subexponential time, assuming\nthe generalised Riemann hypothesis. Previous results either had higher\ncomplexities, or relied on heuristic assumptions. Along the way, we prove that\nthe Primitivisation problem can be solved in polynomial time (a problem\npreviously believed to be hard), and we prove that the action of smooth ideals\non oriented elliptic curves can be computed in polynomial time (previous\nresults of this form required the ideal to be powersmooth, i.e., not divisible\nby any large prime power). Following the attacks on SIDH, isogenies in high\ndimension are a central ingredient of our results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2023 09:22:43 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2023 06:32:26 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 10:00:36 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Merdy", "Arthur Herl\u00e9dan Le", "", "LIP, ARIC, UMPA-ENSL"], ["Wesolowski", "Benjamin", "", "CNRS, UMPA-ENSL"]], "extracted_entities": [{"text": "quantum subexponential time", "label": "quantisation"}, {"text": "Primitivisation", "label": "quantisation"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2310.03249", "submitter": "Mohamed Aghzal", "authors": "Mohamed Aghzal, Erion Plaku, Ziyu Yao", "title": "Can Large Language Models be Good Path Planners? A Benchmark and\n  Investigation on Spatial-temporal Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large language models (LLMs) have achieved remarkable success across a wide\nspectrum of tasks; however, they still face limitations in scenarios that\ndemand long-term planning and spatial reasoning. To facilitate this line of\nresearch, in this work, we propose a new benchmark, termed $\\textbf{P}$ath\n$\\textbf{P}$lanning from $\\textbf{N}$atural $\\textbf{L}$anguage\n($\\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning by\nformulating ''path planning'' tasks that require an LLM to navigate to target\nlocations while avoiding obstacles and adhering to constraints. Leveraging this\nbenchmark, we systematically investigate LLMs including GPT-4 via different\nfew-shot prompting methodologies as well as BART and T5 of various sizes via\nfine-tuning. Our experimental results show the promise of few-shot GPT-4 in\nspatial reasoning, when it is prompted to reason and act interleavedly,\nalthough it still fails to perform long-term temporal reasoning. In contrast,\nwhile fine-tuned LLMs achieved impressive results on in-distribution reasoning\ntasks, they struggled to generalize to larger environments or environments with\nmore obstacles.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2023 01:42:16 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2024 20:18:54 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 00:58:13 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Aghzal", "Mohamed", ""], ["Plaku", "Erion", ""], ["Yao", "Ziyu", ""]], "extracted_entities": [{"text": "GPT-4", "label": "GPT-4"}, {"text": "fine-tuning", "label": "Fine-tuning"}, {"text": "GPT-4", "label": "GPT-4"}], "human_readable_topic": "Large Language Models for Planning Tasks"}
{"id": "2310.03459", "submitter": "Jiyoung Han", "authors": "Samantha Fairchild and Jiyoung Han", "title": "Mean value theorems for the S-arithmetic primitive Siegel transforms", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the theory and properties of primitive unimodular $S$-arithmetic\nlattices in $\\mathbb{Q}_S^d$ by giving integral formulas in the spirit of\nSiegel's primitive mean value formula and Rogers' and Schmidt's second moment\nformulas. We then use mean value and second moment formulas in three\napplications. First, we obtain quantitative estimates for counting primitive\n$S$-arithmetic lattice points which are used to count primitive integer vectors\nin $\\mathbb{Z}^d$ with congruence conditions. These counting results use\nasymptotic information for the totient summatory function with added congruence\nconditions. We next obtain two versions of a quantitative Khintchine-Groshev\ntheorem: counting $\\psi$-approximable elements over the primitive set\n$P(\\mathbb{Z}_S^d)$ of $S$-integer vectors and over the primitive set\n$P(\\mathbb{Z}^d)$ of integer vectors with additional congruence conditions. We\nconclude with an $S$-arithmetic version of logarithm laws for unipotent flows\nin the spirit of Athreya-Margulis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2023 11:08:07 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2023 08:22:45 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2024 06:03:41 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 22:09:36 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Fairchild", "Samantha", ""], ["Han", "Jiyoung", ""]], "extracted_entities": [{"text": "logarithm laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2310.04579", "submitter": "Tao Li", "authors": "Tao Li, Juan Guevara, Xinhong Xie, and Quanyan Zhu", "title": "Self-Confirming Transformer for Belief-Conditioned Adaptation in Offline\n  Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline reinforcement learning (RL) suffers from the distribution shift\nbetween the offline dataset and the online environment. In multi-agent RL\n(MARL), this distribution shift may arise from the nonstationary opponents in\nthe online testing who display distinct behaviors from those recorded in the\noffline dataset. Hence, the key to the broader deployment of offline MARL is\nthe online adaptation to nonstationary opponents. Recent advances in foundation\nmodels, e.g., large language models, have demonstrated the generalization\nability of the transformer, an emerging neural network architecture, in\nsequence modeling, of which offline RL is a special case. One naturally wonders\n\\textit{whether offline-trained transformer-based RL policies adapt to\nnonstationary opponents online}. We propose a novel auto-regressive training to\nequip transformer agents with online adaptability based on the idea of\nself-augmented pre-conditioning. The transformer agent first learns offline to\npredict the opponent's action based on past observations. When deployed online,\nsuch a fictitious opponent play, referred to as the belief, is fed back to the\ntransformer, together with other environmental feedback, to generate future\nactions conditional on the belief. Motivated by self-confirming equilibrium in\ngame theory, the training loss consists of belief consistency loss, requiring\nthe beliefs to match the opponent's actual actions and best response loss,\nmandating the agent to behave optimally under the belief. We evaluate the\nonline adaptability of the proposed self-confirming transformer (SCT) in a\nstructured environment, iterated prisoner's dilemma games, to demonstrate SCT's\nbelief consistency and equilibrium behaviors as well as more involved\nmulti-particle environments to showcase its superior performance against\nnonstationary opponents over prior transformers and offline MARL baselines.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2023 20:43:08 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 06:49:47 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Li", "Tao", ""], ["Guevara", "Juan", ""], ["Xie", "Xinhong", ""], ["Zhu", "Quanyan", ""]], "extracted_entities": [{"text": "foundation\nmodels", "label": "Foundation Model"}, {"text": "large language models", "label": "Large Language Model"}], "human_readable_topic": "Offline-to-Online Reinforcement Learning"}
{"id": "2310.07205", "submitter": "Shu-Xu Yi Dr.", "authors": "S.-X. Yi, C.-W. Wang, X.-Y. Shao, R. Moradi, H. Gao, B. Zhang, S.-L.\n  Xiong, S.-N. Zhang, W.-J. Tan, J.-C. Liu, W.-C. Xue, Y.-Q. Zhang, C. Zheng,\n  Y. Wang, P. Zhang, Z.-H. An, C. Cai, P.-Y. Feng, K. Gong, D.-Y. Guo, Y.\n  Huang, B. Li, X.-B. Li, X.-Q. Li, X.-J. Liu, Y.-Q. Liu, X. Ma, W.-X. Peng, R.\n  Qiao, L.-M. Song, J. Wang, P. Wang, Y. Wang, X.-Y. Wen, S. Xiao, Y.-B. Xu, S.\n  Yang, Q.-B. Yi, D.-L. Zhang, F. Zhang, H.-M. Zhang, J.-P. Zhang, Z. Zhang,\n  X.-Y. Zhao, Y. Zhao, S.-J. Zheng", "title": "Evidence of mini-jet emission in a large emission zone from a\n  magnetically-dominated gamma-ray burst jet", "comments": "16 pages, 19 figures, 4 tables. Submitted to ApJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The second brightest GRB in history, GRB230307A, provides an ideal laboratory\nto study the mechanism of GRB prompt emission thanks to its extraordinarily\nhigh photon statistics and its single episode activity. Here we demonstrate\nthat the rapidly variable components of its prompt emission compose an overall\nbroad single pulse-like profile. Although these individual rapid components are\naligned in time across all energy bands, this overall profile conspires to show\na well-defined energy-dependent behavior which is typically seen in single GRB\npulses. Such a feature demonstrates that the prompt emission of this burst is\nfrom many individual emitting units that are casually linked in a emission site\nat a large distance from the central engine. Such a scenario is in natural\nconsistency with the internal-collision-induced magnetic reconnection and\nturbulence framework, which invokes many mini-jets due to local magnetic\nreconnection that constantly appear and disappear in a global\nmagnetically-dominated jet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2023 05:33:16 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2024 10:02:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 07:34:36 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Yi", "S. -X.", ""], ["Wang", "C. -W.", ""], ["Shao", "X. -Y.", ""], ["Moradi", "R.", ""], ["Gao", "H.", ""], ["Zhang", "B.", ""], ["Xiong", "S. -L.", ""], ["Zhang", "S. -N.", ""], ["Tan", "W. -J.", ""], ["Liu", "J. -C.", ""], ["Xue", "W. -C.", ""], ["Zhang", "Y. -Q.", ""], ["Zheng", "C.", ""], ["Wang", "Y.", ""], ["Zhang", "P.", ""], ["An", "Z. -H.", ""], ["Cai", "C.", ""], ["Feng", "P. -Y.", ""], ["Gong", "K.", ""], ["Guo", "D. -Y.", ""], ["Huang", "Y.", ""], ["Li", "B.", ""], ["Li", "X. -B.", ""], ["Li", "X. -Q.", ""], ["Liu", "X. -J.", ""], ["Liu", "Y. -Q.", ""], ["Ma", "X.", ""], ["Peng", "W. -X.", ""], ["Qiao", "R.", ""], ["Song", "L. -M.", ""], ["Wang", "J.", ""], ["Wang", "P.", ""], ["Wang", "Y.", ""], ["Wen", "X. -Y.", ""], ["Xiao", "S.", ""], ["Xu", "Y. -B.", ""], ["Yang", "S.", ""], ["Yi", "Q. -B.", ""], ["Zhang", "D. -L.", ""], ["Zhang", "F.", ""], ["Zhang", "H. -M.", ""], ["Zhang", "J. -P.", ""], ["Zhang", "Z.", ""], ["Zhao", "X. -Y.", ""], ["Zhao", "Y.", ""], ["Zheng", "S. -J.", ""]], "extracted_entities": [{"text": "prompt emission", "label": "Prompting"}, {"text": "prompt emission", "label": "Prompting"}, {"text": "prompt emission", "label": "Prompting"}], "human_readable_topic": "Astronomy and Astrophysics Research"}
{"id": "2310.08689", "submitter": "Jesse Comer", "authors": "Balder ten Cate and Jesse Comer", "title": "Craig Interpolation for Decidable First-Order Fragments", "comments": "This is an expanded version of a paper by the same name which\n  appeared in the Proceedings of FoSSaCS 2024. arXiv admin note: text overlap\n  with arXiv:2304.08086", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the guarded-negation fragment is, in a precise sense, the\nsmallest extension of the guarded fragment with Craig interpolation. In\ncontrast, we show that full first-order logic is the smallest extension of both\nthe two-variable fragment and the forward fragment with Craig interpolation.\nSimilarly, we also show that all extensions of the two-variable fragment and of\nthe fluted fragment with Craig interpolation are undecidable.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2023 19:51:59 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2024 17:08:33 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2024 04:14:04 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 12:55:21 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Cate", "Balder ten", ""], ["Comer", "Jesse", ""]], "extracted_entities": [{"text": "Craig interpolation", "label": "Embedding"}, {"text": "Craig interpolation", "label": "Embedding"}, {"text": "Craig interpolation", "label": "Embedding"}], "human_readable_topic": "Modal Logics and Formalization"}
{"id": "2310.08824", "submitter": "Ruijiang Gao", "authors": "Ruijiang Gao, Mingzhang Yin", "title": "Confounding-Robust Policy Improvement with Human-AI Teams", "comments": "AAAI 25", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human-AI collaboration has the potential to transform various domains by\nleveraging the complementary strengths of human experts and Artificial\nIntelligence (AI) systems. However, unobserved confounding can undermine the\neffectiveness of this collaboration, leading to biased and unreliable outcomes.\nIn this paper, we propose a novel solution to address unobserved confounding in\nhuman-AI collaboration by employing sensitivity analysis from causal inference.\nOur approach combines domain expertise with AI-driven statistical modeling to\naccount for potentially hidden confounders. We present a deferral collaboration\nframework for incorporating the sensitivity model into offline policy learning,\nenabling the system to control for the influence of unobserved confounding\nfactors. In addition, we propose a personalized deferral collaboration system\nto leverage the diverse expertise of different human decision-makers. By\nadjusting for potential biases, our proposed solution enhances the robustness\nand reliability of collaborative outcomes. The empirical and theoretical\nanalyses demonstrate the efficacy of our approach in mitigating unobserved\nconfounding and improving the overall performance of human-AI collaborations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2023 02:39:52 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 08:39:04 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Gao", "Ruijiang", ""], ["Yin", "Mingzhang", ""]], "extracted_entities": [{"text": "offline policy learning", "label": "Few-shot Learning"}], "human_readable_topic": "Biases in AI and NLP Models"}
{"id": "2310.11355", "submitter": "Tara Kalsi", "authors": "Tara Kalsi, Alessandro Romito, Henning Schomerus", "title": "Spectral chaos bounds from scaling theory of maximally efficient\n  quantum-dynamical scrambling", "comments": "Accepted for publication in Quantum", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key conjecture about the evolution of complex quantum systems towards an\nergodic steady state, known as scrambling, is that this process acquires\nuniversal features when it is most efficient. We develop a single-parameter\nscaling theory for the spectral statistics in this scenario, which embodies\nexact self-similarity of the spectral correlations along the complete\nscrambling dynamics. We establish that the scaling predictions are matched by a\nprivileged stochastic process and serve as bounds for other dynamical\nscrambling scenarios, allowing one to quantify inefficient or incomplete\nscrambling on all time scales.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2023 15:41:50 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2024 16:19:39 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 18:21:31 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Kalsi", "Tara", ""], ["Romito", "Alessandro", ""], ["Schomerus", "Henning", ""]], "extracted_entities": [{"text": "single-parameter\nscaling theory", "label": "Scaling law"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2310.19786", "submitter": "Noah Golowich", "authors": "Yuval Dagan and Constantinos Daskalakis and Maxwell Fishelson and Noah\n  Golowich", "title": "From External to Swap Regret 2.0: An Efficient Reduction and Oblivious\n  Adversary for Large Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel reduction from swap-regret minimization to external-regret\nminimization, which improves upon the classical reductions of Blum-Mansour\n[BM07] and Stolz-Lugosi [SL05] in that it does not require finiteness of the\nspace of actions. We show that, whenever there exists a no-external-regret\nalgorithm for some hypothesis class, there must also exist a no-swap-regret\nalgorithm for that same class. For the problem of learning with expert advice,\nour result implies that it is possible to guarantee that the swap regret is\nbounded by {\\epsilon} after $\\log(N)^{O(1/\\epsilon)}$ rounds and with $O(N)$\nper iteration complexity, where $N$ is the number of experts, while the\nclassical reductions of Blum-Mansour and Stolz-Lugosi require $O(N/\\epsilon^2)$\nrounds and at least $\\Omega(N^2)$ per iteration complexity. Our result comes\nwith an associated lower bound, which -- in contrast to that in [BM07] -- holds\nfor oblivious and $\\ell_1$-constrained adversaries and learners that can employ\ndistributions over experts, showing that the number of rounds must be\n$\\tilde\\Omega(N/\\epsilon^2)$ or exponential in $1/\\epsilon$.\n  Our reduction implies that, if no-regret learning is possible in some game,\nthen this game must have approximate correlated equilibria, of arbitrarily good\napproximation. This strengthens the folklore implication of no-regret learning\nthat approximate coarse correlated equilibria exist. Importantly, it provides a\nsufficient condition for the existence of correlated equilibrium which vastly\nextends the requirement that the action set is finite, thus answering a\nquestion left open by [DG22; Ass+23]. Moreover, it answers several outstanding\nquestions about equilibrium computation and learning in games.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2023 17:50:29 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2023 17:57:22 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2023 07:34:24 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 02:58:57 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Dagan", "Yuval", ""], ["Daskalakis", "Constantinos", ""], ["Fishelson", "Maxwell", ""], ["Golowich", "Noah", ""]], "extracted_entities": [{"text": "no-regret learning", "label": "Zero-shot Learning"}, {"text": "no-regret learning", "label": "Zero-shot Learning"}], "human_readable_topic": "Catastrophic Forgetting in Large Language Models"}
{"id": "2310.19979", "submitter": "Anthony Christiana", "authors": "Anthony Christiana, Huizheng Guo, Jozef H. Przytycki", "title": "Using Fibonacci Numbers and Chebyshev Polynomials to Express Fox\n  Coloring Groups and Alexander-Burau-Fox Modules of Diagrams of Wheel Graphs", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we compute the Reduced Fox Coloring Group of the diagrams of\nWheel Graphs which can also be represented at the closure of the braids\n$(\\sigma_1 \\sigma_2^{-1})^n$. In doing so, we utilize Fibonacci numbers and\ntheir properties.\n  Following this, we generalize our result to compute the Alexander-Burau-Fox\nModule over the ring $\\mathbb{Z}[t^{\\pm 1}]$ for the same class of links. In\nour computation, Chebyshev polynomials function as a generalization of\nFibonacci Numbers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2023 19:54:07 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 22:19:48 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Christiana", "Anthony", ""], ["Guo", "Huizheng", ""], ["Przytycki", "Jozef H.", ""]], "extracted_entities": [{"text": "braids", "label": "RAG"}], "human_readable_topic": "Uncategorized"}
{"id": "2310.20360", "submitter": "Benno Kuckuck", "authors": "Arnulf Jentzen, Benno Kuckuck, Philippe von Wurstemberger", "title": "Mathematical Introduction to Deep Learning: Methods, Implementations,\n  and Theory", "comments": "712 pages, 36 figures, 45 source codes, 87 exercises. In v2, the\n  material on optimization algorithms/methods has been significantly expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book aims to provide an introduction to the topic of deep learning\nalgorithms. We review essential components of deep learning algorithms in full\nmathematical detail including different artificial neural network (ANN)\narchitectures (such as fully-connected feedforward ANNs, convolutional ANNs,\nrecurrent ANNs, residual ANNs, and ANNs with batch normalization) and different\noptimization algorithms (such as the basic stochastic gradient descent (SGD)\nmethod, accelerated methods, and adaptive methods). We also cover several\ntheoretical aspects of deep learning algorithms such as approximation\ncapacities of ANNs (including a calculus for ANNs), optimization theory\n(including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In\nthe last part of the book some deep learning approximation methods for PDEs are\nreviewed including physics-informed neural networks (PINNs) and deep Galerkin\nmethods. We hope that this book will be useful for students and scientists who\ndo not yet have any background in deep learning at all and would like to gain a\nsolid foundation as well as for practitioners who would like to obtain a firmer\nmathematical understanding of the objects and methods considered in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2023 11:01:23 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 21:17:16 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Jentzen", "Arnulf", ""], ["Kuckuck", "Benno", ""], ["von Wurstemberger", "Philippe", ""]], "extracted_entities": [{"text": "fully-connected feedforward ANNs", "label": "AI model"}, {"text": "convolutional ANNs", "label": "AI model"}, {"text": "recurrent ANNs", "label": "AI model"}, {"text": "residual ANNs", "label": "AI model"}], "human_readable_topic": "Deep Learning and Neural Networks Optimization"}
{"id": "2311.00585", "submitter": "Tuomas Sahlsten", "authors": "Tuomas Sahlsten", "title": "Fourier transforms and iterated function systems", "comments": "To appear in proceedings \"Recent Developments in Fractals and Related\n  Fields, Conference on Fractals and Related Fields IV, Ile de Porquerolles,\n  France, 2022\". v3: fixed typos, updated references and made various fixes\n  suggested by the referee", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.DS math.GR math.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We discuss the problem of bounding the Fourier transforms of stationary\nmeasures of iterated function systems (IFSs) and how the pseudo-randomness of\nthe IFS either due to arithmetic, algebraic or geometric reasons is reflected\nin the behaviour of the Fourier transform. We outline various methods that have\nbeen built to estimate the Fourier transform of stationary measures arising\ne.g. from thermodynamical formalism, additive combinatorics, random walks on\ngroups and hyperbolic dynamics. Open problems, prospects and recent links to\nquantum chaos are also highlighted.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2023 15:32:08 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2023 15:37:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 14:34:21 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Sahlsten", "Tuomas", ""]], "extracted_entities": [{"text": "iterated function systems", "label": "LLMs"}, {"text": "thermodynamical formalism", "label": "quantisation"}, {"text": "additive combinatorics", "label": "quantisation"}, {"text": "hyperbolic dynamics", "label": "quantisation"}, {"text": "quantum chaos", "label": "quantisation"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2311.01314", "submitter": "Ghazaleh Haratinezhad Torbati", "authors": "Ghazaleh Haratinezhad Torbati, Anna Tigunova, Andrew Yates, Gerhard\n  Weikum", "title": "Recommendations by Concise User Profiles from Review Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems perform well for popular items and users with ample\ninteractions (likes, ratings etc.). This work addresses the difficult and\nunderexplored case of users who have very sparse interactions but post\ninformative review texts. This setting naturally calls for encoding\nuser-specific text with large language models (LLM). However, feeding the full\ntext of all reviews through an LLM has a weak signal-to-noise ratio and incurs\nhigh costs of processed tokens. This paper addresses these two issues. It\npresents a light-weight framework, called CUP, which first computes concise\nuser profiles and feeds only these into the training of transformer-based\nrecommenders. For user profiles, we devise various techniques to select the\nmost informative cues from noisy reviews. Experiments, with book reviews data,\nshow that fine-tuning a small language model with judiciously constructed\nprofiles achieves the best performance, even in comparison to LLM-generated\nrankings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2023 15:31:12 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2023 14:31:27 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 16:36:08 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Torbati", "Ghazaleh Haratinezhad", ""], ["Tigunova", "Anna", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]], "extracted_entities": [{"text": "LLM", "label": "Large Language Model"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Personalization of Large Language Models"}
{"id": "2311.05769", "submitter": "Ross Deans Kristensen-McLachlan", "authors": "Ross Deans Kristensen-McLachlan, Miceal Canavan, M\\'arton Kardos, Mia\n  Jacobsen, Lene Aar{\\o}e", "title": "Are Chatbots Reliable Text Annotators? Sometimes", "comments": "Accepted for publication in PNAS Nexus (accepted Feb. 2025)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent research highlights the significant potential of ChatGPT for text\nannotation in social science research. However, ChatGPT is a closed-source\nproduct which has major drawbacks with regards to transparency,\nreproducibility, cost, and data protection. Recent advances in open-source (OS)\nlarge language models (LLMs) offer an alternative without these drawbacks.\nThus, it is important to evaluate the performance of OS LLMs relative to\nChatGPT and standard approaches to supervised machine learning classification.\nWe conduct a systematic comparative evaluation of the performance of a range of\nOS LLMs alongside ChatGPT, using both zero- and few-shot learning as well as\ngeneric and custom prompts, with results compared to supervised classification\nmodels. Using a new dataset of tweets from US news media, and focusing on\nsimple binary text annotation tasks, we find significant variation in the\nperformance of ChatGPT and OS models across the tasks, and that the supervised\nclassifier using DistilBERT generally outperforms both. Given the unreliable\nperformance of ChatGPT and the significant challenges it poses to Open Science\nwe advise caution when using ChatGPT for substantive text annotation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2023 22:28:14 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 09:57:48 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Kristensen-McLachlan", "Ross Deans", ""], ["Canavan", "Miceal", ""], ["Kardos", "M\u00e1rton", ""], ["Jacobsen", "Mia", ""], ["Aar\u00f8e", "Lene", ""]], "extracted_entities": [{"text": "ChatGPT", "label": "ChatGPT"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "OS", "label": "Open-source LLMs"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "zero- and few-shot learning", "label": "Zero-shot Learning"}, {"text": "custom prompts", "label": "Prompting"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "DistilBERT", "label": "DistilBERT"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "ChatGPT", "label": "ChatGPT"}], "human_readable_topic": "Text Classification with Limited Annotations"}
{"id": "2311.07978", "submitter": "David Adelani", "authors": "Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji,\n  Jimmy Lin, Pontus Stenetorp, David Ifeoluwa Adelani", "title": "AfroBench: How Good are Large Language Models on African Languages?", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2023 08:10:14 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2024 16:04:16 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 15:16:47 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Ojo", "Jessica", ""], ["Ogundepo", "Odunayo", ""], ["Oladipo", "Akintunde", ""], ["Ogueji", "Kelechi", ""], ["Lin", "Jimmy", ""], ["Stenetorp", "Pontus", ""], ["Adelani", "David Ifeoluwa", ""]], "extracted_entities": [{"text": "LLM", "label": "LLM"}, {"text": "LLMs", "label": "LLM"}, {"text": "prompting", "label": "Prompting"}, {"text": "LLMs", "label": "LLM"}, {"text": "BERT", "label": "BERT"}, {"text": "LLMs", "label": "LLM"}], "human_readable_topic": "Large Language Model Evaluation Benchmarks"}
{"id": "2311.09802", "submitter": "Sen Yang", "authors": "Sen Yang, Xin Li, Leyang Cui, Lidong Bing, Wai Lam", "title": "Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs", "comments": "To appear in Findings of NAACL2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Two lines of approaches are adopted for complex reasoning with LLMs. One line\nof work prompts LLMs with various reasoning structures, while the structural\noutputs can be naturally regarded as intermediate reasoning steps. Another line\nof work adopt LLM-free declarative solvers to do the reasoning task, rendering\nhigher reasoning accuracy but lacking interpretability due to the black-box\nnature of the solvers. Aiming to resolve the trade-off between answer accuracy\nand interpretability, we present a simple extension to the latter line of work.\nSpecifically, we showcase that the intermediate search logs generated by Prolog\ninterpreters can be accessed and interpreted into human-readable reasoning\nproofs. As long as LLMs correctly translate problem descriptions into Prolog\nrepresentations, the corresponding reasoning proofs are ensured to be causal\nand reliable. On two logical reasoning and one arithmetic reasoning datasets,\nour framework obtains significant improvements in terms of both answer accuracy\nand reasoning proof accuracy. Our code is released at\nhttps://github.com/DAMO-NLP-SG/CaRing\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2023 11:26:21 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2024 08:15:50 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 08:33:46 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Yang", "Sen", ""], ["Li", "Xin", ""], ["Cui", "Leyang", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]], "extracted_entities": [{"text": "LLMs", "label": "LLM"}, {"text": "prompts", "label": "Prompting"}, {"text": "LLMs", "label": "LLM"}, {"text": "LLMs", "label": "LLM"}], "human_readable_topic": "Logical Reasoning with Large Language Models"}
{"id": "2311.09838", "submitter": "Alicia Gill", "authors": "Alicia Gill, Jere Koskela, Xavier Didelot, Richard G. Everitt", "title": "Bayesian Inference of Reproduction Number from Epidemiological and\n  Genetic Data Using Particle MCMC", "comments": "24 pages, 11 figures (30 pages, 19 figures including appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.GN q-bio.PE stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference of the reproduction number through time is of vital importance\nduring an epidemic outbreak. Typically, epidemiologists tackle this using\nobserved prevalence or incidence data. However, prevalence and incidence data\nalone is often noisy or partial. Models can also have identifiability issues\nwith determining whether a large amount of a small epidemic or a small amount\nof a large epidemic has been observed. Sequencing data however is becoming more\nabundant, so approaches which can incorporate genetic data are an active area\nof research. We propose using particle MCMC methods to infer the time-varying\nreproduction number from a combination of prevalence data reported at a set of\ndiscrete times and a dated phylogeny reconstructed from sequences. We validate\nour approach on simulated epidemics with a variety of scenarios. We then apply\nthe method to real data sets of HIV-1 in North Carolina, USA and tuberculosis\nin Buenos Aires, Argentina. The models and algorithms are implemented in an\nopen source R package called EpiSky which is available at\nhttps://github.com/alicia-gill/EpiSky.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2023 12:09:32 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 13:07:05 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Gill", "Alicia", ""], ["Koskela", "Jere", ""], ["Didelot", "Xavier", ""], ["Everitt", "Richard G.", ""]], "extracted_entities": [{"text": "EpiSky", "label": "Open-source LLMs"}], "human_readable_topic": "Large Language Model Data Curation and Deduplication"}
{"id": "2311.11482", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Yang Yuan, Andrew Chi-Chih Yao", "title": "Meta Prompting for AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Meta Prompting (MP), a prompting paradigm designed to enhance\nthe utilization of large language models (LLMs) and AI systems in complex\nproblem-solving and data interaction. Grounded in type theory and category\ntheory, Meta Prompting prioritizes structural and syntactical considerations\nover traditional content-centric methods. In this work, we formally define Meta\nPrompting, delineate its distinctions from few-shot prompting, and demonstrate\nits effectiveness across various AI applications. In particular, we show that\nMeta Prompting can decompose intricate reasoning tasks into simpler\nsub-problems, thereby improving token efficiency and enabling fairer\ncomparisons with conventional few-shot techniques. Furthermore, we extend this\nframework to prompting tasks, allowing LLMs to recursively self-generate\nrefined prompts in a metaprogramming-like manner. Empirical evaluations reveal\nthat a Qwen-72B base language model equipped with Meta Prompting-without\nadditional instruction tuning-achieves a PASS@1 accuracy of 46.3% on MATH\nproblems, surpassing a supervised fine-tuned counterpart, 83.5% accuracy on\nGSM8K, and a 100% success rate on Game of 24 tasks using GPT-4. The code is\navailable at https://github.com/meta-prompting/meta-prompting.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2023 01:51:13 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2024 13:54:42 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2024 01:15:59 GMT"}, {"version": "v4", "created": "Thu, 1 Feb 2024 04:12:52 GMT"}, {"version": "v5", "created": "Tue, 2 Apr 2024 03:36:57 GMT"}, {"version": "v6", "created": "Sat, 15 Jun 2024 08:19:24 GMT"}, {"version": "v7", "created": "Wed, 26 Feb 2025 05:39:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhang", "Yifan", ""], ["Yuan", "Yang", ""], ["Yao", "Andrew Chi-Chih", ""]], "extracted_entities": [{"text": "Meta Prompting", "label": "Prompting"}, {"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "Meta Prompting", "label": "Prompting"}, {"text": "Meta\nPrompting", "label": "Prompting"}, {"text": "Meta Prompting", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "Meta Prompting-without", "label": "Prompting"}, {"text": "GPT-4", "label": "GPT-4"}], "human_readable_topic": "Prompt Engineering for Large Language Models"}
{"id": "2311.12161", "submitter": "Ayush Kumar Shah", "authors": "Ayush Kumar Shah, Bryan Manrique Amador, Abhisek Dey, Ming Creekmore,\n  Blake Ocampo, Scott Denmark, Richard Zanibbi", "title": "ChemScraper: Leveraging PDF Graphics Instructions for Molecular Diagram\n  Parsing", "comments": "20 pages without references, 12 figures, 4 Tables, submitted to\n  International Conference on Document Analysis and Recognition (ICDAR) -\n  Journal Track", "journal-ref": "IJDAR, vol. 27, no. 3, pp. 395-414, Sep. 2024", "doi": "10.1007/s10032-024-00486-7", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most molecular diagram parsers recover chemical structure from raster images\n(e.g., PNGs). However, many PDFs include commands giving explicit locations and\nshapes for characters, lines, and polygons. We present a new parser that uses\nthese born-digital PDF primitives as input. The parsing model is fast and\naccurate, and does not require GPUs, Optical Character Recognition (OCR), or\nvectorization. We use the parser to annotate raster images and then train a new\nmulti-task neural network for recognizing molecules in raster images. We\nevaluate our parsers using SMILES and standard benchmarks, along with a novel\nevaluation protocol comparing molecular graphs directly that supports automatic\nerror compilation and reveals errors missed by SMILES-based evaluation. On the\nsynthetic USPTO benchmark, our born-digital parser obtains a recognition rate\nof 98.4% (1% higher than previous models) and our relatively simple neural\nparser for raster images obtains a rate of 85% using less training data than\nexisting neural approaches (thousands vs. millions of molecules).\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2023 20:27:42 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2023 03:23:17 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2024 16:43:14 GMT"}, {"version": "v4", "created": "Fri, 31 May 2024 19:53:06 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2025 17:16:28 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Shah", "Ayush Kumar", ""], ["Amador", "Bryan Manrique", ""], ["Dey", "Abhisek", ""], ["Creekmore", "Ming", ""], ["Ocampo", "Blake", ""], ["Denmark", "Scott", ""], ["Zanibbi", "Richard", ""]], "extracted_entities": [{"text": "vectorization", "label": "quantisation"}], "human_readable_topic": "Molecular and Protein Representation Learning"}
{"id": "2311.15114", "submitter": "Dibyendu Panigrahi Dp", "authors": "D. Panigrahi, S. Chatterjee", "title": "Studies of the Inhomogeneous Cosmology in Higher Dimensional space-time\n  with a Cosmological Constant", "comments": "17 Pages, 15 figures", "journal-ref": "Gravitation and Cosmology, Vol.31, Page 53, 2025", "doi": "10.1134/S020228932470049X", "report-no": null, "categories": "gr-qc astro-ph.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have studied the inhomogeneous cosmology in Kaluza-Klein spacetime with a\npositive cosmological constant in a dust dominated era ($p = 0$). Depending on\nthe integration constant we have derived two types of solutions. The\ndimensional reduction of extra dimensional scale factor is possible due to\ninhomogeneity depending on the curvature of the metric for positive\ncosmological constant for all solutions. The high value of entropy in present\nobservable universe and the possible matter leakage in $4D$ world due to\nreduction of extra dimension are also discussed. Our solutions show the early\ndeceleration and late accelerating nature of the universe. Findings are\nverified by the wellknown Raychaudhuri equation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2023 20:38:25 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 20:17:54 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Panigrahi", "D.", ""], ["Chatterjee", "S.", ""]], "extracted_entities": [{"text": "Raychaudhuri equation", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2312.00035", "submitter": "Yang Li", "authors": "Yang Li, Chunhe Xia, Tianbo Wang", "title": "FBChain: A Blockchain-based Federated Learning Model with Efficiency and\n  Secure Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and security in the parameter transmission process of federated\nlearning are currently among the most prominent concerns. However, there are\ntwo thorny problems caused by unprotected communication methods:\n\"parameter-leakage\" and \"inefficient-communication\". This article proposes\nBlockchain-based Federated Learning (FBChain) model for federated learning\nparameter communication to overcome the above two problems. First, we utilize\nthe immutability of blockchain to store the global model and hash value of\nlocal model parameters in case of tampering during the communication process,\nprotect data privacy by encrypting parameters, and verify data consistency by\ncomparing the hash values of local parameters, thus addressing the\n\"parameter-leakage\" problem. Second, the Proof of Weighted Link Speed (PoWLS)\nconsensus algorithm comprehensively selects nodes with the higher weighted link\nspeed to aggregate global model and package blocks, thereby solving the\n\"inefficient-communication\" problem. Experimental results demonstrate the\neffectiveness of our proposed FBChain model and its ability to improve model\ncommunication efficiency in federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2023 01:36:35 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2024 17:41:28 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 15:08:48 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Li", "Yang", ""], ["Xia", "Chunhe", ""], ["Wang", "Tianbo", ""]], "extracted_entities": [{"text": "federated\nlearning", "label": "Few-shot Learning"}], "human_readable_topic": "Federated Learning for Private Data"}
{"id": "2312.00472", "submitter": "Mariana Jaber Dr.", "authors": "Mariana Jaber and Wojciech A. Hellwing and Jorge E. Garc\\'ia-Farieta\n  and Suhani Gupta and Maciej Bilicki", "title": "Dynamics of pairwise motions in the fully non-linear regime in LCDM and\n  Modified Gravity cosmologies", "comments": "11 pages plus references, 5 figures. Our main findings are in Figs.\n  1, 2 and 4. Accepted in PRD for publication", "journal-ref": "Physical Review D, Volume 109, Issue 12, article id.123528, June\n  2024 Physical Review D, Volume 109, Issue 12, article id.123528", "doi": "10.1103/PhysRevD.109.123528", "report-no": null, "categories": "astro-ph.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In contrast to our understanding of density field tracers, the modelling of\ndirect statistics pertaining to the cosmic velocity field remains open to\nsignificant opportunities for improvement. The lack of accurate modelling for\nthe non-linear domain of pairwise velocities restricts our capacity to fully\nexploit the information encoded in this observable. We present a robust\napproach for modelling the mean infall velocities, $v_{12}(r,a)$, with broad\napplicability spanning sub-megaparsec scales and cosmologies extending beyond\nthe standard LCDM paradigm. Our approach involves solving the full\npair-conservation equation using accurate non-linear power spectrum\ndescriptions. To assess the robustness of our model, we extend it to\ncosmologies beyond the standard LCDM, in particular, the Hu-Sawicki\n$f(R)$-gravity and Dvali-Gabadadze-Porrati (DGP) modified gravity models.\nRemarkably, our predictions for pairwise velocities of dark matter particles at\nkilo-parsec scales exhibit excellent agreement with N-body simulations\nthroughout the entire dynamical range ($0.1 \\lesssim \\xi \\lesssim 1000$, or\n$r\\geq0.4$Mpc/h). Furthermore, we show that different gravity models leave\ndistinct signatures in the shape and dynamics of the mean pairwise velocities,\nproviding a potent test of cosmological gravity laws.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2023 10:11:04 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 18:11:58 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Jaber", "Mariana", ""], ["Hellwing", "Wojciech A.", ""], ["Garc\u00eda-Farieta", "Jorge E.", ""], ["Gupta", "Suhani", ""], ["Bilicki", "Maciej", ""]], "extracted_entities": [{"text": "cosmological gravity laws", "label": "Scaling law"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2312.00474", "submitter": "Fateme Shojaei Arani", "authors": "Fateme Shojaei Arani, Malek Bagheri Harouni, Brahim Lamine, Alain\n  Blanchard", "title": "Revisiting van Citter Zernike correlations in the presence of primordial\n  gravitational waves", "comments": "52 pages, 7 figures, submitted to JCAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present a detailed construction of quantum field theory of\ninteraction between a generic GW background and a spherical electromagnetic\n(EM) field. This scenario is applicable to the EM emission from furthest stars.\nAfter identification of the evolution of the EM field, we show that the\nbackground of primordial gravitational waves (PGWs) predicted by the\ninflationary scenario induces a decrease in the spatial coherence of the EM\nfield propagating over cosmological distances, leading the van Citter-Zernike\ncorrelations to become unobservable, an effect called as blurring. Since\nspatial correlation is observed in VLBI measurements of distant quasars, it\nimposes a constraint on the level of the primordial gravitational wave\nbackground. We evaluate the blurring effect caused by PGWs placed in two-mode\nsqueezed state which is the standard quantum state predicted by the simplest\nscenario of inflation. As a result of the small coupling strength between GWs\nand EM probe, the incoherence induced by PGWs is far beyond the coherence\nlength in VLBI measurements, which finally renders the detection of PGWs based\non interferometric setups. The main idea of the present study is to promote the\nuse of high-precision VLBI measurement of angular size-redshift of distant\nsources, as a new possible way of constraining the underlying primordial\nbackground, in parallel to other surveys such as the cosmic microwave\nbackground. In particular, the present schema can pave the way to search for\nthe effect of scalar curvature perturbations in the VLBI $\\theta-z$\nmeasurements.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2023 10:13:49 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2024 22:42:27 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2024 10:35:07 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 09:21:24 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Arani", "Fateme Shojaei", ""], ["Harouni", "Malek Bagheri", ""], ["Lamine", "Brahim", ""], ["Blanchard", "Alain", ""]], "extracted_entities": [{"text": "PGWs", "label": "LLMs"}, {"text": "PGWs", "label": "LLMs"}, {"text": "PGWs", "label": "LLMs"}, {"text": "PGWs", "label": "LLMs"}], "human_readable_topic": "Astronomy and Astrophysics Research"}
{"id": "2312.01529", "submitter": "Che Liu", "authors": "Che Liu, Cheng Ouyang, Yinda Chen, Cesar C\\'esar Quilodr\\'an-Casas,\n  Lei Ma, Jie Fu, Yike Guo, Anand Shah, Wenjia Bai, Rossella Arcucci", "title": "T3D: Advancing 3D Medical Vision-Language Pre-training by Learning\n  Multi-View Visual Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While 3D visual self-supervised learning (vSSL) shows promising results in\ncapturing visual representations, it overlooks the clinical knowledge from\nradiology reports. Meanwhile, 3D medical vision-language pre-training (MedVLP)\nremains underexplored due to the lack of a large-scale, publicly available 3D\nmedical image-report dataset. To bridge this gap, we introduce **CT-3DVLP**,\nthe first and largest **public** 3D volume-report dataset, establishing a\ncomprehensive benchmark for 3D MedVLP research. Meanwhile, we propose the\n**T3D** framework, which enhances 3D MedVLP beyond naive CLIP-style alignment\nthat directly pairs volumes with reports but neglects local visual\nrepresentations. Instead, we introduce **Text-informed Multi-view Alignment\n(TMA)**, a novel approach that clusters volumetric data while enforcing\nconsistency across different views of the same volume-report pair. TMA\nintegrates textual features into fine-grained visual representations, ensuring\ncontextual coherence across views. We evaluate T3D across multiple downstream\ntasks in both unimodal and cross-modal settings, including zero-shot and\nfine-tuned classification, cross-modal retrieval, report generation, and\nsemantic segmentation. Our results show that T3D consistently outperforms\nexisting vSSL and multimodal methods, demonstrating superior zero-shot and\nfine-tuning capabilities and setting a new benchmark for 3D medical image\nunderstanding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2023 23:03:22 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2023 09:01:07 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 07:04:54 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Liu", "Che", ""], ["Ouyang", "Cheng", ""], ["Chen", "Yinda", ""], ["Quilodr\u00e1n-Casas", "Cesar C\u00e9sar", ""], ["Ma", "Lei", ""], ["Fu", "Jie", ""], ["Guo", "Yike", ""], ["Shah", "Anand", ""], ["Bai", "Wenjia", ""], ["Arcucci", "Rossella", ""]], "extracted_entities": [{"text": "TMA", "label": "contextual Embedding"}], "human_readable_topic": "Multimodal Learning for Medical Prediction"}
{"id": "2312.03398", "submitter": "Yuzhe Zhu", "authors": "Yuzhe Zhu", "title": "Averaging lemmas and hypoellipticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the methods of commutator and fundamental solutions to establish\naveraging lemmas and hypoelliptic estimates for purely kinetic transport\nequations. Assuming certain amount of velocity regularity for solutions, we\nextend our analysis using the commutator method to derive the averaging and\nhypoelliptic regularity properties for kinetic equations in the presence of\ngeneral inhomogeneous fluxes. These results find applications in the study of\nhypoelliptic advection-diffusion equations and kinetic formulations of\nhyperbolic conservation laws including Burgers' equation with transport and\nisentropic gas dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2023 10:20:06 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2024 17:20:10 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 08:05:52 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhu", "Yuzhe", ""]], "extracted_entities": [{"text": "hyperbolic conservation laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2312.04059", "submitter": "Zhuoran Huang", "authors": "Zhuoran Huang, Michael P. Berry, Christina Chwyl, Gary Hsieh, Jing\n  Wei, Evan M. Forman", "title": "Comparing Large Language Model AI and Human-Generated Coaching Messages\n  for Behavioral Weight Loss", "comments": "12 pages, 5 figures", "journal-ref": "Journal of Technology in Behavioral Science (2025)", "doi": "10.1007/s41347-025-00491-5", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated coaching messages for weight control can save time and costs, but\ntheir repetitive, generic nature may limit their effectiveness compared to\nhuman coaching. Large language model (LLM) based artificial intelligence (AI)\nchatbots, like ChatGPT, could offer more personalized and novel messages to\naddress repetition with their data-processing abilities. While LLM AI\ndemonstrates promise to encourage healthier lifestyles, studies have yet to\nexamine the feasibility and acceptability of LLM-based BWL coaching. 87 adults\nin a weight-loss trial rated ten coaching messages' helpfulness (five\nhuman-written, five ChatGPT-generated) using a 5-point Likert scale, providing\nadditional open-ended feedback to justify their ratings. Participants also\nidentified which messages they believed were AI-generated. The evaluation\noccurred in two phases: messages in Phase 1 were perceived as impersonal and\nnegative, prompting revisions for Phase 2 messages. In Phase 1, AI-generated\nmessages were rated less helpful than human-written ones, with 66 percent\nreceiving a helpfulness rating of 3 or higher. However, in Phase 2, the AI\nmessages matched the human-written ones regarding helpfulness, with 82% scoring\nthree or above. Additionally, 50% were misidentified as human-written,\nsuggesting AI's sophistication in mimicking human-generated content. A thematic\nanalysis of open-ended feedback revealed that participants appreciated AI's\nempathy and personalized suggestions but found them more formulaic, less\nauthentic, and too data-focused. This study reveals the preliminary feasibility\nand acceptability of LLM AIs, like ChatGPT, in crafting potentially effective\nweight control coaching messages. Our findings also underscore areas for future\nenhancement.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2023 05:45:24 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 18:38:02 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Huang", "Zhuoran", ""], ["Berry", "Michael P.", ""], ["Chwyl", "Christina", ""], ["Hsieh", "Gary", ""], ["Wei", "Jing", ""], ["Forman", "Evan M.", ""]], "extracted_entities": [{"text": "ChatGPT", "label": "ChatGPT"}, {"text": "ChatGPT-generated", "label": "ChatGPT"}, {"text": "ChatGPT", "label": "ChatGPT"}], "human_readable_topic": "Human-Centered Writing Assistance with AI"}
{"id": "2312.04079", "submitter": "Enrique Cervero Martin", "authors": "Enrique Cervero-Mart\\'in, Marco Tomamichel", "title": "Device independent security of quantum key distribution from\n  monogamy-of-entanglement games", "comments": "42 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse two party non-local games whose predicate requires Alice and Bob\nto generate matching bits, and their three party extensions where a third\nplayer receives all inputs and is required to output a bit that matches that of\nthe original players. We propose a general device independent quantum key\ndistribution protocol for the subset of such non-local games that satisfy a\nmonogamy-of-entanglement property characterised by a gap in the maximum winning\nprobability between the bipartite and tripartite versions of the game. This gap\nis due to the optimal strategy for two players requiring entanglement, which\ndue to its monogamy property cannot be shared with any additional players.\nBased solely on the monogamy-of-entanglement property, we provide a simple\nproof of information theoretic security of our protocol. Lastly, we numerically\noptimize the finite and asymptotic secret key rates of our protocol using the\nmagic square game as an example, for which we provide a numerical bound on the\nmaximal tripartite quantum winning probability which closely matches the\nbipartite classical winning probability. Further, we show that our protocol is\nrobust for depolarizing noise up to about $2.2\\%$, providing the first such\nbound for general attacks for magic square based quantum key distribution.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2023 06:48:38 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 16:03:04 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Cervero-Mart\u00edn", "Enrique", ""], ["Tomamichel", "Marco", ""]], "extracted_entities": [{"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2312.04992", "submitter": "Tsing Zhang", "authors": "Jianqing Zhang, Yang Liu, Yang Hua, Hao Wang, Tao Song, Zhengui Xue,\n  Ruhui Ma, and Jian Cao", "title": "PFLlib: A Beginner-Friendly and Comprehensive Personalized Federated\n  Learning Library and Benchmark", "comments": "Accepted by JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Amid the ongoing advancements in Federated Learning (FL), a machine learning\nparadigm that allows collaborative learning with data privacy protection,\npersonalized FL (pFL)has gained significant prominence as a research direction\nwithin the FL domain. Whereas traditional FL (tFL) focuses on jointly learning\na global model, pFL aims to balance each client's global and personalized goals\nin FL settings. To foster the pFL research community, we started and built\nPFLlib, a comprehensive pFL library with an integrated benchmark platform. In\nPFLlib, we implemented 37 state-of-the-art FL algorithms (8 tFL algorithms and\n29 pFL algorithms) and provided various evaluation environments with three\nstatistically heterogeneous scenarios and 24 datasets. At present, PFLlib has\ngained more than 1600 stars and 300 forks on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2023 12:03:08 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 04:41:34 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhang", "Jianqing", ""], ["Liu", "Yang", ""], ["Hua", "Yang", ""], ["Wang", "Hao", ""], ["Song", "Tao", ""], ["Xue", "Zhengui", ""], ["Ma", "Ruhui", ""], ["Cao", "Jian", ""]], "extracted_entities": [{"text": "data privacy protection", "label": "AI Ethics"}], "human_readable_topic": "Federated Learning for Private Data"}
{"id": "2312.06304", "submitter": "Mahdi Hejrati", "authors": "Mahdi Hejrati and Jouni Mattila", "title": "Orchestrated Robust Controller for Precision Control of Heavy-duty\n  Hydraulic Manipulators", "comments": "This paper has been submitted for possible publication in IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vast industrial investment along with increased academic research on\nheavy-duty hydraulic manipulators has unavoidably paved the way for their\nautomatization, necessitating the design of robust and high-precision\ncontrollers. In this study, an orchestrated robust controller is designed to\naddress the mentioned issue for generic manipulators with an anthropomorphic\narm and spherical wrist. Thanks to virtual decomposition control (VDC), the\nentire robotic system is decomposed into subsystems, and a robust controller is\ndesigned at each local subsystem by considering unknown model uncertainties,\nunknown disturbances, and compound input nonlinearities. As such, radial basic\nfunction neural networks (RBFNNs) are incorporated into VDC to tackle unknown\ndisturbances and uncertainties, resulting in novel decentralized RBFNNs. All\nrobust local controllers designed at each local subsystem, then, are\norchestrated to accomplish high-precision control. In the end, for the first\ntime in the context of VDC, a semi-globally uniformly ultimate boundedness is\nachieved under the designed controller. The validity of the theoretical results\nis verified by performing extensive simulations and experiments on a\n6-degrees-of-freedom industrial manipulator with a nominal lifting capacity of\n600 kg at 5 meters reach. Comparing the simulation result to the\nstate-of-the-art controller along with provided experimental results,\ndemonstrates that proposed method established all promises and performed\nexcellently.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2023 11:13:27 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2024 08:59:06 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2024 11:08:40 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 07:36:36 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Hejrati", "Mahdi", ""], ["Mattila", "Jouni", ""]], "extracted_entities": [{"text": "radial basic\nfunction neural networks", "label": "Neural Language Model"}, {"text": "RBFNNs", "label": "Neural Language Model"}, {"text": "RBFNNs", "label": "Neural Language Model"}], "human_readable_topic": "Robot Manipulation and Autonomous Systems"}
{"id": "2312.07950", "submitter": "Xiaoyu Liu", "authors": "Xin Ding, Xiaoyu Liu, Zhijun Tu, Yun Zhang, Wei Li, Jie Hu, Hanting\n  Chen, Yehui Tang, Zhiwei Xiong, Baoqun Yin, Yunhe Wang", "title": "CBQ: Cross-Block Quantization for Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-training quantization (PTQ) has played a key role in compressing large\nlanguage models (LLMs) with ultra-low costs. However, existing PTQ methods only\nfocus on handling the outliers within one layer or one block, which ignores the\ndependency of blocks and leads to severe performance degradation in low-bit\nsettings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ\nmethod for LLMs. CBQ employs a cross-block dependency using a homologous\nreconstruction scheme, establishing long-range dependencies across multiple\nblocks to minimize error accumulation. Furthermore, CBQ incorporates a\ncoarse-to-fine preprocessing (CFP) strategy for suppressing weight and\nactivation outliers, coupled with an adaptive LoRA-Rounding technique for\nprecise weight quantization. These innovations enable CBQ to not only handle\nextreme outliers effectively but also improve overall quantization accuracy.\nExtensive experiments show that CBQ achieves superior low-bit quantization\n(W4A4, W4A8, W2A16) and outperforms existing state-of-the-art methods across\nvarious LLMs and datasets. Notably, CBQ quantizes the 4-bit LLAMA1-65B model\nwithin only 4.3 hours on a single GPU, achieving a commendable tradeoff between\nperformance and quantization efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2023 07:56:27 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2024 06:55:52 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2024 04:51:51 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2024 10:57:16 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 09:14:18 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Ding", "Xin", ""], ["Liu", "Xiaoyu", ""], ["Tu", "Zhijun", ""], ["Zhang", "Yun", ""], ["Li", "Wei", ""], ["Hu", "Jie", ""], ["Chen", "Hanting", ""], ["Tang", "Yehui", ""], ["Xiong", "Zhiwei", ""], ["Yin", "Baoqun", ""], ["Wang", "Yunhe", ""]], "extracted_entities": [{"text": "Post-training quantization", "label": "quantisation"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "precise weight quantization", "label": "quantisation"}, {"text": "low-bit quantization", "label": "quantisation"}, {"text": "W4A4", "label": "GPT"}, {"text": "W4A8", "label": "GPT"}, {"text": "W2A16", "label": "GPT"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Quantization Techniques for Large Language Models"}
{"id": "2312.13409", "submitter": "Thuan Nguyen", "authors": "Christian Bender and Nguyen Tran Thuan", "title": "Entropy-Regularized Mean-Variance Portfolio Optimization with Jumps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the trade-off between exploitation and exploration in\nreinforcement learning, we study a continuous-time entropy-regularized mean\nvariance portfolio selection problem in the presence of jumps. We propose an\nexploratory SDE for the wealth process associated with multiple risky assets\nwhich exhibit L\\'evy jumps. In contrast to the existing literature, we study\nthe limiting behavior of the natural discrete-time formulation of the wealth\nprocess associated to a randomized control in order to derive the\ncontinuous-time dynamics. We then show that an optimal distributional control\nof the continuous-time entropy-regularized exploratory mean-variance problem is\nGaussian. The respective optimal wealth process solves a linear SDE whose\nrepresentation is explicitly obtained.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2023 20:24:01 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 16:15:34 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Bender", "Christian", ""], ["Thuan", "Nguyen Tran", ""]], "extracted_entities": [{"text": "reinforcement learning", "label": "Few-shot Learning"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2312.13506", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Marc Donias, Yannick Berthoumieu and Mohamed Najim", "title": "SPDGAN: A Generative Adversarial Network based on SPD Manifold Learning\n  for Automatic Image Colorization", "comments": null, "journal-ref": null, "doi": "10.1007/s00521-023-08999-8", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper addresses the automatic colorization problem, which converts a\ngray-scale image to a colorized one. Recent deep-learning approaches can\ncolorize automatically grayscale images. However, when it comes to different\nscenes which contain distinct color styles, it is difficult to accurately\ncapture the color characteristics. In this work, we propose a fully automatic\ncolorization approach based on Symmetric Positive Definite (SPD) Manifold\nLearning with a generative adversarial network (SPDGAN) that improves the\nquality of the colorization results. Our SPDGAN model establishes an\nadversarial game between two discriminators and a generator. The latter is\nbased on ResNet architecture with few alterations. Its goal is to generate fake\ncolorized images without losing color information across layers through\nresidual connections. Then, we employ two discriminators from different\ndomains. The first one is devoted to the image pixel domain, while the second\none is to the Riemann manifold domain which helps to avoid color misalignment.\nExtensive experiments are conducted on the Places365 and COCO-stuff databases\nto test the effect of each component of our SPDGAN. In addition, quantitative\nand qualitative comparisons with state-of-the-art methods demonstrate the\neffectiveness of our model by achieving more realistic colorized images with\nless artifacts visually, and good results of PSNR, SSIM, and FID values.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2023 00:52:01 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 12:42:22 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Mourchid", "Youssef", ""], ["Donias", "Marc", ""], ["Berthoumieu", "Yannick", ""], ["Najim", "Mohamed", ""]], "extracted_entities": [{"text": "Symmetric Positive Definite (SPD) Manifold\nLearning", "label": "Few-shot Learning"}, {"text": "SPDGAN", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "SPDGAN", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "PSNR", "label": "quantisation"}, {"text": "SSIM", "label": "quantisation"}], "human_readable_topic": "Synthetic Image Generation for Deep Learning"}
{"id": "2312.13509", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Rim Slama", "title": "MR-STGN: Multi-Residual Spatio Temporal Graph Network Using Attention\n  Fusion for Patient Action Assessment", "comments": null, "journal-ref": null, "doi": "10.1109/MMSP59012.2023.10337711", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Accurate assessment of patient actions plays a crucial role in healthcare as\nit contributes significantly to disease progression monitoring and treatment\neffectiveness. However, traditional approaches to assess patient actions often\nrely on manual observation and scoring, which are subjective and\ntime-consuming. In this paper, we propose an automated approach for patient\naction assessment using a Multi-Residual Spatio Temporal Graph Network\n(MR-STGN) that incorporates both angular and positional 3D skeletons. The\nMR-STGN is specifically designed to capture the spatio-temporal dynamics of\npatient actions. It achieves this by integrating information from multiple\nresidual layers, with each layer extracting features at distinct levels of\nabstraction. Furthermore, we integrate an attention fusion mechanism into the\nnetwork, which facilitates the adaptive weighting of various features. This\nempowers the model to concentrate on the most pertinent aspects of the\npatient's movements, offering precise instructions regarding specific body\nparts or movements that require attention. Ablation studies are conducted to\nanalyze the impact of individual components within the proposed model. We\nevaluate our model on the UI-PRMD dataset demonstrating its performance in\naccurately predicting real-time patient action scores, surpassing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2023 01:09:52 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 13:16:39 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Mourchid", "Youssef", ""], ["Slama", "Rim", ""]], "extracted_entities": [{"text": "attention fusion mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Multimodal Learning for Medical Prediction"}
{"id": "2312.13735", "submitter": "Xinghao Chen", "authors": "Xinghao Chen, Siwei Li, Yijing Yang, Yunhe Wang", "title": "DECO: Unleashing the Potential of ConvNets for Query-based Detection and\n  Segmentation", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer and its variants have shown great potential for various vision\ntasks in recent years, including image classification, object detection and\nsegmentation. Meanwhile, recent studies also reveal that with proper\narchitecture design, convolutional networks (ConvNets) also achieve competitive\nperformance with transformers. However, no prior methods have explored to\nutilize pure convolution to build a Transformer-style Decoder module, which is\nessential for Encoder-Decoder architecture like Detection Transformer (DETR).\nTo this end, in this paper we explore whether we could build query-based\ndetection and segmentation framework with ConvNets instead of sophisticated\ntransformer architecture. We propose a novel mechanism dubbed InterConv to\nperform interaction between object queries and image features via convolutional\nlayers. Equipped with the proposed InterConv, we build Detection ConvNet\n(DECO), which is composed of a backbone and convolutional encoder-decoder\narchitecture. We compare the proposed DECO against prior detectors on the\nchallenging COCO benchmark. Despite its simplicity, our DECO achieves\ncompetitive performance in terms of detection accuracy and running speed.\nSpecifically, with the ResNet-18 and ResNet-50 backbone, our DECO achieves\n$40.5\\%$ and $47.8\\%$ AP with $66$ and $34$ FPS, respectively. The proposed\nmethod is also evaluated on the segment anything task, demonstrating similar\nperformance and higher efficiency. We hope the proposed method brings another\nperspective for designing architectures for vision tasks. Codes are available\nat https://github.com/xinghaochen/DECO and\nhttps://github.com/mindspore-lab/models/tree/master/research/huawei-noah/DECO.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2023 10:59:17 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 14:58:37 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Chen", "Xinghao", ""], ["Li", "Siwei", ""], ["Yang", "Yijing", ""], ["Wang", "Yunhe", ""]], "extracted_entities": [{"text": "InterConv", "label": "Transformers"}], "human_readable_topic": "Vision Transformers with Convolutional Layers"}
{"id": "2312.15545", "submitter": "Rafael Benedikt Andrist", "authors": "Rafael B. Andrist, Gaofeng Huang", "title": "The Density Property for Generalized Calogero--Moser Spaces with Inner\n  Degrees of Freedom", "comments": "The results of this preprint are now contained in the much more\n  general result of the new preprint arXiv:2502.13903 with different co-authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CV math-ph math.AG math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the density property for generalized Calogero--Moser spaces with\ninner degrees of freedom. This allows us to describe the holomorphic\nautomorphism group of these complex affine manifolds. These generalized\nCalogero--Moser spaces can also be understood as quiver varieties corresponding\nto moduli spaces of $\\mathrm{SU}(2)$ instantons on a non-commutative\n$\\mathbb{R}^4$.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2023 21:03:30 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 23:01:04 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Andrist", "Rafael B.", ""], ["Huang", "Gaofeng", ""]], "extracted_entities": [{"text": "Calogero--Moser", "label": "Mistral"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2312.16948", "submitter": "Dexie Lin", "authors": "Dexie Lin", "title": "Compatible almost complex structures on the Hard Lefschetz condition", "comments": "Change the title. Rewrite the Theorem 1.1 as Theorem 1.1 and 1.2.\n  Modify a mistake in the proof of lemma 3.4 of previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG math.SG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a compact K\\\"ahler manifold, it is well-established that its de Rham\ncohomology satisfies the Hard Lefschetz condition, which is reflected in the\nequality between the Betti numbers and the Hodge numbers. A special subclass of\nsymplectic manifolds also adheres to this condition. Cirici and Wilson\n\\cite{CW20} employ the variant Hodge number to propose a sufficient criterion\nfor compact almost K\\\"ahler manifolds to satisfy this condition. In this paper,\nwe show that this condition is only sufficient by presenting examples of\ncompact almost K\\\"ahler manifolds that fulfill the Hard Lefschetz condition\nwhile violating the equality between the variant Hodge numbers and Betti\nnumbers, that is, \\[b^1>2h^{1,0}.\\] This phenomenon contrasts with the behavior\nobserved in compact K\\\"ahler manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2023 10:44:30 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2024 15:38:25 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2025 08:27:15 GMT"}, {"version": "v4", "created": "Wed, 22 Jan 2025 02:59:55 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 05:19:11 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Lin", "Dexie", ""]], "extracted_entities": [{"text": "Hard Lefschetz condition", "label": "BERT"}, {"text": "Betti numbers", "label": "BERT"}, {"text": "Hard Lefschetz condition", "label": "BERT"}], "human_readable_topic": "Uncategorized"}
{"id": "2312.17273", "submitter": "Zhaisheng Ding", "authors": "Zhaisheng Ding, Haiyan Li, Ruichao Hou, Yanyu Liu and Shidong Xie", "title": "X Modality Assisting RGBT Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing robust multi-modal feature representations is crucial for\nenhancing object tracking performance. In pursuit of this objective, a novel X\nModality Assisting Network (X-Net) is introduced, which explores the impact of\nthe fusion paradigm by decoupling visual object tracking into three distinct\nlevels, thereby facilitating subsequent processing. Initially, to overcome the\nchallenges associated with feature learning due to significant discrepancies\nbetween RGB and thermal modalities, a plug-and-play pixel-level generation\nmodule (PGM) based on knowledge distillation learning is proposed. This module\neffectively generates the X modality, bridging the gap between the two patterns\nwhile minimizing noise interference. Subsequently, to optimize sample feature\nrepresentation and promote cross-modal interactions, a feature-level\ninteraction module (FIM) is introduced, integrating a mixed feature interaction\ntransformer and a spatial dimensional feature translation strategy. Finally, to\naddress random drifting caused by missing instance features, a flexible online\noptimization strategy called the decision-level refinement module (DRM) is\nproposed, which incorporates optical flow and refinement mechanisms. The\nefficacy of X-Net is validated through experiments on three benchmarks,\ndemonstrating its superiority over state-of-the-art trackers. Notably, X-Net\nachieves performance gains of 0.47%/1.2% in the average of precise rate and\nsuccess rate, respectively. Additionally, the research content, data, and code\nare pledged to be made publicly accessible at\nhttps://github.com/DZSYUNNAN/XNet.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2023 05:38:54 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 15:06:13 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Ding", "Zhaisheng", ""], ["Li", "Haiyan", ""], ["Hou", "Ruichao", ""], ["Liu", "Yanyu", ""], ["Xie", "Shidong", ""]], "extracted_entities": [{"text": "knowledge distillation learning", "label": "Knowledge distillation"}], "human_readable_topic": "Visual Adaptation with Learnable Tokens"}
{"id": "2401.00659", "submitter": "Tingting Wang", "authors": "Tingting Wang, Shixun Huang, Zhifeng Bao, J. Shane Culpepper, Volkan\n  Dedeoglu, Reza Arablouei", "title": "Distinctiveness Maximization in Datasets Assemblage", "comments": "This is a technical report of an accepted WWW'25 work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, given a user's query set and budget, we aim to use the limited\nbudget to help users assemble a set of datasets that can enrich a base dataset\nby introducing the maximum number of distinct tuples (i.e., maximizing\ndistinctiveness). We prove this problem to be NP-hard. A greedy algorithm using\nexact distinctiveness computation attains an approximation ratio of (1-1/e)/2,\nbut it lacks efficiency and scalability due to its frequent computation of the\nexact distinctiveness marginal gain of any candidate dataset for selection.\nThis requires scanning through every tuple in candidate datasets and thus is\nunaffordable in practice. To overcome this limitation, we propose an efficient\nmachine learning (ML)-based method for estimating the distinctiveness marginal\ngain of any candidate dataset. This effectively eliminates the need to test\neach tuple individually. Estimating the distinctiveness marginal gain of a\ndataset involves estimating the number of distinct tuples in the tuple sets\nreturned by each query in a query set across multiple datasets. This can be\nviewed as the cardinality estimation for a query set on a set of datasets, and\nthe proposed method is the first to tackle this cardinality estimation problem.\nThis is a significant advancement over prior methods that were limited to\nsingle-query cardinality estimation on a single dataset and struggled with\nidentifying overlaps among tuple sets returned by each query in a query set\nacross multiple datasets. Extensive experiments using five real-world data\npools demonstrate that our algorithm, which utilizes ML-based distinctiveness\nestimation, outperforms all relevant baselines in effectiveness, efficiency,\nand scalability. A case study on two downstream ML tasks also highlights its\npotential to find datasets with more useful tuples to enhance the performance\nof ML tasks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2024 04:14:00 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2024 08:30:24 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2024 03:38:24 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 11:38:18 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Wang", "Tingting", ""], ["Huang", "Shixun", ""], ["Bao", "Zhifeng", ""], ["Culpepper", "J. Shane", ""], ["Dedeoglu", "Volkan", ""], ["Arablouei", "Reza", ""]], "extracted_entities": [{"text": "scalability", "label": "Scaling law"}, {"text": "scalability", "label": "Scaling law"}], "human_readable_topic": "Knowledge Retrieval for Large Language Models"}
{"id": "2401.01401", "submitter": "Adway Das", "authors": "Adway Kumar Das, Cameron Cianci, Delmar G. A. Cabral, David A.\n  Zarate-Herrada, Patrick Pinney, Sa\\'ul Pilatowsky-Cameo, Apollonas S.\n  Matsoukas-Roubeas, Victor S. Batista, Adolfo del Campo, E. Jonathan\n  Torres-Herrera, Lea F. Santos", "title": "Proposal for many-body quantum chaos detection", "comments": "10 pages, 6 figures", "journal-ref": "Phys. Rev. Research 7, 013181 (2025)", "doi": "10.1103/PhysRevResearch.7.013181", "report-no": null, "categories": "cond-mat.stat-mech quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, the term ``quantum chaos'' refers to spectral correlations\nsimilar to those found in the random matrix theory. Quantum chaos can be\ndiagnosed through the analysis of level statistics using e.g.~the spectral form\nfactor, which detects both short- and long-range level correlations. The\nspectral form factor corresponds to the Fourier transform of the two-point\nspectral correlation function and exhibits a typical slope-dip-ramp-plateau\nstructure (aka correlation hole) when the system is chaotic. We discuss how\nthis structure could be detected through the quench dynamics of two physical\nquantities accessible to experimental many-body quantum systems: the survival\nprobability and the spin autocorrelation function. The survival probability is\nequivalent to the spectral form factor with an additional filter. When the\nsystem is small, the dip of the correlation hole reaches sufficiently large\nvalues at times which are short enough to be detected with current experimental\nplatforms. As the system is pushed away from chaos, the correlation hole\ndisappears, signaling integrability or localization. We also provide a\nrelatively shallow circuit with which the correlation hole could be detected\nwith commercially available quantum computers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2024 19:00:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2024 23:12:22 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2024 11:22:30 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 06:10:38 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Das", "Adway Kumar", ""], ["Cianci", "Cameron", ""], ["Cabral", "Delmar G. A.", ""], ["Zarate-Herrada", "David A.", ""], ["Pinney", "Patrick", ""], ["Pilatowsky-Cameo", "Sa\u00fal", ""], ["Matsoukas-Roubeas", "Apollonas S.", ""], ["Batista", "Victor S.", ""], ["del Campo", "Adolfo", ""], ["Torres-Herrera", "E. Jonathan", ""], ["Santos", "Lea F.", ""]], "extracted_entities": [{"text": "spectral form factor", "label": "quantisation"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2401.04364", "submitter": "Shahroz Tariq", "authors": "Binh M. Le, Jiwon Kim, Shahroz Tariq, Kristen Moore, Alsharif\n  Abuadbba, Simon S. Woo", "title": "SoK: Facial Deepfake Detectors", "comments": "18 pages, 6 figures, 5 table, under peer-review, Accepted at IEEE\n  European Symposium on security and privacy 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfakes have rapidly emerged as a profound and serious threat to society,\nprimarily due to their ease of creation and dissemination. This situation has\ntriggered an accelerated development of deepfake detection technologies.\nHowever, many existing detectors rely heavily on lab-generated datasets for\nvalidation, which may not effectively prepare them for novel, emerging, and\nreal-world deepfake techniques. In this paper, we conduct an extensive and\ncomprehensive review and analysis of the latest state-of-the-art deepfake\ndetectors, evaluating them against several critical criteria. These criteria\nfacilitate the categorization of these detectors into 4 high-level groups and\n13 fine-grained sub-groups, all aligned with a unified standard conceptual\nframework. This classification and framework offer deep and practical insights\ninto the factors that affect detector efficacy. We assess the generalizability\nof 16 leading detectors across various standard attack scenarios, including\nblack-box, white-box, and gray-box settings. Our systematized analysis and\nexperimentation lay the groundwork for a deeper understanding of deepfake\ndetectors and their generalizability, paving the way for future research\nfocused on creating detectors adept at countering various attack scenarios.\nAdditionally, this work offers insights for developing more proactive defenses\nagainst deepfakes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2024 05:32:22 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2024 09:02:42 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 10:52:15 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Le", "Binh M.", ""], ["Kim", "Jiwon", ""], ["Tariq", "Shahroz", ""], ["Moore", "Kristen", ""], ["Abuadbba", "Alsharif", ""], ["Woo", "Simon S.", ""]], "extracted_entities": [{"text": "black-box", "label": "Embedding"}], "human_readable_topic": "Backdoor Attacks and Defenses in Deep Learning"}
{"id": "2401.06150", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Rim Slama", "title": "D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on\n  transformer for assessment of patient physical rehabilitation", "comments": "15 pages, Computers in Biology and Medicine Journal", "journal-ref": null, "doi": "10.1016/j.compbiomed.2023.107420", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper tackles the challenge of automatically assessing physical\nrehabilitation exercises for patients who perform the exercises without\nclinician supervision. The objective is to provide a quality score to ensure\ncorrect performance and achieve desired results. To achieve this goal, a new\ngraph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with\nTransformer, is introduced. This model combines a modified version of STGCN and\ntransformer architectures for efficient handling of spatio-temporal data. The\nkey idea is to consider skeleton data respecting its non-linear structure as a\ngraph and detecting joints playing the main role in each rehabilitation\nexercise. Dense connections and GRU mechanisms are used to rapidly process\nlarge 3D skeleton inputs and effectively model temporal dynamics. The\ntransformer encoder's attention mechanism focuses on relevant parts of the\ninput sequence, making it useful for evaluating rehabilitation exercises. The\nevaluation of our proposed approach on the KIMORE and UI-PRMD datasets\nhighlighted its potential, surpassing state-of-the-art methods in terms of\naccuracy and computational time. This resulted in faster and more accurate\nlearning and assessment of rehabilitation exercises. Additionally, our model\nprovides valuable feedback through qualitative illustrations, effectively\nhighlighting the significance of joints in specific exercises.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2023 00:38:31 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 13:32:19 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Mourchid", "Youssef", ""], ["Slama", "Rim", ""]], "extracted_entities": [{"text": "attention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Skeleton-based Action Recognition"}
{"id": "2401.08807", "submitter": "Lezhi Ma", "authors": "Lezhi Ma, Shangqing Liu, Yi Li, Xiaofei Xie and Lei Bu", "title": "SpecGen: Automated Generation of Formal Program Specifications via Large\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal program specifications play a crucial role in various stages of\nsoftware development. However, manually crafting formal program specifications\nis rather difficult, making the job time-consuming and labor-intensive. It is\neven more challenging to write specifications that correctly and\ncomprehensively describe the semantics of complex programs. To reduce the\nburden on software developers, automated specification generation methods have\nemerged. However, existing methods usually rely on predefined templates or\ngrammar, making them struggle to accurately describe the behavior and\nfunctionality of complex real-world programs. To tackle this challenge, we\nintroduce SpecGen, a novel technique for formal program specification\ngeneration based on Large Language Models. Our key insight is to overcome the\nlimitations of existing methods by leveraging the code comprehension capability\nof LLMs. The process of SpecGen consists of two phases. The first phase employs\na conversational approach that guides the LLM to generate appropriate\nspecifications for a given program. The second phase, designed for where the\nLLM fails to generate correct specifications, applies four mutation operators\nto the model-generated specifications and selects verifiable specifications\nfrom the mutated ones through a novel heuristic selection strategy. We evaluate\nSpecGen on two datasets, including the SV-COMP Java category benchmark and a\nmanually constructed dataset. Experimental results demonstrate that SpecGen\nsucceeds in generating verifiable specifications for 279 out of 385 programs,\noutperforming the existing purely LLM-based approaches and conventional\nspecification generation tools like Houdini and Daikon. Further investigations\non the quality of generated specifications indicate that SpecGen can\ncomprehensively articulate the behaviors of the input program.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2024 20:13:50 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2024 03:01:48 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2024 07:30:06 GMT"}, {"version": "v4", "created": "Sat, 7 Dec 2024 07:50:25 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 07:20:36 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Ma", "Lezhi", ""], ["Liu", "Shangqing", ""], ["Li", "Yi", ""], ["Xie", "Xiaofei", ""], ["Bu", "Lei", ""]], "extracted_entities": [{"text": "SpecGen", "label": "LLM"}, {"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "LLM"}, {"text": "SpecGen", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "SpecGen", "label": "LLM"}, {"text": "SpecGen", "label": "LLM"}, {"text": "SpecGen", "label": "LLM"}], "human_readable_topic": "Automated Program Verification with Large Language Models"}
{"id": "2401.11323", "submitter": "Yu Bai", "authors": "Yu Bai, Heyan Huang, Cesare Spinoso-Di Piano, Marc-Antoine Rondeau,\n  Sanxing Chen, Yang Gao, Jackie Chi Kit Cheung", "title": "Identifying and Analyzing Performance-Critical Tokens in Large Language\n  Models", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-context learning (ICL) has emerged as an effective solution for few-shot\nlearning with large language models (LLMs). However, how LLMs leverage\ndemonstrations to specify a task and learn a corresponding computational\nfunction through ICL is underexplored. Drawing from the way humans learn from\ncontent-label mappings in demonstrations, we categorize the tokens in an ICL\nprompt into content, stopword, and template tokens. Our goal is to identify the\ntypes of tokens whose representations directly influence LLM's performance, a\nproperty we refer to as being performance-critical. By ablating representations\nfrom the attention of the test example, we find that the representations of\ninformative content tokens have less influence on performance compared to\ntemplate and stopword tokens, which contrasts with the human attention to\ninformative words. We give evidence that the representations of\nperformance-critical tokens aggregate information from the content tokens.\nMoreover, we demonstrate experimentally that lexical meaning, repetition, and\nstructural cues are the main distinguishing characteristics of these tokens.\nOur work sheds light on how large language models learn to perform tasks from\ndemonstrations and deepens our understanding of the roles different types of\ntokens play in large language models.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2024 20:55:21 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2024 16:43:35 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 03:35:56 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Bai", "Yu", ""], ["Huang", "Heyan", ""], ["Piano", "Cesare Spinoso-Di", ""], ["Rondeau", "Marc-Antoine", ""], ["Chen", "Sanxing", ""], ["Gao", "Yang", ""], ["Cheung", "Jackie Chi Kit", ""]], "extracted_entities": [{"text": "In-context learning", "label": "contextual Embedding"}, {"text": "few-shot\nlearning", "label": "Few-shot Learning"}, {"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "ICL", "label": "Few-shot Learning"}, {"text": "ICL\nprompt", "label": "Prompting"}, {"text": "attention", "label": "Attention mechanism"}, {"text": "attention", "label": "Attention mechanism"}, {"text": "large language models", "label": "Large Language Model"}, {"text": "large language models", "label": "Large Language Model"}], "human_readable_topic": "In-Context Learning for NLP Tasks"}
{"id": "2401.11647", "submitter": "Ye Lin Tun", "authors": "Ye Lin Tun, Chu Myaet Thwal, Huy Q. Le, Minh N. H. Nguyen, Choong Seon\n  Hong", "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies integrate federated learning (FL) with self-supervised learning\n(SSL) to take advantage of raw data distributed across edge devices. However,\nedge devices often struggle with high computational and communication costs\nimposed by SSL and FL algorithms. With the deployment of more complex and\nlarge-scale models, such as Transformers, these challenges are exacerbated. To\ntackle this, we propose the Layer-Wise Federated Self-Supervised Learning\n(LW-FedSSL) approach, which allows edge devices to incrementally train a small\npart of the model at a time. Specifically, in LW-FedSSL, training is decomposed\ninto multiple stages, with each stage responsible for only a specific layer (or\na block of layers) of the model. Since only a portion of the model is active\nfor training at any given time, LW-FedSSL significantly reduces computational\nrequirements. Additionally, only the active model portion needs to be exchanged\nbetween the FL server and clients, reducing the communication overhead. This\nenables LW-FedSSL to jointly address both computational and communication\nchallenges in FL. Depending on the SSL algorithm used, it can achieve up to a\n$3.34 \\times$ reduction in memory usage, $4.20 \\times$ fewer computational\noperations (GFLOPs), and a $5.07 \\times$ lower communication cost while\nmaintaining performance comparable to its end-to-end training counterpart.\nFurthermore, we explore a progressive training strategy called Prog-FedSSL,\nwhich offers a $1.84\\times$ reduction in GFLOPs and a $1.67\\times$ reduction in\ncommunication costs while maintaining the same memory requirements as\nend-to-end training. While the resource efficiency of Prog-FedSSL is lower than\nthat of LW-FedSSL, its performance improvements make it a viable candidate for\nFL environments with more lenient resource constraints.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2024 01:57:31 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2024 00:51:18 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2024 02:11:09 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 05:20:00 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Tun", "Ye Lin", ""], ["Thwal", "Chu Myaet", ""], ["Le", "Huy Q.", ""], ["Nguyen", "Minh N. H.", ""], ["Hong", "Choong Seon", ""]], "extracted_entities": [{"text": "Transformers", "label": "Transformers"}], "human_readable_topic": "Wireless Networks and Federated Learning"}
{"id": "2401.11858", "submitter": "Pratik Worah", "authors": "Cliff Stein and Pratik Worah", "title": "Approximating a gene regulatory network from non-sequential data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given non-sequential snapshots from instances of a dynamical system, we\ndesign a compressed sensing based algorithm that reconstructs the dynamical\nsystem. We formally prove that successful reconstruction is possible under the\nassumption that we can construct an approximate clock from a subset of the\ncoordinates of the underlying system.\n  As an application, we argue that our assumption is likely to be true for\nRNA-seq datasets, and thus we can recover the underlying nuclear receptor\nnetworks and predict pathways, as opposed to genes, that may differentiate\nbetween interesting phenotypes in some publicly available datasets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2024 11:27:42 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 18:55:23 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Stein", "Cliff", ""], ["Worah", "Pratik", ""]], "extracted_entities": [{"text": "publicly available datasets", "label": "Open-source LLMs"}], "human_readable_topic": "Sparse Neural Networks and Model Compression"}
{"id": "2401.16608", "submitter": "Patrick LaChance", "authors": "Patrick LaChance, Rupert Croft, Yueying Ni, Nianyi Chen, Tiziana Di\n  Matteo, and Simeon Bird", "title": "The evolution of galaxy morphology from redshift z=6 to 3: Mock JWST\n  observations of galaxies in the ASTRID simulation", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": "10.33232/001c.129991", "report-no": null, "categories": "astro-ph.GA astro-ph.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present mock JWST observations for more than 250,000 different galaxies\nfrom the Astrid simulation with $3 \\leq z \\leq 6$. The mock observations are\nmade using the BPASS stellar SED model, and a simple dust model. They are then\nviewed through NIRCam filters, convolved with a PSF, have noise added, and are\ndrizzled together to emulate the Cosmic Evolution Early Release Science (CEERS)\nsurvey. We analyse this dataset by computing a number of morphological measures\nand find our catalog to have comparable statistics to similar mock catalogs,\nand the first release of CEERS data. We find that most of the Sersic indices of\ngalaxies in our redshift range are lower than observed, with most having n less\nthan one. Additionally, we observe the sizes of galaxies of all masses to\nincrease from redshift z=6 to redshift z=3 consistent with other results. The\nnumber of galaxies in our catalog allows us to examine how relationships like\nthe mass-size relation evolve with redshift, and compare the accuracy of a\nvariety of traditional galaxy classification techniques (Sersic fit,\nAsymmetry-Concentration, and Gini-$M_{20}$) within our redshift range. We find\nthe mass-size relation to be nearly flat at redshift z=6, and consistently\nincreases as redshift decreases, and find the galaxy classification methods\nhave minimal correlation with each other in our redshift range. We also\ninvestigate the impact that different stages of our imaging pipeline have on\nthese morphological measures to determine how robust mock catalogs are to\ndifferent choices at each step. Finally, we test the addition of incorporating\nlight from AGNs into our pipeline and find that while the population of\ngalaxies that have significant AGN luminosity is low, those galaxies do tend to\nhave higher Sersic indices once the AGN luminosity is added, rectifying some of\nthe systematic bias towards lower Sersic indices present in our dataset.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2024 22:34:00 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2024 15:18:17 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 17:08:09 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["LaChance", "Patrick", ""], ["Croft", "Rupert", ""], ["Ni", "Yueying", ""], ["Chen", "Nianyi", ""], ["Di Matteo", "Tiziana", ""], ["Bird", "Simeon", ""]], "extracted_entities": [{"text": "BPASS stellar SED model", "label": "AI model"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2401.16990", "submitter": "Johan De Aguas", "authors": "Johan de Aguas and Johan Pensar and Tom\\'as Varnet P\\'erez and Guido\n  Biele", "title": "Recovery and inference of causal effects with sequential adjustment for\n  confounding and attrition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Confounding bias and selection bias bring two significant challenges to the\nvalidity of conclusions drawn from applied causal inference. The latter can\nstem from informative missingness, such as in cases of attrition. We introduce\nthe Sequential Adjustment Criteria (SAC), which extend available graphical\nconditions for recovering causal effects from confounding and attrition using\nsequential regressions, allowing for the inclusion of post-exposure and\nforbidden variables in the adjustment sets. We propose an estimator for the\nrecovered Average Treatment Effect (ATE) based on Targeted Minimum-Loss\nEstimation (TMLE), which exhibits multiple robustness under certain technical\nconditions. This approach ensures consistency even in scenarios where the\nDouble Inverse Probability Weighting (DIPW) and the naive plug-in sequential\nregressions approaches fall short. Through a simulation study, we assess the\nperformance of the proposed estimator against alternative methods across\ndifferent graph setups and model specification scenarios. As a motivating\napplication, we examine the effect of pharmacological treatment for\nAttention-Deficit/Hyperactivity Disorder (ADHD) upon the scores obtained by\ndiagnosed Norwegian schoolchildren in national tests using observational data\n($n=9\\,352$). Our findings align with the accumulated clinical evidence,\naffirming a positive but small impact of medication on academic achievement.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2024 13:22:21 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2024 15:49:06 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2024 19:01:30 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 09:47:49 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["de Aguas", "Johan", ""], ["Pensar", "Johan", ""], ["P\u00e9rez", "Tom\u00e1s Varnet", ""], ["Biele", "Guido", ""]], "extracted_entities": [{"text": "Confounding bias", "label": "Model Bias and Fairness"}], "human_readable_topic": "Missing Value Imputation Methods"}
{"id": "2402.01543", "submitter": "Jean Pauphilet", "authors": "Dimitris Bertsimas, Arthur Delarue, and Jean Pauphilet", "title": "Adaptive Optimization for Prediction with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  When training predictive models on data with missing entries, the most widely\nused and versatile approach is a pipeline technique where we first impute\nmissing entries and then compute predictions. In this paper, we view prediction\nwith missing data as a two-stage adaptive optimization problem and propose a\nnew class of models, adaptive linear regression models, where the regression\ncoefficients adapt to the set of observed features. We show that some adaptive\nlinear regression models are equivalent to learning an imputation rule and a\ndownstream linear regression model simultaneously instead of sequentially. We\nleverage this joint-impute-then-regress interpretation to generalize our\nframework to non-linear models. In settings where data is strongly not missing\nat random, our methods achieve a 2-10% improvement in out-of-sample accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2024 16:35:51 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 08:13:55 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Pauphilet", "Jean", ""]], "extracted_entities": [{"text": "adaptive linear regression models", "label": "AI model"}], "human_readable_topic": "Missing Value Imputation Methods"}
{"id": "2402.01881", "submitter": "Siyi Liu", "authors": "Siyi Liu, Chen Gao, Yong Li", "title": "Large Language Model Agent for Hyper-Parameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperparameter optimization is critical in modern machine learning, requiring\nexpert knowledge, numerous trials, and high computational and human resources.\nDespite the advancements in Automated Machine Learning (AutoML), challenges in\nterms of trial efficiency, setup complexity, and interoperability still\npersist. To address these issues, we introduce a novel paradigm leveraging\nLarge Language Models (LLMs) to automate hyperparameter optimization across\ndiverse machine learning tasks, which is named AgentHPO (short for LLM\nAgent-based Hyperparameter Optimization). Specifically, AgentHPO processes the\ntask information autonomously, conducts experiments with specific\nhyperparameters (HPs), and iteratively optimizes them based on historical\ntrials. This human-like optimization process largely reduces the number of\nrequired trials, simplifies the setup process, and enhances interpretability\nand user trust, compared to traditional AutoML methods. Extensive empirical\nexperiments conducted on 12 representative machine-learning tasks indicate that\nAgentHPO not only matches but also often surpasses the best human trials in\nterms of performance while simultaneously providing explainable results.\nFurther analysis sheds light on the strategies employed by the LLM in\noptimizing these tasks, highlighting its effectiveness and adaptability in\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2024 20:12:05 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2024 15:03:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 13:57:13 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Liu", "Siyi", ""], ["Gao", "Chen", ""], ["Li", "Yong", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "AgentHPO", "label": "LLM-based"}, {"text": "LLM", "label": "LLM"}, {"text": "AgentHPO", "label": "LLM"}, {"text": "AgentHPO", "label": "LLM-based"}], "human_readable_topic": "Machine Unlearning in Large Language Models"}
{"id": "2402.01958", "submitter": "Federico Bonetto", "authors": "Federico Bonetto and Guido Gentile", "title": "Synchronization and averaging in partially hyperbolic systems with fast\n  and slow variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a family of dynamical systems obtained by coupling an Anosov map on\nthe two-dimensional torus -- the chaotic system -- with the identity map on the\none-dimensional torus -- the neutral system -- through a dissipative\ninteraction. We show that the two systems synchronize: the trajectories evolve\ntoward an attracting invariant manifold, and the full dynamics is conjugated to\nits linearization around the invariant manifold. As a byproduct, we obtain that\nthere exists a unique exponentially mixing physical measure. When the\ninteraction is small, the evolution of the variable which describes the neutral\nsystem is very close to the identity; hence, it appears as a slow variable with\nrespect to the variable which describes the chaotic system, and which is\nwherefore named the fast variable. We demonstrate that, seen on a suitably long\ntime scale, the slow variable effectively follows the solution of a\ndeterministic differential equation obtained by averaging over the fast\nvariable. More precisely, we prove that the invariant manifold is in\nprobability close to the fixed point of the averaged dynamics and that the\ndifference between the exact evolution of the slow variable, seen from the\ninvariant manifold, and its averaged evolution is in probability exponentially\ndecreasing for arbitrarily large times.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2024 23:34:42 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2024 20:36:13 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 10:47:17 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Bonetto", "Federico", ""], ["Gentile", "Guido", ""]], "extracted_entities": [{"text": "two-dimensional torus", "label": "Mistral"}, {"text": "one-dimensional torus", "label": "Mistral"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2402.01989", "submitter": "Hassan Zahid Butt", "authors": "Hassan Zahid Butt and Xingpeng Li", "title": "Enhancing Optimal Microgrid Planning with Adaptive BESS Degradation\n  Costs and PV Asset Management: An Iterative Post-Optimization Correction\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The transition to renewable energy has positioned photovoltaic (PV) systems\nand battery energy storage systems (BESS) as essential assets in microgrids,\nparticularly for remote installations. However, traditional planning models\noften neglect dynamic degradation costs or rely on complex or non-linear\napproaches, limiting their scalability and practical applicability. This paper\nintroduces a microgrid planning model that integrates adaptive degradation cost\nmodeling to enable accurate, efficient, and scalable long-term resource\nallocation. The proposed model employs the iterative post-optimization\ncorrection (IPOC) framework, solving a sequence of mixed-integer linear\nprogramming problems. Each iteration refines BESS degradation costs based on\nobserved depth-of-discharge profiles and incorporates PV degradation costs to\nensure realistic asset performance assessments. Sensitivity analysis of PV and\nBESS capital costs further underscores the model's robustness under varying\neconomic conditions, with the IPOC framework achieving up to ~1% additional\ncost savings for the given test system compared to static approaches. The\nresults demonstrate that by iteratively adjusting degradation penalties based\non actual usage, the methodology optimizes BESS performance, ensures precise\nresource allocation, resolves issues of under- or overutilization, enhances\nsystem reliability, and facilitates scalable, sustainable microgrid planning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2024 02:20:36 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:14:04 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Butt", "Hassan Zahid", ""], ["Li", "Xingpeng", ""]], "extracted_entities": [{"text": "BESS", "label": "BERT"}, {"text": "BESS", "label": "BERT"}, {"text": "BESS", "label": "BERT"}], "human_readable_topic": "Electric Grid Management and Electrification"}
{"id": "2402.02593", "submitter": "Vivswan Shah", "authors": "Vivswan Shah and Nathan Youngblood", "title": "Leveraging Continuously Differentiable Activation Functions for Learning\n  in Quantized Noisy Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world analog systems intrinsically suffer from noise that can impede\nmodel convergence and accuracy on a variety of deep learning models. We\ndemonstrate that differentiable activations like GELU and SiLU enable robust\npropagation of gradients which help to mitigate analog quantization error that\nis ubiquitous to all analog systems. We perform analysis and training of\nconvolutional, linear, and transformer networks in the presence of quantized\nnoise. Here, we are able to demonstrate that continuously differentiable\nactivation functions are significantly more noise resilient over conventional\nrectified activations. As in the case of ReLU, the error in gradients are 100x\nhigher than those in GELU near zero. Our findings provide guidance for\nselecting appropriate activations to realize performant and reliable hardware\nimplementations across several machine learning domains such as computer\nvision, signal processing, and beyond. Code available at:\n\\href{https://github.com/Vivswan/GeLUReLUInterpolation}{https://github.com/Vivswan/GeLUReLUInterpolation}.}\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2024 20:01:22 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2025 21:15:38 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 09:50:27 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Shah", "Vivswan", ""], ["Youngblood", "Nathan", ""]], "extracted_entities": [{"text": "analog quantization error", "label": "quantisation"}, {"text": "quantized\nnoise", "label": "quantisation"}], "human_readable_topic": "Backdoor Attacks and Defenses in Deep Learning"}
{"id": "2402.05374", "submitter": "Youngsik Yun", "authors": "Youngsik Yun and Jihie Kim", "title": "CIC: A Framework for Culturally-Aware Image Captioning", "comments": "Accepted by IJCAI 2024", "journal-ref": null, "doi": "10.24963/ijcai.2024/180", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2024 03:12:25 GMT"}, {"version": "v2", "created": "Thu, 2 May 2024 02:41:50 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2024 00:52:51 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2024 15:39:30 GMT"}, {"version": "v5", "created": "Mon, 24 Feb 2025 06:56:33 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Yun", "Youngsik", ""], ["Kim", "Jihie", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompts", "label": "Prompting"}, {"text": "LLMs", "label": "LLM"}, {"text": "prompts", "label": "Prompting"}], "human_readable_topic": "Multimodal Image Captioning Models"}
{"id": "2402.05881", "submitter": "Matteo Nerini", "authors": "Matteo Nerini, Golsa Ghiaasi, Bruno Clerckx", "title": "Localized and Distributed Beyond Diagonal Reconfigurable Intelligent\n  Surfaces with Lossy Interconnections: Modeling and Optimization", "comments": "Accepted by IEEE for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reconfigurable intelligent surface (RIS) is a key technology to control the\ncommunication environment in future wireless networks. Recently, beyond\ndiagonal RIS (BD-RIS) emerged as a generalization of RIS achieving larger\ncoverage through additional tunable impedance components interconnecting the\nRIS elements. However, conventional RIS and BD-RIS can effectively serve only\nusers in their proximity, resulting in limited coverage. To overcome this\nlimitation, in this paper, we investigate distributed RIS, whose elements are\ndistributed over a wide region, in opposition to localized RIS commonly\nconsidered in the literature. The scaling laws of distributed BD-RIS reveal\nthat it offers significant gains over distributed conventional RIS and\nlocalized BD-RIS, enabled by its interconnections allowing signal propagation\nwithin the BD-RIS. To assess the practical performance of distributed BD-RIS,\nwe model and optimize BD-RIS with lossy interconnections through transmission\nline theory. Our model accounts for phase changes and losses over the BD-RIS\ninterconnections arising when the interconnection lengths are not much smaller\nthan the wavelength. Numerical results show that the performance of localized\nBD-RIS is only slightly impacted by losses, given the short interconnection\nlengths. Besides, distributed BD-RIS can achieve orders of magnitude of gains\nover conventional RIS, even in the presence of low losses.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2024 18:15:41 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 17:35:36 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Nerini", "Matteo", ""], ["Ghiaasi", "Golsa", ""], ["Clerckx", "Bruno", ""]], "extracted_entities": [{"text": "scaling laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2402.08159", "submitter": "Dennis Hein", "authors": "Dennis Hein, Grant Stevens, Adam Wang, and Ge Wang", "title": "PFCM: Poisson flow consistency models for low-dose CT image denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray computed tomography (CT) is widely used for medical diagnosis and\ntreatment planning; however, concerns about ionizing radiation exposure drive\nefforts to optimize image quality at lower doses. This study introduces Poisson\nFlow Consistency Models (PFCM), a novel family of deep generative models that\ncombines the robustness of PFGM++ with the efficient single-step sampling of\nconsistency models. PFCM are derived by generalizing consistency distillation\nto PFGM++ through a change-of-variables and an updated noise distribution. As a\ndistilled version of PFGM++, PFCM inherit the ability to trade off robustness\nfor rigidity via the hyperparameter $D \\in (0,\\infty)$. A fact that we exploit\nto adapt this novel generative model for the task of low-dose CT image\ndenoising, via a ``task-specific'' sampler that ``hijacks'' the generative\nprocess by replacing an intermediate state with the low-dose CT image. While\nthis ``hijacking'' introduces a severe mismatch -- the noise characteristics of\nlow-dose CT images are different from that of intermediate states in the\nPoisson flow process -- we show that the inherent robustness of PFCM at small\n$D$ effectively mitigates this issue. The resulting sampler achieves excellent\nperformance in terms of LPIPS, SSIM, and PSNR on the Mayo low-dose CT dataset.\nBy contrast, an analogous sampler based on standard consistency models is found\nto be significantly less robust under the same conditions, highlighting the\nimportance of a tunable $D$ afforded by our novel framework. To highlight\ngeneralizability, we show effective denoising of clinical images from a\nprototype photon-counting system reconstructed using a sharper kernel and at a\nrange of energy levels.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2024 01:39:56 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:57:19 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Hein", "Dennis", ""], ["Stevens", "Grant", ""], ["Wang", "Adam", ""], ["Wang", "Ge", ""]], "extracted_entities": [{"text": "PFCM", "label": "AI model"}, {"text": "consistency distillation", "label": "Knowledge distillation"}, {"text": "PFCM", "label": "AI model"}], "human_readable_topic": "Medical Imaging Reconstruction and Denoising"}
{"id": "2402.08658", "submitter": "David Haag", "authors": "David Haag, Devender Kumar, Sebastian Gruber, Dominik Hofer, Mahdi\n  Sareban, Gunnar Treff, Josef Niebauer, Christopher Bull, Albrecht Schmidt,\n  Jan David Smeddinck", "title": "The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time\n  Adaptive Interventions: Fostering Physical Activity in a Conceptual Cardiac\n  Rehabilitation Setting", "comments": null, "journal-ref": null, "doi": "10.1145/3706598.3713307", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We evaluated the viability of using Large Language Models (LLMs) to trigger\nand personalize content in Just-in-Time Adaptive Interventions (JITAIs) in\ndigital health. As an interaction pattern representative of context-aware\ncomputing, JITAIs are being explored for their potential to support sustainable\nbehavior change, adapting interventions to an individual's current context and\nneeds. Challenging traditional JITAI implementation models, which face severe\nscalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs\nin the use case of heart-healthy activity in cardiac rehabilitation. Using\nthree personas representing patients affected by CVD with varying severeness\nand five context sets per persona, we generated 450 JITAI decisions and\nmessages. These were systematically evaluated against those created by 10\nlaypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated\nJITAIs surpassed human-generated intervention suggestions, outperforming both\nLayPs and HCPs across all metrics (i.e., appropriateness, engagement,\neffectiveness, and professionalism). These results highlight the potential of\nLLMs to enhance JITAI implementations in personalized health interventions,\ndemonstrating how generative AI could revolutionize context-aware computing.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2024 18:39:36 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2024 09:08:44 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 08:57:38 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Haag", "David", ""], ["Kumar", "Devender", ""], ["Gruber", "Sebastian", ""], ["Hofer", "Dominik", ""], ["Sareban", "Mahdi", ""], ["Treff", "Gunnar", ""], ["Niebauer", "Josef", ""], ["Bull", "Christopher", ""], ["Schmidt", "Albrecht", ""], ["Smeddinck", "Jan David", ""]], "extracted_entities": [{"text": "GPT-4", "label": "GPT"}, {"text": "GPT-4-generated", "label": "GPT"}], "human_readable_topic": "Large Language Models in Healthcare Applications"}
{"id": "2402.09532", "submitter": "Shuxiang Cao", "authors": "Shuxiang Cao, Zhen Shao, Jian-Qing Zheng, Mohammed Alghadeer, Simone D\n  Fasciati, Michele Piscitelli, Peter A Spring, Shiyu Wang, Shuhei Tamate, Neel\n  Vora, Yilun Xu, Gang Huang, Kasra Nowrouzi, Yasunobu Nakamura, Irfan Siddiqi,\n  Peter Leek, Terry Lyons and Mustafa Bakr", "title": "Superconducting qubit readout enhanced by path signature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum non-demolition measurement plays an essential role in quantum\ntechnology, crucial for quantum error correction, metrology, and sensing.\nConventionally, the qubit state is classified from the raw or integrated\ntime-domain measurement record. Here, we demonstrate a method to enhance the\nassignment fidelity of the readout by considering the \"path signature\" of this\nmeasurement record, where the path signature is a mathematical tool for\nanalyzing stochastic time series. We evaluate this approach across five\ndifferent hardware setups, including those with and without readout\nmultiplexing and parametric amplifiers, and demonstrate a significant\nimprovement in assignment fidelity across all setups. Moreover, we show that\nthe path signature of the measurement record has features that can be used to\ndetect and classify state transitions that occurred during the measurement,\nimproving the prediction of the qubit state at the end of the measurement. This\nmethod has the potential to become a foundational tool for quantum technology.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2024 19:15:42 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 16:54:44 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Cao", "Shuxiang", ""], ["Shao", "Zhen", ""], ["Zheng", "Jian-Qing", ""], ["Alghadeer", "Mohammed", ""], ["Fasciati", "Simone D", ""], ["Piscitelli", "Michele", ""], ["Spring", "Peter A", ""], ["Wang", "Shiyu", ""], ["Tamate", "Shuhei", ""], ["Vora", "Neel", ""], ["Xu", "Yilun", ""], ["Huang", "Gang", ""], ["Nowrouzi", "Kasra", ""], ["Nakamura", "Yasunobu", ""], ["Siddiqi", "Irfan", ""], ["Leek", "Peter", ""], ["Lyons", "Terry", ""], ["Bakr", "Mustafa", ""]], "extracted_entities": [{"text": "quantum\ntechnology", "label": "quantisation"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2402.10745", "submitter": "Sreraman Muralidharan", "authors": "Sreraman Muralidharan", "title": "The simulation of distributed quantum algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed quantum computing (DQC) provides a way to scale quantum computers\nusing multiple quantum processing units (QPU) connected through quantum\ncommunication links. In this paper, we have built a distributed quantum\ncomputing simulator and used the simulator to investigate quantum algorithms\nsuch as the quantum Fourier transform, quantum phase estimation, quantum\namplitude estimation, and generation of probability distribution in DQC. The\nsimulator can be used to easily generate and execute distributed quantum\ncircuits, obtain and benchmark DQC parameters such as the fidelity of the\nalgorithm and the number of entanglement generation steps, and use dynamic\ncircuits in a distributed setting to improve results. We show the applicability\nof dynamic quantum circuits in DQC, where mid-circuit measurements, local\noperations, and classical communication are used in place of noisy\ninter-processor (non-local) quantum gates\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2024 15:05:15 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2024 21:19:05 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 16:03:53 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Muralidharan", "Sreraman", ""]], "extracted_entities": [{"text": "quantum Fourier transform", "label": "quantisation"}, {"text": "quantum phase estimation", "label": "quantisation"}, {"text": "quantum\namplitude estimation", "label": "quantisation"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2402.11000", "submitter": "Yangyifei Luo", "authors": "Yangyifei Luo, Zhuo Chen, Lingbing Guo, Qian Li, Wenxuan Zeng, Zhixin\n  Cai, Jianxin Li", "title": "ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment", "comments": "Ongoing work; 16 pages, 9 Tables, 8 Figures; Code:\n  https://github.com/lyyf2002/ASGEA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) aims to identify entities across different knowledge\ngraphs that represent the same real-world objects. Recent embedding-based EA\nmethods have achieved state-of-the-art performance in EA yet faced\ninterpretability challenges as they purely rely on the embedding distance and\nneglect the logic rules behind a pair of aligned entities. In this paper, we\npropose the Align-Subgraph Entity Alignment (ASGEA) framework to exploit logic\nrules from Align-Subgraphs. ASGEA uses anchor links as bridges to construct\nAlign-Subgraphs and spreads along the paths across KGs, which distinguishes it\nfrom the embedding-based methods. Furthermore, we design an interpretable\nPath-based Graph Neural Network, ASGNN, to effectively identify and integrate\nthe logic rules across KGs. We also introduce a node-level multi-modal\nattention mechanism coupled with multi-modal enriched anchors to augment the\nAlign-Subgraph. Our experimental results demonstrate the superior performance\nof ASGEA over the existing embedding-based methods in both EA and Multi-Modal\nEA (MMEA) tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2024 17:03:05 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2024 13:57:28 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 03:55:35 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Luo", "Yangyifei", ""], ["Chen", "Zhuo", ""], ["Guo", "Lingbing", ""], ["Li", "Qian", ""], ["Zeng", "Wenxuan", ""], ["Cai", "Zhixin", ""], ["Li", "Jianxin", ""]], "extracted_entities": [{"text": "ASGEA", "label": "Embedding"}, {"text": "ASGNN", "label": "Neural Language Model"}, {"text": "node-level multi-modal\nattention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Entity Alignment in Knowledge Graphs"}
{"id": "2402.11471", "submitter": "Zhongqin Gao", "authors": "Zhongqin Gao, Yan Lv and Xiaowen Zhou", "title": "De Finetti's Control for Refracted Skew Brownian Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a refracted skew Brownian motion as a risk model\nwith endogenous regime switching, which generalizes the refracted diffusion\nrisk process introduced by Gerber and Shiu. We consider an optimal dividend\nproblem for the refracted skew Brownian risk model and identify sufficient\nconditions, respectively, for barrier strategy, band strategy and their\nvariants to be optimal.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2024 06:18:00 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2025 14:12:27 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 04:18:47 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Gao", "Zhongqin", ""], ["Lv", "Yan", ""], ["Zhou", "Xiaowen", ""]], "extracted_entities": [{"text": "Gerber", "label": "ALBERT"}], "human_readable_topic": "Uncategorized"}
{"id": "2402.12365", "submitter": "Benedikt Alkin", "authors": "Benedikt Alkin and Andreas F\\\"urst and Simon Schmid and Lukas Gruber\n  and Markus Holzleitner and Johannes Brandstetter", "title": "Universal Physics Transformers: A Framework For Efficiently Scaling\n  Neural Operators", "comments": "Published at NeurIPS 2024, Github: https://ml-jku.github.io/UPT/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.flu-dyn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural operators, serving as physics surrogate models, have recently gained\nincreased interest. With ever increasing problem complexity, the natural\nquestion arises: what is an efficient way to scale neural operators to larger\nand more complex simulations - most importantly by taking into account\ndifferent types of simulation datasets. This is of special interest since, akin\nto their numerical counterparts, different techniques are used across\napplications, even if the underlying dynamics of the systems are similar.\nWhereas the flexibility of transformers has enabled unified architectures\nacross domains, neural operators mostly follow a problem specific design, where\nGNNs are commonly used for Lagrangian simulations and grid-based models\npredominate Eulerian simulations. We introduce Universal Physics Transformers\n(UPTs), an efficient and unified learning paradigm for a wide range of\nspatio-temporal problems. UPTs operate without grid- or particle-based latent\nstructures, enabling flexibility and scalability across meshes and particles.\nUPTs efficiently propagate dynamics in the latent space, emphasized by inverse\nencoding and decoding techniques. Finally, UPTs allow for queries of the latent\nspace representation at any point in space-time. We demonstrate diverse\napplicability and efficacy of UPTs in mesh-based fluid simulations, and\nsteady-state Reynolds averaged Navier-Stokes simulations, and Lagrangian-based\ndynamics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2024 18:52:13 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2024 17:15:35 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2024 12:52:04 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2024 07:48:24 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2025 10:24:17 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Alkin", "Benedikt", ""], ["F\u00fcrst", "Andreas", ""], ["Schmid", "Simon", ""], ["Gruber", "Lukas", ""], ["Holzleitner", "Markus", ""], ["Brandstetter", "Johannes", ""]], "extracted_entities": [{"text": "Universal Physics Transformers", "label": "Transformers"}, {"text": "UPTs", "label": "Transformers"}, {"text": "UPTs", "label": "Transformers"}, {"text": "UPTs", "label": "Transformers"}, {"text": "UPTs", "label": "Transformers"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2402.12714", "submitter": "Rui Jiao", "authors": "Rui Jiao, Xiangzhe Kong, Li Zhang, Ziyang Yu, Fangyuan Ren, Wenjuan\n  Tan, Wenbing Huang and Yang Liu", "title": "An Equivariant Pretrained Transformer for Unified 3D Molecular\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pretraining on a large number of unlabeled 3D molecules has showcased\nsuperiority in various scientific applications. However, prior efforts\ntypically focus on pretraining models in a specific domain, either proteins or\nsmall molecules, missing the opportunity to leverage cross-domain knowledge. To\nmitigate this gap, we introduce Equivariant Pretrained Transformer (EPT), an\nall-atom foundation model that can be pretrained from multiple domain 3D\nmolecules. Built upon an E(3)-equivariant transformer, EPT is able to not only\nprocess atom-level information but also incorporate block-level features (e.g.\nresiduals in proteins). Additionally, we employ a block-level denoising task,\nrather than the conventional atom-level denoising, as the pretraining\nobjective. To pretrain EPT, we construct a large-scale dataset of 5.89M\nentries, comprising small molecules, proteins, protein-protein complexes, and\nprotein-molecule complexes. Experimental evaluations on downstream tasks\nincluding ligand binding affinity prediction, protein property prediction, and\nmolecular property prediction, show that EPT significantly outperforms previous\nstate-of-the-art methods in the first task and achieves competitively superior\nperformance for the remaining two tasks. Furthermore, we demonstrate the\npotential of EPT in identifying small molecule drug candidates targeting 3CL\nprotease, a critical target in the replication of SARS-CoV-2. Among 1,978\nFDA-approved drugs, EPT ranks 7 out of 8 known anti-COVID-19 drugs in the top\n200, indicating the high recall of EPT. By using Molecular Dynamics (MD)\nsimulations, EPT further discoveries 7 novel compounds whose binding affinities\nare higher than that of the top-ranked known anti-COVID-19 drug, showcasing its\npowerful capabilities in drug discovery.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2024 04:40:00 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 11:33:06 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Jiao", "Rui", ""], ["Kong", "Xiangzhe", ""], ["Zhang", "Li", ""], ["Yu", "Ziyang", ""], ["Ren", "Fangyuan", ""], ["Tan", "Wenjuan", ""], ["Huang", "Wenbing", ""], ["Liu", "Yang", ""]], "extracted_entities": [{"text": "Equivariant Pretrained Transformer", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}, {"text": "EPT", "label": "Foundation Model"}], "human_readable_topic": "Molecular and Protein Representation Learning"}
{"id": "2402.13726", "submitter": "Otmar Ertl", "authors": "Otmar Ertl", "title": "ExaLogLog: Space-Efficient and Practical Approximate Distinct Counting\n  up to the Exa-Scale", "comments": "14 pages, accepted at EDBT 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces ExaLogLog, a new data structure for approximate distinct\ncounting, which has the same practical properties as the popular HyperLogLog\nalgorithm. It is commutative, idempotent, mergeable, reducible, has a\nconstant-time insert operation, and supports distinct counts up to the\nexa-scale. At the same time, as theoretically derived and experimentally\nverified, it requires 43% less space to achieve the same estimation error.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2024 11:39:33 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 14:08:15 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Ertl", "Otmar", ""]], "extracted_entities": [{"text": "ExaLogLog", "label": "Embedding"}], "human_readable_topic": "Efficient Pruning of Large Language Models"}
{"id": "2402.13758", "submitter": "Zheheng Luo", "authors": "Zheheng Luo, Qianqian Xie, Sophia Ananiadou", "title": "Factual consistency evaluation of summarization in the Era of large\n  language models", "comments": "published on ESWA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Factual inconsistency with source documents in automatically generated\nsummaries can lead to misinformation or pose risks. Existing factual\nconsistency (FC) metrics are constrained by their performance, efficiency, and\nexplainability. Recent advances in Large language models (LLMs) have\ndemonstrated remarkable potential in text evaluation but their effectiveness in\nassessing FC in summarization remains underexplored. Prior research has mostly\nfocused on proprietary LLMs, leaving essential factors that affect their\nassessment capabilities unexplored. Additionally, current FC evaluation\nbenchmarks are restricted to news articles, casting doubt on the generality of\nthe FC methods tested on them. In this paper, we first address the gap by\nintroducing TreatFact a dataset of LLM-generated summaries of clinical texts,\nannotated for FC by domain experts. Moreover, we benchmark 11 LLMs for FC\nevaluation across news and clinical domains and analyse the impact of model\nsize, prompts, pre-training and fine-tuning data. Our findings reveal that\ndespite proprietary models prevailing on the task, open-source LLMs lag behind.\nNevertheless, there is potential for enhancing the performance of open-source\nLLMs through increasing model size, expanding pre-training data, and developing\nwell-curated fine-tuning data. Experiments on TreatFact suggest that both\nprevious methods and LLM-based evaluators are unable to capture factual\ninconsistencies in clinical summaries, posing a new challenge for FC\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2024 12:35:19 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 09:26:10 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Luo", "Zheheng", ""], ["Xie", "Qianqian", ""], ["Ananiadou", "Sophia", ""]], "extracted_entities": [{"text": "Large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompts", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Text Summarization with Large Language Models"}
{"id": "2402.16319", "submitter": "Runyu Peng", "authors": "Runyu Peng, Yunhua Zhou, Qipeng Guo, Yang Gao, Hang Yan, Xipeng Qiu,\n  Dahua Lin", "title": "Data-free Weight Compress and Denoise for Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large Language Models (LLMs) are reshaping the research landscape in\nartificial intelligence, particularly as model parameters scale up\nsignificantly, unlocking remarkable capabilities across various domains.\nNevertheless, the scalability of model parameters faces constraints due to\nlimitations in GPU memory and computational speed. To address these\nconstraints, various weight compression methods have emerged, such as Pruning\nand Quantization. Given the low-rank nature of weight matrices in language\nmodels, the reduction of weights through matrix decomposition undoubtedly holds\nsignificant potential and promise. In this paper, drawing upon the intrinsic\nstructure of LLMs, we propose a novel approach termed Data-free Joint Rank-k\nApproximation for compressing the parameter matrices. Significantly, our method\nis characterized by without necessitating additional involvement of any corpus,\nwhile simultaneously preserving orthogonality in conjunction with pruning and\nquantization methods. We achieve a model pruning of 80% parameters while\nretaining 93.43% of the original performance without any calibration data.\nAdditionally, we explore the fundamental properties of the weight matrix of\nLLMs undergone Rank-k Approximation and conduct comprehensive experiments to\nelucidate our hypothesis.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2024 05:51:47 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 07:41:18 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Peng", "Runyu", ""], ["Zhou", "Yunhua", ""], ["Guo", "Qipeng", ""], ["Gao", "Yang", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Lin", "Dahua", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "Pruning", "label": "quantisation"}, {"text": "Quantization", "label": "quantisation"}, {"text": "pruning", "label": "quantisation"}], "human_readable_topic": "Efficient Pruning Methods for Large Language Models"}
{"id": "2402.17073", "submitter": "Abhishek Dalvi", "authors": "Abhishek Dalvi, Vasant Honavar", "title": "Hyperdimensional Representation Learning for Node Classification and\n  Link Prediction", "comments": "Accepted by WSDM 2025", "journal-ref": null, "doi": "10.1145/3701551.3703492", "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Hyperdimensional Graph Learner (HDGL), a novel method for node\nclassification and link prediction in graphs. HDGL maps node features into a\nvery high-dimensional space (\\textit{hyperdimensional} or HD space for short)\nusing the \\emph{injectivity} property of node representations in a family of\nGraph Neural Networks (GNNs) and then uses HD operators such as\n\\textit{bundling} and \\textit{binding} to aggregate information from the local\nneighborhood of each node yielding latent node representations that can support\nboth node classification and link prediction tasks. HDGL, unlike GNNs that rely\non computationally expensive iterative optimization and hyperparameter tuning,\nrequires only a single pass through the data set. We report results of\nexperiments using widely used benchmark datasets which demonstrate that, on the\nnode classification task, HDGL achieves accuracy that is competitive with that\nof the state-of-the-art GNN methods at substantially reduced computational\ncost; and on the link prediction task, HDGL matches the performance of DeepWalk\nand related methods, although it falls short of computationally demanding\nstate-of-the-art GNNs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2024 23:15:01 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2024 03:46:13 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 00:21:39 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Dalvi", "Abhishek", ""], ["Honavar", "Vasant", ""]], "extracted_entities": [{"text": "hyperparameter tuning", "label": "Fine-tuning"}], "human_readable_topic": "Hypergraph and Graph Neural Networks"}
{"id": "2402.18599", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Atik Faysal, Huaxia Wang and Avimanyu Sahoo", "title": "Meta-Task: A Method-Agnostic Framework for Learning to Regularize in\n  Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Overfitting is a significant challenge in Few-Shot Learning (FSL), where\nmodels trained on small, variable datasets tend to memorize rather than\ngeneralize to unseen tasks. Regularization is crucial in FSL to prevent\noverfitting and enhance generalization performance. To address this issue, we\nintroduce Meta-Task, a novel, method-agnostic framework that leverages both\nlabeled and unlabeled data to enhance generalization through auxiliary tasks\nfor regularization. Specifically, Meta-Task introduces a Task-Decoder, which is\na simple example of the broader framework that refines hidden representations\nby reconstructing input images from embeddings, effectively mitigating\noverfitting.\n  Our framework's method-agnostic design ensures its broad applicability across\nvarious FSL settings. We validate Meta-Task's effectiveness on standard\nbenchmarks, including Mini-ImageNet, Tiered-ImageNet, and FC100, where it\nconsistently improves existing state-of-the-art meta-learning techniques,\ndemonstrating superior performance, faster convergence, reduced generalization\nerror, and lower variance-all without extensive hyperparameter tuning. These\nresults underline Meta-Task's practical applicability and efficiency in\nreal-world, resource-constrained scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2024 21:15:40 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 23:07:40 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Rostami", "Mohammad", ""], ["Faysal", "Atik", ""], ["Wang", "Huaxia", ""], ["Sahoo", "Avimanyu", ""]], "extracted_entities": [{"text": "Few-Shot Learning", "label": "Few-shot Learning"}, {"text": "FSL", "label": "Few-shot Learning"}, {"text": "FSL", "label": "Few-shot Learning"}, {"text": "embeddings", "label": "Embedding"}, {"text": "FSL", "label": "Few-shot Learning"}, {"text": "hyperparameter tuning", "label": "Fine-tuning"}], "human_readable_topic": "Prompt Tuning for Few-Shot Learning Tasks"}
{"id": "2402.18895", "submitter": "Andr\\'es Vallejo", "authors": "Andr\\'es Vallejo, Alejandro Romanelli, Virginia Feldman and Ra\\'ul\n  Donangelo", "title": "Evolution of expected values in open quantum systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a generalization of Ehrenfest theorem valid for open quantum\nsystems. From this result, we identify three contributions to the evolution of\nexpected values: i) the explicit time dependence of the observable, ii) the\nincompatibility between the observable and an operator which plays the role of\nan effective Hamiltonian, and iii) entropy changes. Considering the local\nHamiltonian as the observable, and adopting a specific interpretation of the\nnature of thermal interactions, we obtain an alternative version of the first\nlaw of thermodynamics. Within this framework, we show that in some cases the\npower performed by the system can be considered as a quantum observable. As an\napplication, the pure dephasing process is reinterpreted from this perspective.\n", "versions": [{"version": "v1", "created": "Thu, 29 Feb 2024 06:47:28 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 08:35:55 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Vallejo", "Andr\u00e9s", ""], ["Romanelli", "Alejandro", ""], ["Feldman", "Virginia", ""], ["Donangelo", "Ra\u00fal", ""]], "extracted_entities": [{"text": "first\nlaw of thermodynamics", "label": "Scaling law"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2402.18945", "submitter": "Pengzhou Cheng", "authors": "Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Zhuosheng\n  Zhang, Gongshen Liu", "title": "SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via\n  Syntactic Transfer", "comments": "17 pages, 16 figures, 12 tables, accepted at NAACL 2025 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although pre-training achieves remarkable performance, it suffers from\ntask-agnostic backdoor attacks due to vulnerabilities in data and training\nmechanisms. These attacks can transfer backdoors to various downstream tasks.\nIn this paper, we introduce $\\mathtt{maxEntropy}$, an entropy-based poisoning\nfilter that mitigates such risks. To overcome the limitations of manual target\nsetting and explicit triggers, we propose $\\mathtt{SynGhost}$, an invisible and\nuniversal task-agnostic backdoor attack via syntactic transfer, further\nexposing vulnerabilities in pre-trained language models (PLMs). Specifically,\n$\\mathtt{SynGhost}$ injects multiple syntactic backdoors into the pre-training\nspace through corpus poisoning, while preserving the PLM's pre-training\ncapabilities. Second, $\\mathtt{SynGhost}$ adaptively selects optimal targets\nbased on contrastive learning, creating a uniform distribution in the\npre-training space. To identify syntactic differences, we also introduce an\nawareness module to minimize interference between backdoors. Experiments show\nthat $\\mathtt{SynGhost}$ poses significant threats and can transfer to various\ndownstream tasks. Furthermore, $\\mathtt{SynGhost}$ resists defenses based on\nperplexity, fine-pruning, and $\\mathtt{maxEntropy}$. The code is available at\nhttps://github.com/Zhou-CyberSecurity-AI/SynGhost.\n", "versions": [{"version": "v1", "created": "Thu, 29 Feb 2024 08:20:49 GMT"}, {"version": "v2", "created": "Fri, 24 May 2024 15:21:55 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 12:40:42 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Cheng", "Pengzhou", ""], ["Du", "Wei", ""], ["Wu", "Zongru", ""], ["Zhang", "Fengwei", ""], ["Chen", "Libo", ""], ["Zhang", "Zhuosheng", ""], ["Liu", "Gongshen", ""]], "extracted_entities": [{"text": "contrastive learning", "label": "Few-shot Learning"}, {"text": "fine-pruning", "label": "Fine-tuning"}], "human_readable_topic": "Backdoor Attacks on Large Language Models"}
{"id": "2402.19097", "submitter": "Alexander Shabalin", "authors": "Alexander Shabalin, Viacheslav Meshchaninov, Egor Chimbulatov,\n  Vladislav Lapikov, Roman Kim, Grigory Bartosh, Dmitry Molchanov, Sergey\n  Markov, Dmitry Vetrov", "title": "TEncDM: Understanding the Properties of the Diffusion Model in the Space\n  of Language Model Encodings", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the Text Encoding Diffusion Model (TEncDM), a novel\napproach to diffusion modeling that operates in the space of pre-trained\nlanguage model encodings. In contrast to traditionally used embeddings,\nencodings integrate contextual information. In our approach, we also employ a\ntransformer-based decoder, specifically designed to incorporate context in the\ntoken prediction process. We conduct a comprehensive examination of the\ninfluence of the encoder, decoder, noise scheduler, and self-conditioning on\nzero-shot generation. Furthermore, we compare TEncDM with previous approaches\non three conditional text generation tasks: QQP, XSum, and Wiki-Auto. The\nresults show that TEncDM exhibits superior performance compared to existing\nnon-autoregressive diffusion models. Our code is available at\nhttps://github.com/M0RJIQUE/tencdm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Feb 2024 12:25:45 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2024 09:35:24 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2024 16:30:58 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 13:06:32 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Shabalin", "Alexander", ""], ["Meshchaninov", "Viacheslav", ""], ["Chimbulatov", "Egor", ""], ["Lapikov", "Vladislav", ""], ["Kim", "Roman", ""], ["Bartosh", "Grigory", ""], ["Molchanov", "Dmitry", ""], ["Markov", "Sergey", ""], ["Vetrov", "Dmitry", ""]], "extracted_entities": [{"text": "embeddings", "label": "Embedding"}, {"text": "encodings", "label": "Embedding"}, {"text": "zero-shot generation", "label": "Zero-shot Learning"}], "human_readable_topic": "Diffusion Models for NLP"}
{"id": "2403.00062", "submitter": "Serhii Kryhin", "authors": "Serhii Kryhin, Subir Sachdev, Pavel A. Volkov", "title": "Strong non-linear response of strange metals", "comments": "5 pages, 2 figures, 6 Supplemental Information sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.str-el", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that nonlinear transport responses in strange metals are strong,\nlarger by a factor of $E_F/T$ than in Fermi liquids. Within the two-dimensional\nYukawa-Sachdev-Ye-Kitaev model of a Fermi surface with a spatially random\ncoupling to a critical scalar, the third order conductivity is found to diverge\nas $1/T$ at low $T$, indicating the existence of a voltage-temperature scaling\nregime in the conductance. Its frequency and orientation dependence contains\ninformation on relaxation times of heat and electron distribution deformations,\nproviding a new set of tools to characterize strange metals.\n", "versions": [{"version": "v1", "created": "Thu, 29 Feb 2024 19:00:09 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2024 20:23:33 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 04:41:18 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Kryhin", "Serhii", ""], ["Sachdev", "Subir", ""], ["Volkov", "Pavel A.", ""]], "extracted_entities": [{"text": "voltage-temperature scaling\nregime", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2403.01500", "submitter": "Chan-Ho Kim", "authors": "Chan-Ho Kim", "title": "On the adjoint Selmer groups of semi-stable elliptic curves and Flach's\n  zeta elements", "comments": "A reference update is made. There is no change in the content.\n  Comments are very welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explicitly construct the rank one primitive Stark (equivalently,\nKolyvagin) system extending a constant multiple of Flach's zeta elements for\nsemi-stable elliptic curves. As its arithmetic applications, we obtain the\nequivalence between a specific behavior of the Stark system and the minimal\nmodularity lifting theorem, and we also discuss the cyclicity of the adjoint\nSelmer groups. This Stark system construction yields a more refined\ninterpretation of the collection of Flach's zeta elements than the \"geometric\nEuler system\" approach due to Flach, Wiles, Mazur, and Weston.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2024 12:23:32 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2024 05:10:58 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2024 14:15:49 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 13:46:21 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Kim", "Chan-Ho", ""]], "extracted_entities": [{"text": "Stark", "label": "BERT"}, {"text": "Stark system", "label": "BERT"}, {"text": "Stark system", "label": "BERT"}], "human_readable_topic": "Uncategorized"}
{"id": "2403.01529", "submitter": "Cong Li", "authors": "Cong Li", "title": "Deep Incremental Model Informed Reinforcement Learning for Continuous\n  Robotic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning attempts to use an available or learned\nmodel to improve the data efficiency of reinforcement learning. This work\nproposes a one-step lookback approach that jointly learns the deep incremental\nmodel and the policy to realize the sample-efficient continuous robotic\ncontrol, wherein the control-theoretical knowledge is utilized to decrease the\nmodel learning difficulty and facilitate efficient training. Specifically, we\nuse one-step backward data to facilitate the deep incremental model, an\nalternative structured representation of the robotic evolution model, that\naccurately predicts the robotic movement but with low sample complexity. This\nis because the formulated deep incremental model degrades the model learning\ndifficulty into a parametric matrix learning problem, which is especially\nfavourable to high-dimensional robotic applications. The imagined data from the\nlearned deep incremental model is used to supplement training data to enhance\nthe sample efficiency. Comparative numerical simulations on benchmark\ncontinuous robotics control problems are conducted to validate the efficiency\nof our proposed one-step lookback approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2024 15:00:54 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 10:24:17 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Li", "Cong", ""]], "extracted_entities": [{"text": "Model-based reinforcement learning", "label": "Few-shot Learning"}, {"text": "deep incremental\nmodel", "label": "AI model"}, {"text": "deep incremental model", "label": "AI model"}, {"text": "deep incremental model", "label": "AI model"}, {"text": "deep incremental model", "label": "AI model"}], "human_readable_topic": "Reinforcement Learning with Transformers"}
{"id": "2403.02774", "submitter": "Philipp Hess", "authors": "Philipp Hess, Michael Aich, Baoxiang Pan, and Niklas Boers", "title": "Fast, Scale-Adaptive, and Uncertainty-Aware Downscaling of Earth System\n  Model Fields with Generative Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate and high-resolution Earth system model (ESM) simulations are\nessential to assess the ecological and socio-economic impacts of anthropogenic\nclimate change, but are computationally too expensive to be run at sufficiently\nhigh spatial resolution. Recent machine learning approaches have shown\npromising results in downscaling ESM simulations, outperforming\nstate-of-the-art statistical approaches. However, existing methods require\ncomputationally costly retraining for each ESM and extrapolate poorly to\nclimates unseen during training. We address these shortcomings by learning a\nconsistency model (CM) that efficiently and accurately downscales arbitrary ESM\nsimulations without retraining in a zero-shot manner. Our approach yields\nprobabilistic downscaled fields at a resolution only limited by the\nobservational reference data. We show that the CM outperforms state-of-the-art\ndiffusion models at a fraction of computational cost while maintaining high\ncontrollability on the downscaling task. Further, our method generalizes to\nclimate states unseen during training without explicitly formulated physical\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2024 08:41:41 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2025 11:30:30 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2025 11:14:57 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 11:43:09 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Hess", "Philipp", ""], ["Aich", "Michael", ""], ["Pan", "Baoxiang", ""], ["Boers", "Niklas", ""]], "extracted_entities": [{"text": "zero-shot manner", "label": "Zero-shot Learning"}], "human_readable_topic": "Deep Learning for Weather Forecasting"}
{"id": "2403.03761", "submitter": "Xin Wang", "authors": "Yin Mo, Lei Zhang, Yu-Ao Chen, Yingjian Liu, Tengxiang Lin, Xin Wang", "title": "Parameterized quantum comb and simpler circuits for reversing unknown\n  qubit-unitary operations", "comments": "16 pages including appendix, v2 is accepted version", "journal-ref": "npj Quantum Information volume 11, Article number: 32 (2025)", "doi": "10.1038/s41534-025-00979-1", "report-no": null, "categories": "quant-ph cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum combs play a vital role in characterizing and transforming quantum\nprocesses, with wide-ranging applications in quantum information processing.\nHowever, obtaining the explicit quantum circuit for the desired quantum comb\nremains a challenging problem. We propose PQComb, a novel framework that\nemploys parameterized quantum circuits (PQCs) or quantum neural networks to\nharness the full potential of quantum combs for diverse quantum process\ntransformation tasks. This method is well-suited for near-term quantum devices\nand can be applied to various tasks in quantum machine learning. As a notable\napplication, we present two streamlined protocols for the time-reversal\nsimulation of unknown qubit unitary evolutions, reducing the ancilla qubit\noverhead from six to three compared to the previous best-known method. We also\nextend PQComb to solve the problems of qutrit unitary transformation and\nchannel discrimination. Furthermore, we demonstrate the hardware efficiency and\nrobustness of our qubit unitary inversion protocol under realistic noise\nsimulations of IBM-Q superconducting quantum hardware, yielding a significant\nimprovement in average similarity over the previous protocol under practical\nregimes. PQComb's versatility and potential for broader applications in quantum\nmachine learning pave the way for more efficient and practical solutions to\ncomplex quantum tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2024 14:53:24 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 08:28:19 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Mo", "Yin", ""], ["Zhang", "Lei", ""], ["Chen", "Yu-Ao", ""], ["Liu", "Yingjian", ""], ["Lin", "Tengxiang", ""], ["Wang", "Xin", ""]], "extracted_entities": [{"text": "quantum machine learning", "label": "Few-shot Learning"}, {"text": "unknown qubit unitary evolutions", "label": "quantisation"}, {"text": "qutrit unitary transformation", "label": "quantisation"}, {"text": "quantum\nmachine learning", "label": "Few-shot Learning"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2403.05061", "submitter": "Geonho Bang", "authors": "Geonho Bang, Kwangjin Choi, Jisong Kim, Dongsuk Kum, Jun Won Choi", "title": "RadarDistill: Boosting Radar-based Object Detection Performance via\n  Knowledge Distillation from LiDAR Features", "comments": "Accepted to CVPR 2024. Code available at\n  https://github.com/geonhobang/RadarDistill", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inherent noisy and sparse characteristics of radar data pose challenges\nin finding effective representations for 3D object detection. In this paper, we\npropose RadarDistill, a novel knowledge distillation (KD) method, which can\nimprove the representation of radar data by leveraging LiDAR data. RadarDistill\nsuccessfully transfers desirable characteristics of LiDAR features into radar\nfeatures using three key components: Cross-Modality Alignment (CMA),\nActivation-based Feature Distillation (AFD), and Proposal-based Feature\nDistillation (PFD). CMA enhances the density of radar features by employing\nmultiple layers of dilation operations, effectively addressing the challenge of\ninefficient knowledge transfer from LiDAR to radar. AFD selectively transfers\nknowledge based on regions of the LiDAR features, with a specific focus on\nareas where activation intensity exceeds a predefined threshold. PFD similarly\nguides the radar network to selectively mimic features from the LiDAR network\nwithin the object proposals. Our comparative analyses conducted on the nuScenes\ndatasets demonstrate that RadarDistill achieves state-of-the-art (SOTA)\nperformance for radar-only object detection task, recording 20.5% in mAP and\n43.7% in NDS. Also, RadarDistill significantly improves the performance of the\ncamera-radar fusion model.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2024 05:15:48 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2024 00:43:16 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 13:41:29 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Bang", "Geonho", ""], ["Choi", "Kwangjin", ""], ["Kim", "Jisong", ""], ["Kum", "Dongsuk", ""], ["Choi", "Jun Won", ""]], "extracted_entities": [{"text": "RadarDistill", "label": "Knowledge distillation"}, {"text": "RadarDistill", "label": "Knowledge distillation"}, {"text": "CMA", "label": "Knowledge distillation"}, {"text": "Activation-based Feature Distillation", "label": "Knowledge distillation"}, {"text": "AFD", "label": "Knowledge distillation"}, {"text": "Proposal-based Feature\nDistillation", "label": "Knowledge distillation"}, {"text": "PFD", "label": "Knowledge distillation"}, {"text": "CMA", "label": "Knowledge distillation"}, {"text": "AFD", "label": "Knowledge distillation"}, {"text": "PFD", "label": "Knowledge distillation"}, {"text": "RadarDistill", "label": "Knowledge distillation"}, {"text": "RadarDistill", "label": "Knowledge distillation"}], "human_readable_topic": "3D Object Detection with LiDAR and Cameras"}
{"id": "2403.05608", "submitter": "Marios Maroudas", "authors": "K. Zioutas, A. Zhitnitsky, C. Zamantzas, Y. K. Semertzidis, O. M.\n  Ruimi, K. Ozbozduman, M. Maroudas, A. Kryemadhi, M. Karuza, D. Horns, A.\n  Gougas, S. Cetin, G. Cantatore, D. Budker", "title": "Search for anti-quark nuggets via their interaction with the LHC beam", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex astro-ph.IM hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anti-quark nuggets (AQNs) have been suggested to solve the dark matter (DM)\nand the missing antimatter problem in the universe and have been proposed as an\nexplanation of various observations. Their size is in the {\\mu}m range and\ntheir density is about equal to the nuclear density with an expected flux of\nabout $0.4 / km^2 / year$. For the typical velocity of DM constituents\n($\\sim$250 km/s), the solar system bodies act as highly performing\ngravitational lenses. Here we assume that DM streams or clusters are impinging,\ne.g., on the Earth, as it was worked out for DM axions and Weakly Interacting\nMassive Particles (WIMPs). Interestingly, in the LHC beam, unforeseen beam\nlosses are triggered by so-called Unidentified Falling Objects (UFOs), which\nare believed to be constituted of dust particles with a size in the {\\mu}m\nrange and a density of several orders of magnitude lower than AQNs. Prezeau\nsuggested that streaming DM constituents incident on the Earth should result in\njet-like structures (\"hairs\") exiting the Earth, or a kind of caustics. Such\nideas open novel directions in the search for DM. This work suggests a new\nanalysis of the UFO results at the Large Hadron Collider (LHC), assuming that\nthey are eventually, at least partly, due to AQNs. Firstly, a reanalysis of the\nexisting data from the 4000 beam monitors since the beginning of the LHC is\nproposed, arguing that dust and AQNs should behave differently. The feasibility\nof this idea has been discussed with CERN accelerator people and potential\ncollaborators.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2024 10:21:36 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 13:36:11 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zioutas", "K.", ""], ["Zhitnitsky", "A.", ""], ["Zamantzas", "C.", ""], ["Semertzidis", "Y. K.", ""], ["Ruimi", "O. M.", ""], ["Ozbozduman", "K.", ""], ["Maroudas", "M.", ""], ["Kryemadhi", "A.", ""], ["Karuza", "M.", ""], ["Horns", "D.", ""], ["Gougas", "A.", ""], ["Cetin", "S.", ""], ["Cantatore", "G.", ""], ["Budker", "D.", ""]], "extracted_entities": [{"text": "AQNs", "label": "LLMs"}, {"text": "AQNs", "label": "LLMs"}, {"text": "AQNs", "label": "LLMs"}, {"text": "AQNs", "label": "LLMs"}], "human_readable_topic": "Particle Detection and Classification in High Energy Physics"}
{"id": "2403.06461", "submitter": "Haozhi Cao", "authors": "Haozhi Cao, Yuecong Xu, Pengyu Yin, Xingyu Ji, Shenghai Yuan, Jianfei\n  Yang, Lihua Xie", "title": "Latte++: Spatial-Temporal Voxel-based Test-Time Adaptation for\n  Multi-Modal Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-modal test-time adaptation (MM-TTA) is proposed to adapt models to an\nunlabeled target domain by leveraging the complementary multi-modal inputs in\nan online manner. Previous MM-TTA methods for 3D segmentation rely on\npredictions of cross-modal information in each input frame, while they ignore\nthe fact that predictions of geometric neighborhoods within consecutive frames\nare highly correlated, leading to unstable predictions across time. To fulfill\nthis gap, we propose ReLiable Spatial-temporal Voxels (Latte), an MM-TTA method\nthat leverages reliable cross-modal spatial-temporal correspondences for\nmulti-modal 3D segmentation. Motivated by the fact that reliable predictions\nshould be consistent with their spatial-temporal correspondences, Latte\naggregates consecutive frames in a sliding-window manner and constructs\nSpatial-Temporal (ST) voxels to capture temporally local prediction consistency\nfor each modality. After filtering out ST voxels with high ST entropy, Latte\nconducts cross-modal learning for each point and pixel by attending to those\nwith reliable and consistent predictions among both spatial and temporal\nneighborhoods. Considering the prediction consistency might vary under\ndifferent sliding windows, we further propose Latte++ which leverages ST voxels\ngenerated under various sliding windows to more thoroughly evaluate intra-modal\nprediction consistency before the cross-modal fusion. Experimental results show\nthat both Latte and Latte++ achieve state-of-the-art performance on five MM-TTA\nbenchmarks compared to previous MM-TTA or TTA methods. Code will be available\nat https://github.com/AronCao49/Latte-plusplus.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2024 06:56:08 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2024 07:07:20 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2024 08:21:31 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 12:05:14 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Cao", "Haozhi", ""], ["Xu", "Yuecong", ""], ["Yin", "Pengyu", ""], ["Ji", "Xingyu", ""], ["Yuan", "Shenghai", ""], ["Yang", "Jianfei", ""], ["Xie", "Lihua", ""]], "extracted_entities": [{"text": "cross-modal learning", "label": "Few-shot Learning"}], "human_readable_topic": "CLIP Models for Visual Learning and Adaptation"}
{"id": "2403.07066", "submitter": "Benedikt Maier", "authors": "Philip Harris, Michael Kagan, Jeffrey Krupa, Benedikt Maier, Nathaniel\n  Woodward", "title": "Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation\n  Models", "comments": "14 pages, 8 figures", "journal-ref": "Phys. Rev. D 111 (2025) 3, 032010", "doi": "10.1103/PhysRevD.111.032010", "report-no": null, "categories": "hep-ph cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-Supervised Learning (SSL) is at the core of training modern large\nmachine learning models, providing a scheme for learning powerful\nrepresentations that can be used in a variety of downstream tasks. However, SSL\nstrategies must be adapted to the type of training data and downstream tasks\nrequired. We propose RS3L (\"Re-simulation-based self-supervised representation\nlearning\"), a novel simulation-based SSL strategy that employs a method of\nre-simulation to drive data augmentation for contrastive learning in the\nphysical sciences, particularly, in fields that rely on stochastic simulators.\nBy intervening in the middle of the simulation process and re-running\nsimulation components downstream of the intervention, we generate multiple\nrealizations of an event, thus producing a set of augmentations covering all\nphysics-driven variations available in the simulator. Using experiments from\nhigh-energy physics, we explore how this strategy may enable the development of\na foundation model; we show how RS3L pre-training enables powerful performance\nin downstream tasks such as discrimination of a variety of objects and\nuncertainty mitigation. In addition to our results, we make the RS3L dataset\npublicly available for further studies on how to improve SSL strategies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2024 18:00:47 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 00:08:55 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Harris", "Philip", ""], ["Kagan", "Michael", ""], ["Krupa", "Jeffrey", ""], ["Maier", "Benedikt", ""], ["Woodward", "Nathaniel", ""]], "extracted_entities": [{"text": "Self-Supervised Learning", "label": "Few-shot Learning"}, {"text": "foundation model", "label": "Foundation Model"}], "human_readable_topic": "Self-Supervised Learning in Medical Imaging"}
{"id": "2403.08369", "submitter": "Ishita Modak", "authors": "Soumya Bera, Ishita Modak, Roderich Moessner", "title": "Inhomogeneous Floquet thermalization", "comments": "8 pages, 7 figures", "journal-ref": "Phys. Rev. B 109, 224206 (2024)", "doi": "10.1103/PhysRevB.109.224206", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How a closed system thermalizes, especially in the absence of global\nconservation laws but in the presence of disorder and interactions, is one of\nthe central questions in non-equilibrium statistical mechanics. We explore this\nfor a disordered, periodically driven Ising chain. Our numerical results reveal\ninhomogeneous thermalization leading to a distribution of thermalization\ntimescales within a single disordered sample, which we encode via a\ndistribution of effective local temperatures. Using this, we find an excellent\ncollapse $\\textit{without}$ $\\textit{any}$ $\\textit{fitting}$\n$\\textit{parameters}$ of the local relaxation dynamics for the entire range of\ndisorder values in the ergodic regime when adapting the disorder-averaged\ndiagonal entanglement entropy as internal `time' of the system. This approach\nevidences a remarkably uniform parametrization of the dynamical many-body\nevolution of local temperature within the otherwise highly heterogeneous\nergodic regime, independent of the strength of the disorder.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2024 09:30:31 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 07:54:49 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Bera", "Soumya", ""], ["Modak", "Ishita", ""], ["Moessner", "Roderich", ""]], "extracted_entities": [{"text": "global\nconservation laws", "label": "Scaling law"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2403.11010", "submitter": "Wolfgang Seiringer", "authors": "Wolfgang Seiringer, Klaus Altendorfer, Thomas Felberbauer, Balwin\n  Bokor, Fabian Brockmann", "title": "How Periodic Forecast Updates Influence MRP Planning Parameters: A\n  Simulation Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many supply chains, the current efforts at digitalization have led to\nimproved information exchanges between manufacturers and their customers.\nSpecifically, demand forecasts are often provided by the customers and\nregularly updated as the related customer information improves. In this paper,\nwe investigate the influence of forecast updates on the production planning\nmethod of Material Requirements Planning (MRP). A simulation study was carried\nout to assess how updates in information affect the setting of planning\nparameters in a rolling horizon MRP planned production system. An intuitive\nresult is that information updates lead to disturbances in the production\norders for the MRP standard, and, therefore, an extension for MRP to mitigate\nthese effects is developed. A large numerical simulation experiment shows that\nthe MRP safety stock exploitation heuristic, that has been developed, leads to\nsignificantly improved results as far as inventory and backorder costs are\nconcerned. An interesting result is that the fixed-order-quantity lotsizing\npolicy performs - in most instances - better than the fixed-order-period\nlotsizing policy, when periodic forecast updates occur. In addition, the\nsimulation study shows that underestimating demand is marginally more costly\nthan overestimating it, based on the comparative analysis of all instances.\nFurthermore, the results indicate that the MRP safety stock exploitation\nheuristic can mitigate the negative effects of biased forecasts.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2024 20:18:43 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2024 07:27:01 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 12:59:59 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Seiringer", "Wolfgang", ""], ["Altendorfer", "Klaus", ""], ["Felberbauer", "Thomas", ""], ["Bokor", "Balwin", ""], ["Brockmann", "Fabian", ""]], "extracted_entities": [{"text": "digitalization", "label": "quantisation"}], "human_readable_topic": "Time Series Prediction and Forecasting Models"}
{"id": "2403.11807", "submitter": "Jen-Tse Huang", "authors": "Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang,\n  Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R. Lyu", "title": "How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming\n  Ability in Multi-Agent Environments", "comments": "Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;\n  Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,\n  Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,\n  Qwen-2-72B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making is a complex process requiring diverse abilities, making it\nan excellent framework for evaluating Large Language Models (LLMs). Researchers\nhave examined LLMs' decision-making through the lens of Game Theory. However,\nexisting evaluation mainly focus on two-player scenarios where an LLM competes\nagainst another. Additionally, previous benchmarks suffer from test set leakage\ndue to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework\nfor evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes\neight classical game theory scenarios and a dynamic scoring scheme specially\ndesigned to quantitatively assess LLMs' performance. $\\gamma$-Bench allows\nflexible game settings and adapts the scoring system to different game\nparameters, enabling comprehensive evaluation of robustness, generalizability,\nand strategies for improvement. Our results indicate that GPT-3.5 demonstrates\nstrong robustness but limited generalizability, which can be enhanced using\nmethods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,\nincluding GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.\nGemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by\nLLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental\nresults are publicly available at https://github.com/CUHK-ARISE/GAMABench.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2024 14:04:47 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2024 15:04:41 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2024 01:14:30 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2024 20:57:58 GMT"}, {"version": "v5", "created": "Sun, 9 Feb 2025 13:37:46 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2025 13:57:52 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Huang", "Jen-tse", ""], ["Li", "Eric John", ""], ["Lam", "Man Ho", ""], ["Liang", "Tian", ""], ["Wang", "Wenxuan", ""], ["Yuan", "Youliang", ""], ["Jiao", "Wenxiang", ""], ["Wang", "Xing", ""], ["Tu", "Zhaopeng", ""], ["Lyu", "Michael R.", ""]], "extracted_entities": [{"text": "Chain-of-Thought", "label": "Chain of thought"}, {"text": "GPT-4", "label": "GPT-4"}, {"text": "Mixtral", "label": "GPT-4"}], "human_readable_topic": "Large Language Models Development and Evaluation"}
{"id": "2403.11893", "submitter": "Uzi Pereg", "authors": "Hosen Nator and Uzi Pereg", "title": "Entanglement Coordination Rates in Multi-User Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal coordination rates are determined in three primary settings of\nmulti-user quantum networks, thus characterizing the minimal resources required\nin order to simulate a joint quantum state among multiple parties. We study the\nfollowing models: (1) a cascade network with rate-limited entanglement, (2) a\nbroadcast network, which consists of a single sender and two receivers, (3) a\nmultiple-access network with two senders and a single receiver. We establish\nthe necessary and sufficient conditions on the asymptotically-achievable\ncommunication and entanglement rates in each setting. At last, we show the\nimplications of our results on nonlocal games with quantum strategies.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2024 15:53:30 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2024 13:15:52 GMT"}, {"version": "v3", "created": "Wed, 1 May 2024 10:46:02 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 15:44:41 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Nator", "Hosen", ""], ["Pereg", "Uzi", ""]], "extracted_entities": [{"text": "rate-limited entanglement", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2403.12117", "submitter": "Josua Stadelmaier", "authors": "Josua Stadelmaier (University of T\\\"ubingen), Brandon Malone (NEC\n  OncoImmunity), Ralf Eggeling (University of T\\\"ubingen)", "title": "Transfer Learning for T-Cell Response Prediction", "comments": "25 pages, 10 figures. Source code, compiled data, final model, and a\n  video presentation are available under\n  https://github.com/JosuaStadelmaier/T-cell-response-prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the prediction of T-cell response for specific given peptides, which\ncould, among other applications, be a crucial step towards the development of\npersonalized cancer vaccines. It is a challenging task due to limited,\nheterogeneous training data featuring a multi-domain structure; such data\nentail the danger of shortcut learning, where models learn general\ncharacteristics of peptide sources, such as the source organism, rather than\nspecific peptide characteristics associated with T-cell response.\n  Using a transformer model for T-cell response prediction, we show that the\ndanger of inflated predictive performance is not merely theoretical but occurs\nin practice. Consequently, we propose a domain-aware evaluation scheme. We then\nstudy different transfer learning techniques to deal with the multi-domain\nstructure and shortcut learning. We demonstrate a per-source fine tuning\napproach to be effective across a wide range of peptide sources and further\nshow that our final model is competitive with existing state-of-the-art\napproaches for predicting T-cell responses for human peptides.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2024 17:32:19 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 21:40:40 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Stadelmaier", "Josua", "", "University of T\u00fcbingen"], ["Malone", "Brandon", "", "NEC\n  OncoImmunity"], ["Eggeling", "Ralf", "", "University of T\u00fcbingen"]], "extracted_entities": [{"text": "shortcut learning", "label": "Few-shot Learning"}, {"text": "shortcut learning", "label": "Few-shot Learning"}, {"text": "per-source fine tuning\napproach", "label": "Fine-tuning"}], "human_readable_topic": "Domain Generalization and Adaptation"}
{"id": "2403.12931", "submitter": "Yihong Luo", "authors": "Yihong Luo, Xiaolong Chen, Xinghua Qu, Tianyang Hu, Jing Tang", "title": "You Only Sample Once: Taming One-Step Text-to-Image Synthesis by\n  Self-Cooperative Diffusion GANs", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some works have tried to combine diffusion and Generative\nAdversarial Networks (GANs) to alleviate the computational cost of the\niterative denoising inference in Diffusion Models (DMs). However, existing\nworks in this line suffer from either training instability and mode collapse or\nsubpar one-step generation learning efficiency. To address these issues, we\nintroduce YOSO, a novel generative model designed for rapid, scalable, and\nhigh-fidelity one-step image synthesis with high training stability and mode\ncoverage. Specifically, we smooth the adversarial divergence by the denoising\ngenerator itself, performing self-cooperative learning. We show that our method\ncan serve as a one-step generation model training from scratch with competitive\nperformance. Moreover, we extend our YOSO to one-step text-to-image generation\nbased on pre-trained models by several effective training techniques (i.e.,\nlatent perceptual loss and latent discriminator for efficient training along\nwith the latent DMs; the informative prior initialization (IPI), and the quick\nadaption stage for fixing the flawed noise scheduler). Experimental results\nshow that YOSO achieves the state-of-the-art one-step generation performance\neven with Low-Rank Adaptation (LoRA) fine-tuning. In particular, we show that\nthe YOSO-PixArt-$\\alpha$ can generate images in one step trained on 512\nresolution, with the capability of adapting to 1024 resolution without extra\nexplicit training, requiring only ~10 A800 days for fine-tuning. Our code is\nprovided at https://github.com/Luo-Yihong/YOSO.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2024 17:34:27 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2024 14:48:42 GMT"}, {"version": "v3", "created": "Fri, 24 May 2024 13:01:32 GMT"}, {"version": "v4", "created": "Mon, 15 Jul 2024 14:51:48 GMT"}, {"version": "v5", "created": "Mon, 21 Oct 2024 07:32:04 GMT"}, {"version": "v6", "created": "Tue, 25 Feb 2025 10:09:17 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Luo", "Yihong", ""], ["Chen", "Xiaolong", ""], ["Qu", "Xinghua", ""], ["Hu", "Tianyang", ""], ["Tang", "Jing", ""]], "extracted_entities": [{"text": "self-cooperative learning", "label": "Few-shot Learning"}], "human_readable_topic": "Generative Adversarial Networks (GANs)"}
{"id": "2403.14692", "submitter": "Mike Perkins", "authors": "Leon Furze, Mike Perkins, Jasper Roe, Jason MacVaugh", "title": "The AI Assessment Scale (AIAS) in action: A pilot implementation of\n  GenAI supported assessment- A Preprint", "comments": null, "journal-ref": "Australasian Journal of Educational Technology 40 2024 38-55", "doi": "10.14742/ajet.9434", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The rapid adoption of Generative Artificial Intelligence (GenAI) technologies\nin higher education has raised concerns about academic integrity, assessment\npractices, and student learning. Banning or blocking GenAI tools has proven\nineffective, and punitive approaches ignore the potential benefits of these\ntechnologies. This paper presents the findings of a pilot study conducted at\nBritish University Vietnam (BUV) exploring the implementation of the Artificial\nIntelligence Assessment Scale (AIAS), a flexible framework for incorporating\nGenAI into educational assessments. The AIAS consists of five levels, ranging\nfrom 'No AI' to 'Full AI', enabling educators to design assessments that focus\non areas requiring human input and critical thinking.\n  Following the implementation of the AIAS, the pilot study results indicate a\nsignificant reduction in academic misconduct cases related to GenAI, a 5.9%\nincrease in student attainment across the university, and a 33.3% increase in\nmodule passing rates. The AIAS facilitated a shift in pedagogical practices,\nwith faculty members incorporating GenAI tools into their modules and students\nproducing innovative multimodal submissions. The findings suggest that the AIAS\ncan support the effective integration of GenAI in HE, promoting academic\nintegrity while leveraging the technology's potential to enhance learning\nexperiences.\n  Refer to published version for final text.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2024 08:00:02 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2024 01:47:10 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 10:47:46 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Furze", "Leon", ""], ["Perkins", "Mike", ""], ["Roe", "Jasper", ""], ["MacVaugh", "Jason", ""]], "extracted_entities": [{"text": "academic integrity", "label": "AI Ethics"}, {"text": "academic misconduct cases", "label": "AI Ethics"}, {"text": "academic\nintegrity", "label": "AI Ethics"}], "human_readable_topic": "AI Performance on Standardized Exams and Educational Assessments"}
{"id": "2403.15297", "submitter": "Tiansi Dong", "authors": "Tiansi Dong, Mateja Jamnik, Pietro Li\\`o", "title": "Sphere Neural-Networks for Rational Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The success of Large Language Models (LLMs), e.g., ChatGPT, is witnessed by\ntheir planetary popularity, their capability of human-like communication, and\nalso by their steadily improved reasoning performance. However, it remains\nunclear whether LLMs reason. It is an open problem how traditional neural\nnetworks can be qualitatively extended to go beyond the statistic paradigm and\nachieve high-level cognition. Here, we present a novel qualitative extension by\ngeneralising computational building blocks from vectors to spheres. We propose\nSphere Neural Networks (SphNNs) for human-like reasoning through model\nconstruction and inspection, and develop SphNN for syllogistic reasoning, a\nmicrocosm of human rationality. SphNN is a hierarchical neuro-symbolic\nKolmogorov-Arnold geometric GNN, and uses a neuro-symbolic transition map of\nneighbourhood spatial relations to transform the current sphere configuration\ntowards the target. SphNN is the first neural model that can determine the\nvalidity of long-chained syllogistic reasoning in one epoch without training\ndata, with the worst computational complexity of O(N). SphNN can evolve into\nvarious types of reasoning, such as spatio-temporal reasoning, logical\nreasoning with negation and disjunction, event reasoning, neuro-symbolic\nunification, and humour understanding (the highest level of cognition). All\nthese suggest a new kind of Herbert A. Simon's scissors with two neural blades.\nSphNNs will tremendously enhance interdisciplinary collaborations to develop\nthe two neural blades and realise deterministic neural reasoning and\nhuman-bounded rationality and elevate LLMs to reliable psychological AI. This\nwork suggests that the non-zero radii of spheres are the missing components\nthat prevent traditional deep-learning systems from reaching the realm of\nrational reasoning and cause LLMs to be trapped in the swamp of hallucination.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2024 15:44:59 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2024 20:02:20 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2024 19:45:42 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 15:48:11 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Dong", "Tiansi", ""], ["Jamnik", "Mateja", ""], ["Li\u00f2", "Pietro", ""]], "extracted_entities": [{"text": "ChatGPT", "label": "ChatGPT"}, {"text": "SphNNs", "label": "Neural Language Model"}, {"text": "SphNN", "label": "Neural Language Model"}, {"text": "long-chained syllogistic reasoning", "label": "Chain of thought"}, {"text": "spatio-temporal reasoning", "label": "Chain of thought"}, {"text": "event reasoning", "label": "Chain of thought"}, {"text": "neuro-symbolic\nunification", "label": "Chain of thought"}, {"text": "SphNNs", "label": "Neural Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Reasoning Capabilities of Large Language Models"}
{"id": "2403.16354", "submitter": "Nicolas Van Kempen", "authors": "Kyla Levin and Nicolas van Kempen and Emery D. Berger and Stephen N.\n  Freund", "title": "ChatDBG: An AI-Powered Debugging Assistant", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debugging is a critical but challenging task for programmers. This paper\nproposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large\nlanguage models (LLMs) to significantly enhance the capabilities and\nuser-friendliness of conventional debuggers. ChatDBG lets programmers engage in\na collaborative dialogue with the debugger, allowing them to pose complex\nquestions about program state, perform root cause analysis for crashes or\nassertion failures, and explore open-ended queries like `why is x null?'. To\nhandle these queries, ChatDBG grants the LLM autonomy to \"take the wheel\": it\ncan act as an independent agent capable of querying and controlling the\ndebugger to navigate through stacks and inspect program state. It then reports\nits findings and yields back control to the programmer. By leveraging the\nreal-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable\nonly through the use of domain-specific reasoning. Our ChatDBG prototype\nintegrates with standard debuggers including LLDB and GDB for native code and\nPdb for Python. Our evaluation across a diverse set of code, including C/C++\ncode with known bugs and a suite of Python code including standalone scripts\nand Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root\ncauses, explain bugs, and generate accurate fixes for a wide range of\nreal-world errors. For the Python programs, a single query led to an actionable\nbug fix 67% of the time; one additional follow-up query increased the success\nrate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more\nthan 65,000 times.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 01:12:57 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2024 15:07:24 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 22:18:54 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Levin", "Kyla", ""], ["van Kempen", "Nicolas", ""], ["Berger", "Emery D.", ""], ["Freund", "Stephen N.", ""]], "extracted_entities": [{"text": "ChatDBG", "label": "ChatGPT"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "ChatDBG", "label": "ChatGPT"}, {"text": "ChatDBG", "label": "ChatGPT"}], "human_readable_topic": "Automated Program Repair with Large Language Models"}
{"id": "2403.16362", "submitter": "Yihao Qin", "authors": "Yihao Qin, Shangwen Wang, Yiling Lou, Jinhao Dong, Kaixin Wang,\n  Xiaoling Li, Xiaoguang Mao", "title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context", "comments": "Added a comment to refer to the published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault Localization (FL) is an essential step during the debugging process.\nWith the strong capabilities of code comprehension, the recent Large Language\nModels (LLMs) have demonstrated promising performance in diagnosing bugs in the\ncode. Nevertheless, due to LLMs' limited performance in handling long contexts,\nexisting LLM-based fault localization remains on localizing bugs within a small\ncode scope (i.e., a method or a class), which struggles to diagnose bugs for a\nlarge code scope (i.e., an entire software system). To address the limitation,\nthis paper presents AgentFL, a multi-agent system based on ChatGPT for\nautomated fault localization. By simulating the behavior of a human developer,\nAgentFL models the FL task as a three-step process, which involves\ncomprehension, navigation, and confirmation. Within each step, AgentFL hires\nagents with diversified expertise, each of which utilizes different tools to\nhandle specific tasks. Particularly, we adopt a series of auxiliary strategies\nsuch as Test Behavior Tracking, Document-Guided Search, and Multi-Round\nDialogue to overcome the challenges in each step. The evaluation on the widely\nused Defects4J-V1.2.0 benchmark shows that AgentFL can localize 157 out of 395\nbugs within Top-1, which outperforms the other LLM-based approaches and\nexhibits complementarity to the state-of-the-art learning-based techniques.\nAdditionally, we confirm the indispensability of the components in AgentFL with\nthe ablation study and demonstrate the usability of AgentFL through a user\nstudy. Finally, the cost analysis shows that AgentFL spends an average of only\n0.074 dollars and 97 seconds for a single bug.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 01:58:19 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 03:23:06 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Qin", "Yihao", ""], ["Wang", "Shangwen", ""], ["Lou", "Yiling", ""], ["Dong", "Jinhao", ""], ["Wang", "Kaixin", ""], ["Li", "Xiaoling", ""], ["Mao", "Xiaoguang", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "ChatGPT", "label": "ChatGPT"}], "human_readable_topic": "Automated Program Repair with Large Language Models"}
{"id": "2403.16633", "submitter": "Shin'ichiro Ando", "authors": "Shin'ichiro Ando, Shunichi Horigome, Ethan O. Nadler, Daneng Yang,\n  Hai-Bo Yu", "title": "SASHIMI-SIDM: Semi-analytical subhalo modelling for self-interacting\n  dark matter at sub-galactic scales", "comments": "23 pages, 7 figures; matches the published version. The code\n  accompanying this submission is available at\n  https://github.com/shinichiroando/sashimi-si", "journal-ref": "JCAP02(2025)053", "doi": "10.1088/1475-7516/2025/02/053", "report-no": null, "categories": "astro-ph.CO astro-ph.GA astro-ph.HE hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We combine the semi-analytical structure formation model, SASHIMI, which\npredicts subhalo populations in collisionless, cold dark matter (CDM), with a\nparametric model that maps CDM halos to self-interacting dark matter (SIDM)\nhalos. The resulting model, SASHIMI-SIDM, generates SIDM subhalo populations\ndown to sub-galactic mass scales, for an arbitrary input cross section, in\nminutes. We show that SASHIMI-SIDM agrees with SIDM subhalo populations from\nhigh-resolution cosmological zoom-in simulations in resolved regimes.\nCrucially, we predict that the fraction of core-collapsed subhalos peaks at a\nmass scale determined by the input SIDM cross section and decreases toward\nhigher halo masses, consistent with the predictions of gravothermal models and\ncosmological simulations. For the first time, we also show that the\ncore-collapsed fraction decreases toward lower halo masses. While the\ndependence of the collapse time on mass and concentration implies such\nbehaviour, our semi-analytical approach allows us to quantify and illustrate\nthis trend clearly across the full mass spectrum of subhalos, including for\nsubhalo masses below the resolution limit of any current cosmological SIDM\nsimulation. As a proof of principle, we apply SASHIMI-SIDM to predict the boost\nto the local dark matter density and annihilation rate from core-collapsed SIDM\nsubhalos, which can be enhanced relative to CDM by an order of magnitude for\nviable SIDM models. Thus, SASHIMI-SIDM provides an efficient and reliable tool\nfor scanning SIDM parameter space and testing it with astrophysical\nobservations. The code is publicly available at\nhttps://github.com/shinichiroando/sashimi-si.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 11:21:52 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 14:37:41 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Ando", "Shin'ichiro", ""], ["Horigome", "Shunichi", ""], ["Nadler", "Ethan O.", ""], ["Yang", "Daneng", ""], ["Yu", "Hai-Bo", ""]], "extracted_entities": [{"text": "SASHIMI", "label": "AI model"}, {"text": "SASHIMI-SIDM", "label": "AI model"}, {"text": "SASHIMI-SIDM", "label": "AI model"}, {"text": "SASHIMI-SIDM", "label": "AI model"}, {"text": "SASHIMI-SIDM", "label": "AI model"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2403.16707", "submitter": "Yasushi Esaki", "authors": "Yasushi Esaki and Satoshi Koide and Takuro Kutsuna", "title": "One-Shot Domain Incremental Learning", "comments": "Accepted at IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2024", "journal-ref": null, "doi": "10.1109/IJCNN60899.2024.10650928", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain incremental learning (DIL) has been discussed in previous studies on\ndeep neural network models for classification. In DIL, we assume that samples\non new domains are observed over time. The models must classify inputs on all\ndomains. In practice, however, we may encounter a situation where we need to\nperform DIL under the constraint that the samples on the new domain are\nobserved only infrequently. Therefore, in this study, we consider the extreme\ncase where we have only one sample from the new domain, which we call one-shot\nDIL. We first empirically show that existing DIL methods do not work well in\none-shot DIL. We have analyzed the reason for this failure through various\ninvestigations. According to our analysis, we clarify that the difficulty of\none-shot DIL is caused by the statistics in the batch normalization layers.\nTherefore, we propose a technique regarding these statistics and demonstrate\nthe effectiveness of our technique through experiments on open datasets. The\ncode is available at https://github.com/ToyotaCRDL/OneShotDIL.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 12:44:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 06:58:41 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Esaki", "Yasushi", ""], ["Koide", "Satoshi", ""], ["Kutsuna", "Takuro", ""]], "extracted_entities": [{"text": "DIL", "label": "Zero-shot Learning"}, {"text": "DIL", "label": "Few-shot Learning"}, {"text": "one-shot\nDIL", "label": "Few-shot Learning"}, {"text": "DIL", "label": "Zero-shot Learning"}, {"text": "one-shot DIL", "label": "Few-shot Learning"}, {"text": "one-shot DIL", "label": "Few-shot Learning"}, {"text": "OneShotDIL", "label": "Few-shot Learning"}], "human_readable_topic": "Zero-Shot Learning for Visual Recognition"}
{"id": "2403.16722", "submitter": "Ramin Abolfath", "authors": "Ramin Abolfath, Sedigheh Fardirad, Houda Kacem, Marie-Catherine\n  Vozenin, Abbas Ghasemizad", "title": "A Monte Carlo simulation framework for investigating the effect of\n  inter-track coupling on H$_2$O$_2$ productions at ultra-high dose rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph physics.bio-ph physics.chem-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Lower production of H$_2$O$_2$ in water is a hallmark of\nultra-high dose rate (UHDR) compared to the conventional dose rate (CDR).\nHowever, the current computational models based on the predicted yield of\nH$_2$O$_2$ are in opposite of the experimental data. Methods: We construct an\nanalytical model for the rate equation in the production of H$_2$O$_2$ from\n\\ce{^{.}OH}-radicals and use it as a guide to propose a hypothetical\ngeometrical inhomogeneity in the configuration of particles in the FLASH-UHDR\nbeams. We perform a series of Monte Carlo (MC) simulations of the track\nstructures for a system of charged particles impinging the medium in the form\nof clusters and/or bunches. Results: We demonstrate the interplay of diffusion,\nreaction rates, and overlaps in track-spacing attribute to a lower yield of\nH$_2$O$_2$ at FLASH-UHDR vs. CDR. This trend is reversed if spacing among the\ntracks becomes larger than a critical value, with a length scale that is\nproportional to the diffusion length of \\ce{^{.}OH}-radicals modulated by a\nrate of decay due to recombination with other species, available within a\ntrack, and the space among the tracks. The latter is substantial on the\nsuppressing of the H$_2$O$_2$ population at FLASH-UHDR relative to CDR.\nConclusions: Based on our analysis of the present work, at FLASH-UHDR, the\nlower yield in H$_2$O$_2$ can be interpreted as a signature of bunching the\nparticles in beams of ionizing radiation. The beams enter the medium in closely\npacked clusters and form inhomogeneities in the track-structure distribution.\nThus the MC simulations based on the assumption of uniformly distributed tracks\nare unable to explain the experimental data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 12:57:41 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2025 13:46:40 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 12:59:19 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Abolfath", "Ramin", ""], ["Fardirad", "Sedigheh", ""], ["Kacem", "Houda", ""], ["Vozenin", "Marie-Catherine", ""], ["Ghasemizad", "Abbas", ""]], "extracted_entities": [{"text": "length scale", "label": "Scaling law"}, {"text": "diffusion length", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2403.16760", "submitter": "Di Cooke", "authors": "Di Cooke, Abigail Edwards, Sophia Barkoff, and Kathryn Kelly", "title": "As Good As A Coin Toss: Human detection of AI-generated images, videos,\n  audio, and audiovisual stimuli", "comments": "For study pre-registration, see https://osf.io/fnhr3 V5: expanded on\n  ecological validation in Introduction; revised table in Results to add OR &\n  OR CI, previous data unchanged; added further details on study design in\n  Methods; added Appendix with survey screenshots; migrated list of dataset\n  sources from footnotes into references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite advancements in technology led synthetic media authentication and\nrecent government efforts to address the threats posed by maliciously employed\nsynthetic content via the mechanisms of law or through more public education,\none of the current principal defenses against weaponized synthetic media\ncontinues to be the ability of the targeted individual to visually or\nauditorily recognize AI-generated content when they encounter it. However, as\nthe realism of synthetic media continues to rapidly improve, it is vital to\nhave an accurate understanding of just how susceptible people currently are to\npotentially being misled by convincing but false AI generated content. We\nconducted a perceptual study with 1276 participants to assess how capable\npeople were at distinguishing between authentic and synthetic images, audio,\nvideo, and audiovisual media. We find that on average, people struggled to\ndistinguish between synthetic and authentic media, with the mean detection\nperformance close to a chance level performance of 50%. We also find that\naccuracy rates worsen when the stimuli contain any degree of synthetic content,\nfeatures foreign languages, and the media type is a single modality. People are\nalso less accurate at identifying synthetic images when they feature human\nfaces, and when audiovisual stimuli have heterogeneous authenticity. Finally,\nwe find that higher degrees of prior knowledgeability about synthetic media\ndoes not significantly impact detection accuracy rates, but age does, with\nolder individuals performing worse than their younger counterparts.\nCollectively, these results highlight that it is no longer feasible to rely on\nthe perceptual capabilities of people to protect themselves against the growing\nthreat of weaponized synthetic media, and that the need for alternative\ncountermeasures is more critical than ever before.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2024 13:39:33 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2024 15:17:51 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2024 14:51:56 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 10:29:37 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Cooke", "Di", ""], ["Edwards", "Abigail", ""], ["Barkoff", "Sophia", ""], ["Kelly", "Kathryn", ""]], "extracted_entities": [{"text": "mechanisms of law", "label": "AI Ethics"}], "human_readable_topic": "Fake News Detection in AI-Generated Content"}
{"id": "2403.18466", "submitter": "Alessandro Gabbana", "authors": "Giulio Ortali, Alessandro Gabbana, Nicola Demo, Gianluigi Rozza,\n  Federico Toschi", "title": "Kinetic data-driven approach to turbulence subgrid modeling", "comments": null, "journal-ref": "Phys. Rev. Research 7, 013202 (2025)", "doi": "10.1103/PhysRevResearch.7.013202", "report-no": null, "categories": "physics.flu-dyn math-ph math.MP physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerical simulations of turbulent flows are well known to pose extreme\ncomputational challenges due to the huge number of dynamical degrees of freedom\nrequired to correctly describe the complex multi-scale statistical correlations\nof the velocity. On the other hand, kinetic mesoscale approaches based on the\nBoltzmann equation, have the potential to describe a broad range of flows,\nstretching well beyond the special case of gases close to equilibrium, which\nresults in the ordinary Navier-Stokes dynamics. Here we demonstrate that, by\nproperly tuning, a kinetic approach can statistically reproduce the\nquantitative dynamics of the larger scales in turbulence, thereby providing an\nalternative, computationally efficient and physically rooted approach towards\nsubgrid scale (SGS) modeling in turbulence. More specifically we show that by\nleveraging on data from fully resolved Direct Numerical Simulation (DNS) we can\nlearn a collision operator for the discretized Boltzmann equation solver (the\nlattice Boltzmann method), which effectively implies a turbulence subgrid\nclosure model. The mesoscopic nature of our formulation makes the learning\nproblem fully local in both space and time, leading to reduced computational\ncosts and enhanced generalization capabilities. We show that the model offers\nsuperior performance compared to traditional methods, such as the Smagorinsky\nmodel, being less dissipative and, therefore, being able to more closely\ncapture the intermittency of higher-order velocity correlations. This\nfoundational work lays the basis for extending the proposed framework to\ndifferent turbulent flow settings and -- most importantly -- to develop new\nclasses of hybrid data-driven kinetic-based models capable of faithfully\ncapturing the complex macroscopic dynamics of diverse physical systems such as\nemulsions, non-Newtonian fluid and multiphase systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2024 11:22:26 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 22:05:19 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Ortali", "Giulio", ""], ["Gabbana", "Alessandro", ""], ["Demo", "Nicola", ""], ["Rozza", "Gianluigi", ""], ["Toschi", "Federico", ""]], "extracted_entities": [{"text": "properly tuning", "label": "Fine-tuning"}, {"text": "Smagorinsky\nmodel", "label": "Foundation Model"}], "human_readable_topic": "Hyperbolic Transformers for Complex Data Modeling"}
{"id": "2403.18998", "submitter": "Yuqing Wang", "authors": "Yuqing Wang and Mika V. M\\\"antyl\\\"a and Serge Demeyer and Mutlu\n  Beyazit and Joanna Kisaakye and Jesse Nyyss\\\"ol\\\"a", "title": "Cross-System Categorization of Abnormal Traces in Microservice-Based\n  Systems via Meta-Learning", "comments": "Accepted at ACM International Conference on the Foundations of\n  Software Engineering (FSE) 2025", "journal-ref": null, "doi": "10.1145/3715742", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Microservice-based systems (MSS) may fail with various fault types. While\nexisting AIOps methods excel at detecting abnormal traces and locating the\nresponsible service(s), human efforts are still required for diagnosing\nspecific fault types and failure causes.This paper presents TraFaultDia, a\nnovel AIOps framework to automatically classify abnormal traces into fault\ncategories for MSS. We treat the classification process as a series of\nmulti-class classification tasks, where each task represents an attempt to\nclassify abnormal traces into specific fault categories for a MSS. TraFaultDia\nleverages meta-learning to train on several abnormal trace classification tasks\nwith a few labeled instances from a MSS, enabling quick adaptation to new,\nunseen abnormal trace classification tasks with a few labeled instances across\nMSS. TraFaultDia's use cases are scalable depending on how fault categories are\nbuilt from anomalies within MSS. We evaluated TraFaultDia on two MSS,\nTrainTicket and OnlineBoutique, with open datasets where each fault category is\nlinked to faulty system components (service/pod) and a root cause. TraFaultDia\nautomatically classifies abnormal traces into these fault categories, thus\nenabling the automatic identification of faulty system components and root\ncauses without manual analysis. TraFaultDia achieves 93.26% and 85.20% accuracy\non 50 new classification tasks for TrainTicket and OnlineBoutique,\nrespectively, when trained within the same MSS with 10 labeled instances per\ncategory. In the cross-system context, when TraFaultDia is applied to a MSS\ndifferent from the one it is trained on, TraFaultDia gets an average accuracy\nof 92.19% and 84.77% for the same set of 50 new, unseen abnormal trace\nclassification tasks of the respective systems, also with 10 labeled instances\nprovided for each fault category per task in each system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2024 20:38:04 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2024 16:15:58 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2024 10:09:16 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 08:50:14 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Wang", "Yuqing", ""], ["M\u00e4ntyl\u00e4", "Mika V.", ""], ["Demeyer", "Serge", ""], ["Beyazit", "Mutlu", ""], ["Kisaakye", "Joanna", ""], ["Nyyss\u00f6l\u00e4", "Jesse", ""]], "extracted_entities": [{"text": "meta-learning", "label": "Few-shot Learning"}], "human_readable_topic": "Anomaly Detection in Logs and Workflows"}
{"id": "2403.20261", "submitter": "Kaiyuan Gao", "authors": "Kaiyuan Gao, Qizhi Pei, Gongbo Zhang, Jinhua Zhu, Kun He, Lijun Wu", "title": "FABind+: Enhancing Molecular Docking through Improved Pocket Prediction\n  and Pose Generation", "comments": "Accepted for presentation at KDD 2025", "journal-ref": null, "doi": "10.1145/3690624.3709253", "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular docking is a pivotal process in drug discovery. While traditional\ntechniques rely on extensive sampling and simulation governed by physical\nprinciples, these methods are often slow and costly. The advent of deep\nlearning-based approaches has shown significant promise, offering increases in\nboth accuracy and efficiency. Building upon the foundational work of FABind, a\nmodel designed with a focus on speed and accuracy, we present FABind+, an\nenhanced iteration that largely boosts the performance of its predecessor. We\nidentify pocket prediction as a critical bottleneck in molecular docking and\npropose a novel methodology that significantly refines pocket prediction,\nthereby streamlining the docking process. Furthermore, we introduce\nmodifications to the docking module to enhance its pose generation\ncapabilities. In an effort to bridge the gap with conventional\nsampling/generative methods, we incorporate a simple yet effective sampling\ntechnique coupled with a confidence model, requiring only minor adjustments to\nthe regression framework of FABind. Experimental results and analysis reveal\nthat FABind+ remarkably outperforms the original FABind, achieves competitive\nstate-of-the-art performance, and delivers insightful modeling strategies. This\ndemonstrates FABind+ represents a substantial step forward in molecular docking\nand drug discovery. Our code is in https://github.com/QizhiPei/FABind.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2024 16:10:34 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2024 05:18:57 GMT"}, {"version": "v3", "created": "Sun, 7 Apr 2024 07:35:01 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 15:39:15 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Gao", "Kaiyuan", ""], ["Pei", "Qizhi", ""], ["Zhang", "Gongbo", ""], ["Zhu", "Jinhua", ""], ["He", "Kun", ""], ["Wu", "Lijun", ""]], "extracted_entities": [{"text": "FABind", "label": "Foundation Model"}, {"text": "FABind+", "label": "Foundation Model"}, {"text": "FABind", "label": "Foundation Model"}, {"text": "FABind+", "label": "Foundation Model"}, {"text": "FABind", "label": "Foundation Model"}, {"text": "FABind+", "label": "Foundation Model"}, {"text": "FABind", "label": "Foundation Model"}], "human_readable_topic": "Molecular and Protein Representation Learning"}
{"id": "2404.00221", "submitter": "Shosei Sakaguchi", "authors": "Shosei Sakaguchi", "title": "Robust Learning for Optimal Dynamic Treatment Regimes with Observational\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public policies and medical interventions often involve dynamics in their\ntreatment assignments, where individuals receive a series of interventions over\nmultiple stages. We study the statistical learning of optimal dynamic treatment\nregimes (DTRs) that determine the optimal treatment assignment for each\nindividual at each stage based on their evolving history. We propose a doubly\nrobust, classification-based approach to learning the optimal DTR using\nobservational data under the assumption of sequential ignorability. The\napproach learns the optimal DTR through backward induction. At each step, it\nconstructs an augmented inverse probability weighting (AIPW) estimator of the\npolicy value function and maximizes it to learn the optimal policy for the\ncorresponding stage. We show that the resulting DTR achieves an optimal\nconvergence rate of $n^{-1/2}$ for welfare regret under mild convergence\nconditions on estimators of the nuisance components.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2024 02:33:39 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2024 04:41:53 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2024 11:00:13 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2024 05:50:48 GMT"}, {"version": "v5", "created": "Mon, 16 Dec 2024 11:48:51 GMT"}, {"version": "v6", "created": "Tue, 25 Feb 2025 04:52:07 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Sakaguchi", "Shosei", ""]], "extracted_entities": [{"text": "welfare regret", "label": "Model Bias and Fairness"}], "human_readable_topic": "Reinforcement Learning from Human Feedback"}
{"id": "2404.01833", "submitter": "Ahmed Salem", "authors": "Mark Russinovich and Ahmed Salem and Ronen Eldan", "title": "Great, Now Write an Article About That: The Crescendo Multi-Turn LLM\n  Jailbreak Attack", "comments": "Accepted at USENIX Security 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large Language Models (LLMs) have risen significantly in popularity and are\nincreasingly being adopted across multiple applications. These LLMs are heavily\naligned to resist engaging in illegal or unethical topics as a means to avoid\ncontributing to responsible AI harms. However, a recent line of attacks, known\nas jailbreaks, seek to overcome this alignment. Intuitively, jailbreak attacks\naim to narrow the gap between what the model can do and what it is willing to\ndo. In this paper, we introduce a novel jailbreak attack called Crescendo.\nUnlike existing jailbreak methods, Crescendo is a simple multi-turn jailbreak\nthat interacts with the model in a seemingly benign manner. It begins with a\ngeneral prompt or question about the task at hand and then gradually escalates\nthe dialogue by referencing the model's replies progressively leading to a\nsuccessful jailbreak. We evaluate Crescendo on various public systems,\nincluding ChatGPT, Gemini Pro, Gemini-Ultra, LlaMA-2 70b and LlaMA-3 70b Chat,\nand Anthropic Chat. Our results demonstrate the strong efficacy of Crescendo,\nwith it achieving high attack success rates across all evaluated models and\ntasks. Furthermore, we present Crescendomation, a tool that automates the\nCrescendo attack and demonstrate its efficacy against state-of-the-art models\nthrough our evaluations. Crescendomation surpasses other state-of-the-art\njailbreaking techniques on the AdvBench subset dataset, achieving 29-61% higher\nperformance on GPT-4 and 49-71% on Gemini-Pro. Finally, we also demonstrate\nCrescendo's ability to jailbreak multimodal models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2024 10:45:49 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2024 13:51:39 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 13:41:41 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Russinovich", "Mark", ""], ["Salem", "Ahmed", ""], ["Eldan", "Ronen", ""]], "extracted_entities": [{"text": "ChatGPT", "label": "ChatGPT"}, {"text": "Gemini Pro", "label": "ChatGPT"}, {"text": "GPT-4", "label": "GPT-2"}], "human_readable_topic": "Jailbreak Attacks on Large Language Models"}
{"id": "2404.01904", "submitter": "Om Prakash", "authors": "Om Prakash, Shikha Patel and Habibul Islam", "title": "Encoding and Construction of Quantum Codes from $(\\gamma,\\Delta)$-cyclic\n  Codes over a Class of Non-chain Rings", "comments": "24", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $\\mathbb{F}_q$ be a finite field of $q=p^m$ elements where $p$ is a prime\nand $m$ is a positive integer. This paper considers $(\\gamma,\\Delta)$-cyclic\ncodes over a class of finite non-chain commutative rings\n$\\mathscr{R}_{q,s}=\\mathbb{F}_q[v_1,v_2,\\dots,v_s]/\\langle\nv_i-v_i^2,v_iv_j=v_jv_i=0\\rangle$ where $\\gamma$ is an automorphism of\n$\\mathscr{R}_{q,s}$, $\\Delta$ is a $\\gamma$-derivation of $\\mathscr{R}_{q,s}$\nand $1\\leq i\\neq j\\leq s$ for a positive integer $s$. Here, we show that a\n$(\\gamma,\\Delta)$-cyclic code of length $n$ over $\\mathscr{R}_{q,s}$ is the\ndirect sum of $(\\theta,\\Im)$-cyclic codes of length $n$ over $\\mathbb{F}_q$,\nwhere $\\theta$ is an automorphism of $\\mathbb{F}_q$ and $\\Im$ is a\n$\\theta$-derivation of $\\mathbb{F}_q$. Further, necessary and sufficient\nconditions for both $(\\gamma,\\Delta)$-cyclic and $(\\theta,\\Im)$-cyclic codes to\ncontain their Euclidean duals are established. Then, we obtain many quantum\ncodes by applying the dual containing criterion on the Gray images of these\ncodes. These codes have better parameters than those available in the\nliterature. Finally, the encoding and error-correction procedures for our\nproposed quantum codes are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2024 12:45:37 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 16:52:12 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Prakash", "Om", ""], ["Patel", "Shikha", ""], ["Islam", "Habibul", ""]], "extracted_entities": [{"text": "Delta", "label": "Scaling law"}, {"text": "gamma", "label": "Scaling law"}], "human_readable_topic": "Code Hallucinations in Large Language Models"}
{"id": "2404.02241", "submitter": "Enshu Liu", "authors": "Enshu Liu, Junyi Zhu, Zinan Lin, Xuefei Ning, Shuaiqi Wang, Matthew B.\n  Blaschko, Sergey Yekhanin, Shengen Yan, Guohao Dai, Huazhong Yang, Yu Wang", "title": "Linear Combination of Saved Checkpoints Makes Consistency and Diffusion\n  Models Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion Models (DM) and Consistency Models (CM) are two types of popular\ngenerative models with good generation quality on various tasks. When training\nDM and CM, intermediate weight checkpoints are not fully utilized and only the\nlast converged checkpoint is used. In this work, we find that high-quality\nmodel weights often lie in a basin which cannot be reached by SGD but can be\nobtained by proper checkpoint averaging. Based on these observations, we\npropose LCSC, a simple but effective and efficient method to enhance the\nperformance of DM and CM, by combining checkpoints along the training\ntrajectory with coefficients deduced from evolutionary search. We demonstrate\nthe value of LCSC through two use cases: $\\textbf{(a) Reducing training cost.}$\nWith LCSC, we only need to train DM/CM with fewer number of iterations and/or\nlower batch sizes to obtain comparable sample quality with the fully trained\nmodel. For example, LCSC achieves considerable training speedups for CM\n(23$\\times$ on CIFAR-10 and 15$\\times$ on ImageNet-64). $\\textbf{(b) Enhancing\npre-trained models.}$ Assuming full training is already done, LCSC can further\nimprove the generation quality or speed of the final converged models. For\nexample, LCSC achieves better performance using 1 number of function evaluation\n(NFE) than the base model with 2 NFE on consistency distillation, and decreases\nthe NFE of DM from 15 to 9 while maintaining the generation quality on\nCIFAR-10. Our code is available at\nhttps://github.com/imagination-research/LCSC.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2024 18:59:39 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2024 02:06:37 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 12:28:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Liu", "Enshu", ""], ["Zhu", "Junyi", ""], ["Lin", "Zinan", ""], ["Ning", "Xuefei", ""], ["Wang", "Shuaiqi", ""], ["Blaschko", "Matthew B.", ""], ["Yekhanin", "Sergey", ""], ["Yan", "Shengen", ""], ["Dai", "Guohao", ""], ["Yang", "Huazhong", ""], ["Wang", "Yu", ""]], "extracted_entities": [{"text": "consistency distillation", "label": "Knowledge distillation"}], "human_readable_topic": "Parameter-Efficient Fine-Tuning of Pre-Trained Models"}
{"id": "2404.02747", "submitter": "Haozhe Liu", "authors": "Haozhe Liu, Wentian Zhang, Jinheng Xie, Francesco Faccio, Mengmeng Xu,\n  Tao Xiang, Mike Zheng Shou, Juan-Manuel Perez-Rua, J\\\"urgen Schmidhuber", "title": "Faster Diffusion via Temporal Attention Decomposition", "comments": "Accepted by TMLR: https://openreview.net/forum?id=xXs2GKXPnH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the role of attention mechanism during inference in\ntext-conditional diffusion models. Empirical observations suggest that\ncross-attention outputs converge to a fixed point after several inference\nsteps. The convergence time naturally divides the entire inference process into\ntwo phases: an initial phase for planning text-oriented visual semantics, which\nare then translated into images in a subsequent fidelity-improving phase.\nCross-attention is essential in the initial phase but almost irrelevant\nthereafter. However, self-attention initially plays a minor role but becomes\ncrucial in the second phase. These findings yield a simple and training-free\nmethod known as temporally gating the attention (TGATE), which efficiently\ngenerates images by caching and reusing attention outputs at scheduled time\nsteps. Experimental results show when widely applied to various existing\ntext-conditional diffusion models, TGATE accelerates these models by 10%-50%.\nThe code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2024 13:44:41 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2024 23:09:10 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 10:49:33 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Liu", "Haozhe", ""], ["Zhang", "Wentian", ""], ["Xie", "Jinheng", ""], ["Faccio", "Francesco", ""], ["Xu", "Mengmeng", ""], ["Xiang", "Tao", ""], ["Shou", "Mike Zheng", ""], ["Perez-Rua", "Juan-Manuel", ""], ["Schmidhuber", "J\u00fcrgen", ""]], "extracted_entities": [{"text": "attention mechanism", "label": "Attention mechanism"}, {"text": "cross-attention", "label": "Attention mechanism"}, {"text": "Cross-attention", "label": "Attention mechanism"}, {"text": "self-attention", "label": "Attention mechanism"}], "human_readable_topic": "Diffusion Models for Text-Guided Image Generation and Editing"}
{"id": "2404.03200", "submitter": "Quentin Jodelet", "authors": "Quentin Jodelet, Xin Liu, Yin Jun Phua, Tsuyoshi Murata", "title": "Future-Proofing Class-Incremental Learning", "comments": "The version of record of this article, first published in \"Machine\n  Vision and Applications\", is available online at Publisher's website:\n  https://doi.org/10.1007/s00138-024-01635-y", "journal-ref": null, "doi": "10.1007/s00138-024-01635-y", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Exemplar-Free Class Incremental Learning is a highly challenging setting\nwhere replay memory is unavailable. Methods relying on frozen feature\nextractors have drawn attention recently in this setting due to their\nimpressive performances and lower computational costs. However, those methods\nare highly dependent on the data used to train the feature extractor and may\nstruggle when an insufficient amount of classes are available during the first\nincremental step. To overcome this limitation, we propose to use a pre-trained\ntext-to-image diffusion model in order to generate synthetic images of future\nclasses and use them to train the feature extractor. Experiments on the\nstandard benchmarks CIFAR100 and ImageNet-Subset demonstrate that our proposed\nmethod can be used to improve state-of-the-art methods for exemplar-free class\nincremental learning, especially in the most difficult settings where the first\nincremental step only contains few classes. Moreover, we show that using\nsynthetic samples of future classes achieves higher performance than using real\ndata from different classes, paving the way for better and less costly\npre-training methods for incremental learning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2024 05:08:51 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 01:29:16 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Jodelet", "Quentin", ""], ["Liu", "Xin", ""], ["Phua", "Yin Jun", ""], ["Murata", "Tsuyoshi", ""]], "extracted_entities": [{"text": "Exemplar-Free Class Incremental Learning", "label": "Few-shot Learning"}, {"text": "exemplar-free class\nincremental learning", "label": "Few-shot Learning"}, {"text": "incremental learning", "label": "Few-shot Learning"}], "human_readable_topic": "Visual Adaptation with Learnable Tokens"}
{"id": "2404.03331", "submitter": "Bin Gao", "authors": "Yan Yang, Bin Gao, Ya-xiang Yuan", "title": "LancBiO: dynamic Lanczos-aided bilevel optimization via Krylov subspace", "comments": "This paper is a camera-ready version of ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization, with broad applications in machine learning, has an\nintricate hierarchical structure. Gradient-based methods have emerged as a\ncommon approach to large-scale bilevel problems. However, the computation of\nthe hyper-gradient, which involves a Hessian inverse vector product, confines\nthe efficiency and is regarded as a bottleneck. To circumvent the inverse, we\nconstruct a sequence of low-dimensional approximate Krylov subspaces with the\naid of the Lanczos process. As a result, the constructed subspace is able to\ndynamically and incrementally approximate the Hessian inverse vector product\nwith less effort and thus leads to a favorable estimate of the hyper-gradient.\nMoreover, we propose a provable subspace-based framework for bilevel problems\nwhere one central step is to solve a small-size tridiagonal linear system. To\nthe best of our knowledge, this is the first time that subspace techniques are\nincorporated into bilevel optimization. This successful trial not only enjoys\n$\\mathcal{O}(\\epsilon^{-1})$ convergence rate but also demonstrates efficiency\nin a synthetic problem and two deep learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2024 09:57:29 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 14:25:09 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Yang", "Yan", ""], ["Gao", "Bin", ""], ["Yuan", "Ya-xiang", ""]], "extracted_entities": [{"text": "Hessian", "label": "BERT"}, {"text": "Hessian", "label": "BERT"}], "human_readable_topic": "Hyperparameter Optimization Methods"}
{"id": "2404.03471", "submitter": "David Emerson", "authors": "Farnaz Kohankhaki, D. B. Emerson, Jacob-Junqi Tian, Laleh\n  Seyyed-Kalantari, Faiza Khan Khattak", "title": "The Impact of Unstated Norms in Bias Analysis of Language Models", "comments": "15 Pages, 4 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in large language models (LLMs) has many forms, from overt\ndiscrimination to implicit stereotypes. Counterfactual bias evaluation is a\nwidely used approach to quantifying bias and often relies on template-based\nprobes that explicitly state group membership. It measures whether the outcome\nof a task performed by an LLM is invariant to a change in group membership. In\nthis work, we find that template-based probes can lead to unrealistic bias\nmeasurements. For example, LLMs appear to mistakenly cast text associated with\nWhite race as negative at higher rates than other groups. We hypothesize that\nthis arises artificially via a mismatch between commonly unstated norms, in the\nform of markedness, in the pretraining text of LLMs (e.g., Black president vs.\npresident) and templates used for bias measurement (e.g., Black president vs.\nWhite president). The findings highlight the potential misleading impact of\nvarying group membership through explicit mention in counterfactual bias\nquantification.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2024 14:24:06 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2024 21:55:38 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2024 13:12:23 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 15:11:54 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Kohankhaki", "Farnaz", ""], ["Emerson", "D. B.", ""], ["Tian", "Jacob-Junqi", ""], ["Seyyed-Kalantari", "Laleh", ""], ["Khattak", "Faiza Khan", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Cognitive Biases in Large Language Models"}
{"id": "2404.03818", "submitter": "Zhangdie Yuan", "authors": "Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse and Andreas\n  Vlachos", "title": "PRobELM: Plausibility Ranking Evaluation for Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PRobELM (Plausibility Ranking Evaluation for Language\nModels), a benchmark designed to assess language models' ability to discern\nmore plausible from less plausible scenarios through their parametric\nknowledge. While benchmarks such as TruthfulQA emphasise factual accuracy or\ntruthfulness, and others such as COPA explore plausible scenarios without\nexplicitly incorporating world knowledge, PRobELM seeks to bridge this gap by\nevaluating models' capabilities to prioritise plausible scenarios that leverage\nworld knowledge over less plausible alternatives. This design allows us to\nassess the potential of language models for downstream use cases such as\nliterature-based discovery where the focus is on identifying information that\nis likely but not yet known. Our benchmark is constructed from a dataset\ncurated from Wikidata edit histories, tailored to align the temporal bounds of\nthe training data for the evaluated models. PRobELM facilitates the evaluation\nof language models across multiple prompting types, including statement, text\ncompletion, and question-answering. Experiments with 10 models of various sizes\nand architectures on the relationship between model scales, training recency,\nand plausibility performance, reveal that factual accuracy does not directly\ncorrelate with plausibility performance and that up-to-date training data\nenhances plausibility assessment across different model architectures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2024 21:57:11 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2024 12:05:06 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 01:42:18 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Yuan", "Zhangdie", ""], ["Chamoun", "Eric", ""], ["Aly", "Rami", ""], ["Whitehouse", "Chenxi", ""], ["Vlachos", "Andreas", ""]], "extracted_entities": [{"text": "question-answering", "label": "Prompting"}], "human_readable_topic": "Evaluating Large Language Models for Reliable Answering"}
{"id": "2404.04183", "submitter": "Pasindu Tennage", "authors": "Pasindu Tennage, Antoine Desjardins, Lefteris Kokoris-Kogias", "title": "RACS and SADL: Towards Robust SMR in the Wide-Area Network", "comments": "Revision of the previous version. arXiv admin note: text overlap with\n  arXiv:2209.06152", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widely deployed consensus protocols in the cloud are often leader-based and\noptimized for low latency under synchronous network conditions. However, cloud\nnetworks can experience disruptions such as network partitions, high-loss\nlinks, and configuration errors. These disruptions interfere with the operation\nof leader-based protocols, as their view change mechanisms interrupt the normal\ncase replication and cause the system to stall.\n  This paper proposes RACS, a novel randomized consensus protocol that ensures\nrobustness against adversarial network conditions. RACS achieves optimal\none-round trip latency under synchronous network conditions while remaining\nresilient to adversarial network conditions. RACS follows a simple design\ninspired by Raft, the most widely used consensus protocol in the cloud, and\ntherefore enables seamless integration with the existing cloud software stack\n-- a goal no previous asynchronous protocol has successfully achieved.\n  Experiments with a prototype deployed on Amazon EC2 confirm that RACS\nachieves a throughput of 28k cmd/sec under adversarial cloud network\nconditions, whereas existing leader-based protocols such as Multi-Paxos and\nRaft provide less than 2.8k cmd/sec. Under synchronous network conditions, RACS\nmatches the performance of Multi-Paxos and Raft, achieving a throughput of 200k\ncmd/sec with a latency of 300ms, confirming that RACS introduces no unnecessary\noverhead. Finally, SADL-RACS-an optimized version of RACS designed for high\nperformance and robustness-achieves an impressive throughput of 500k cmd/sec\nunder synchronous network conditions and 196k cmd/sec under adversarial network\nconditions, further enhancing both performance and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2024 15:53:32 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:19:41 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Tennage", "Pasindu", ""], ["Desjardins", "Antoine", ""], ["Kokoris-Kogias", "Lefteris", ""]], "extracted_entities": [{"text": "RACS", "label": "RAG"}, {"text": "RACS", "label": "RAG"}, {"text": "RACS", "label": "RAG"}, {"text": "Raft", "label": "RAG"}, {"text": "RACS", "label": "RAG"}, {"text": "Multi-Paxos", "label": "RAG"}, {"text": "Raft", "label": "RAG"}, {"text": "RACS", "label": "RAG"}, {"text": "Multi-Paxos", "label": "RAG"}, {"text": "RACS", "label": "RAG"}, {"text": "RACS", "label": "RAG"}], "human_readable_topic": "Adversarial Attacks on Graph Neural Networks"}
{"id": "2404.04910", "submitter": "Hou-I Liu", "authors": "Hou-I Liu, Christine Wu, Jen-Hao Cheng, Wenhao Chai, Shian-Yun Wang,\n  Gaowen Liu, Jenq-Neng Hwang, Hong-Han Shuai and Wen-Huang Cheng", "title": "MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D\n  Object Detection", "comments": "Accepted by CVPR 2025. Our code will be available at\n  https://github.com/hoiliu-0801/MonoTAKD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular 3D object detection (Mono3D) holds noteworthy promise for\nautonomous driving applications owing to the cost-effectiveness and rich visual\ncontext of monocular camera sensors. However, depth ambiguity poses a\nsignificant challenge, as it requires extracting precise 3D scene geometry from\na single image, resulting in suboptimal performance when transferring knowledge\nfrom a LiDAR-based teacher model to a camera-based student model. To address\nthis issue, we introduce {\\em Monocular Teaching Assistant Knowledge\nDistillation (MonoTAKD)} to enhance 3D perception in Mono3D. Our approach\npresents a robust camera-based teaching assistant model that effectively\nbridges the representation gap between different modalities for teacher and\nstudent models, addressing the challenge of inaccurate depth estimation. By\ndefining 3D spatial cues as residual features that capture the differences\nbetween the teacher and the teaching assistant models, we leverage these cues\ninto the student model, improving its 3D perception capabilities. Experimental\nresults show that our MonoTAKD achieves state-of-the-art performance on the\nKITTI3D dataset. Additionally, we evaluate the performance on nuScenes and\nKITTI raw datasets to demonstrate the generalization of our model to multi-view\n3D and unsupervised data settings. Our code will be available at\nhttps://github.com/hoiliu-0801/MonoTAKD.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2024 10:39:04 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 02:56:48 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liu", "Hou-I", ""], ["Wu", "Christine", ""], ["Cheng", "Jen-Hao", ""], ["Chai", "Wenhao", ""], ["Wang", "Shian-Yun", ""], ["Liu", "Gaowen", ""], ["Hwang", "Jenq-Neng", ""], ["Shuai", "Hong-Han", ""], ["Cheng", "Wen-Huang", ""]], "extracted_entities": [{"text": "Monocular Teaching Assistant Knowledge\nDistillation", "label": "Knowledge distillation"}, {"text": "student model", "label": "AI model"}], "human_readable_topic": "Monocular Depth Estimation with Transformers and CNNs"}
{"id": "2404.05062", "submitter": "Abhranil Das", "authors": "Abhranil Das", "title": "New methods to compute the generalized chi-square distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present four new mathematical methods, two exact and two approximate,\nalong with open-source software, to compute the cdf, pdf and inverse cdf of the\ngeneralized chi-square distribution. Some methods are geared for speed, while\nothers are designed to be accurate far into the tails, using which we can also\nmeasure large values of the discriminability index $d'$ between multivariate\nnormal distributions. We compare the accuracy and speed of these and previous\nmethods, characterize their advantages and limitations, and identify the best\nmethods to use in different cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2024 20:16:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2024 21:39:17 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 22:36:16 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Das", "Abhranil", ""]], "extracted_entities": [{"text": "open-source software", "label": "Open-source LLMs"}], "human_readable_topic": "Out-of-Distribution Detection Methods"}
{"id": "2404.05368", "submitter": "Vojtech Mrazek", "authors": "Jan Klhufek, Miroslav Safar, Vojtech Mrazek, Zdenek Vasicek, Lukas\n  Sekanina", "title": "Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural\n  Network Accelerators", "comments": "To appear at the 2024 27th International Symposium on Design &\n  Diagnostics of Electronic Circuits & Systems (DDECS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency and memory footprint of a convolutional neural network\n(CNN) implemented on a CNN inference accelerator depend on many factors,\nincluding a weight quantization strategy (i.e., data types and bit-widths) and\nmapping (i.e., placement and scheduling of DNN elementary operations on\nhardware units of the accelerator). We show that enabling rich mixed\nquantization schemes during the implementation can open a previously hidden\nspace of mappings that utilize the hardware resources more effectively. CNNs\nutilizing quantized weights and activations and suitable mappings can\nsignificantly improve trade-offs among the accuracy, energy, and memory\nrequirements compared to less carefully optimized CNN implementations. To find,\nanalyze, and exploit these mappings, we: (i) extend a general-purpose\nstate-of-the-art mapping tool (Timeloop) to support mixed quantization, which\nis not currently available; (ii) propose an efficient multi-objective\noptimization algorithm to find the most suitable bit-widths and mapping for\neach DNN layer executed on the accelerator; and (iii) conduct a detailed\nexperimental evaluation to validate the proposed method. On two CNNs\n(MobileNetV1 and MobileNetV2) and two accelerators (Eyeriss and Simba) we show\nthat for a given quality metric (such as the accuracy on ImageNet), energy\nsavings are up to 37% without any accuracy drop.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2024 10:10:30 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 13:11:04 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Klhufek", "Jan", ""], ["Safar", "Miroslav", ""], ["Mrazek", "Vojtech", ""], ["Vasicek", "Zdenek", ""], ["Sekanina", "Lukas", ""]], "extracted_entities": [{"text": "weight quantization strategy", "label": "quantisation"}, {"text": "mixed quantization", "label": "quantisation"}], "human_readable_topic": "Neural Network Quantization Methods"}
{"id": "2404.05697", "submitter": "Chong Wang", "authors": "Chong Wang, Xiao-Wei Zhang, Xiaoyu Liu, Jie Wang, Ting Cao and Di Xiao", "title": "Higher Landau-Level Analogs and Signatures of Non-Abelian States in\n  Twisted Bilayer MoTe$_2$", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevLett.134.076503", "report-no": null, "categories": "cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental discovery of fractional Chern insulators at zero magnetic\nfield in moir\\'e superlattices has sparked intense interests in bringing Landau\nlevel physics to flat Chern bands. In twisted MoTe$_2$ bilayers (tMoTe$_2$),\nrecent theoretical and experimental studies have found three consecutive flat\nChern bands at twist angle $\\sim 2^\\circ$. In this work, we investigate whether\nhigher Landau level physics can be found in these consecutive Chern bands. At\ntwist angles $2.00^\\circ$ and $1.89^\\circ$, we identify four consecutive $C =\n1$ bands for the $K$ valley in tMoTe$_2$. By constructing Wannier functions\ndirectly from density functional theory (DFT) calculations, a six-orbital model\nis developed to describe the consecutive Chern bands, with the orbitals forming\na honeycomb lattice. Exact diagonalization on top of Hartree-Fock calculations\nare carried out with the Wannier functions. Especially, when the second moir\\'e\nminiband is half-filled, signatures of non-Abelian states are found. Our\nWannier-based approach in modelling moir\\'e superlattices is faithful to DFT\nwave functions and can serve as benchmarks for continuum models. The\npossibility of realizing non-Abelian anyons at zero magnetic field also opens\nup a new pathway for fault-tolerant quantum information processing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2024 17:31:38 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 14:54:35 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wang", "Chong", ""], ["Zhang", "Xiao-Wei", ""], ["Liu", "Xiaoyu", ""], ["Wang", "Jie", ""], ["Cao", "Ting", ""], ["Xiao", "Di", ""]], "extracted_entities": [{"text": "moir\\'e", "label": "Mistral"}, {"text": "Exact diagonalization", "label": "quantisation"}, {"text": "moir\\'e", "label": "Mistral"}, {"text": "moir\\'e", "label": "Mistral"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2404.06004", "submitter": "Kento Tatsuno", "authors": "Kento Tatsuno, Daisuke Miyashita, Taiga Ikeda, Kiyoshi Ishiyama,\n  Kazunari Sumiyoshi and Jun Deguchi", "title": "AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free\n  Information Retrieval", "comments": "6 pages, 8 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-based approximate nearest neighbor search (ANNS) algorithms work\neffectively against large-scale vector retrieval. Among such methods, DiskANN\nachieves good recall-speed tradeoffs using both DRAM and storage. DiskANN\nadopts product quantization (PQ) to reduce memory usage, which is still\nproportional to the scale of datasets. In this paper, we propose All-in-Storage\nANNS with Product Quantization (AiSAQ), which offloads compressed vectors to\nthe SSD index. Our method achieves $\\sim$10 MB memory usage in query search\nwith billion-scale datasets without critical latency degradation. AiSAQ also\nreduces the index load time for query search preparation, which enables fast\nswitch between muitiple billion-scale indices.This method can be applied to\nretrievers of retrieval-augmented generation (RAG) and be scaled out with\nmultiple-server systems for emerging datasets. Our DiskANN-based implementation\nis available on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2024 04:20:27 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 07:47:30 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Tatsuno", "Kento", ""], ["Miyashita", "Daisuke", ""], ["Ikeda", "Taiga", ""], ["Ishiyama", "Kiyoshi", ""], ["Sumiyoshi", "Kazunari", ""], ["Deguchi", "Jun", ""]], "extracted_entities": [{"text": "product quantization", "label": "quantisation"}, {"text": "Product Quantization", "label": "quantisation"}, {"text": "AiSAQ", "label": "quantisation"}, {"text": "RAG", "label": "RAG"}, {"text": "GitHub", "label": "Open-source LLMs"}], "human_readable_topic": "Hashing Techniques for Efficient Search and Retrieval"}
{"id": "2404.06470", "submitter": "Rohan Sarkar", "authors": "Rohan Sarkar, Avinash Kak", "title": "A Dataset and Framework for Learning State-invariant Object\n  Representations", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We add one more invariance - the state invariance - to the more commonly used\nother invariances for learning object representations for recognition and\nretrieval. By state invariance, we mean robust with respect to changes in the\nstructural form of the objects, such as when an umbrella is folded, or when an\nitem of clothing is tossed on the floor. In this work, we present a novel\ndataset, ObjectsWithStateChange, which captures state and pose variations in\nthe object images recorded from arbitrary viewpoints. We believe that this\ndataset will facilitate research in fine-grained object recognition and\nretrieval of 3D objects that are capable of state changes. The goal of such\nresearch would be to train models capable of learning discriminative object\nembeddings that remain invariant to state changes while also staying invariant\nto transformations induced by changes in viewpoint, pose, illumination, etc. A\nmajor challenge in this regard is that instances of different objects (both\nwithin and across different categories) under various state changes may share\nsimilar visual characteristics and therefore may be close to one another in the\nlearned embedding space, which would make it more difficult to discriminate\nbetween them. To address this, we propose a curriculum learning strategy that\nprogressively selects object pairs with smaller inter-object distances in the\nlearned embedding space during the training phase. This approach gradually\nsamples harder-to-distinguish examples of visually similar objects, both within\nand across different categories. Our ablation related to the role played by\ncurriculum learning indicates an improvement in object recognition accuracy of\n7.9% and retrieval mAP of 9.2% over the state-of-the-art on our new dataset, as\nwell as three other challenging multi-view datasets such as ModelNet40,\nObjectPI, and FG3D.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2024 17:17:48 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 17:26:00 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Sarkar", "Rohan", ""], ["Kak", "Avinash", ""]], "extracted_entities": [{"text": "discriminative object\nembeddings", "label": "Embedding"}, {"text": "curriculum learning", "label": "Few-shot Learning"}, {"text": "curriculum learning", "label": "Few-shot Learning"}], "human_readable_topic": "Visual Adaptation with Learnable Tokens"}
{"id": "2404.07359", "submitter": "Karol Kozio{\\l}", "authors": "Karol Kozio{\\l}, I. Agust\\'in Aucar, Konstantin Gaul, Robert Berger,\n  Gustavo A. Aucar", "title": "Relativistic and quantum electrodynamics effects on NMR shielding\n  tensors of Tl$X$ ($X$ = H, F, Cl, Br, I, At) molecules", "comments": null, "journal-ref": null, "doi": "10.1063/5.0213653", "report-no": null, "categories": "physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Results of relativistic calculations of nuclear magnetic resonance shielding\ntensors ($\\sigma$) for the thallium monocation (Tl$^+$), thallium hydride (TlH)\nand thallium halides (TlF, TlCl, TlBr, TlI, and TlAt) are presented as obtained\nwithin a four-component polarization propagator formalism and a two-component\nlinear response approach within the zeroth-order regular approximation.\nAdditionally, some quantum electrodynamical (QED) effects on those NMR\nshieldings are estimated. A strong dependence of $\\sigma$(Tl) on the bonding\npartner is found, together with a very weak dependence of QED effects with\nthem. In order to explain the trends observed, the excitation patterns\nassociated with relativistic $ee$ (or paramagnetic-like) and $pp$ (or\ndiamagnetic-like) contributions to $\\sigma$ are analyzed. For this purpose,\nalso the electronic spin-free and spin-dependent contributions are separated\nwithin the two-component zeroth-order regular approximation, and the influence\nof spin-orbit coupling on involved molecular orbitals is studied, which allows\nfor a thorough understanding of the underlying mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2024 21:32:40 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2024 07:45:33 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 08:18:14 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Kozio\u0142", "Karol", ""], ["Aucar", "I. Agust\u00edn", ""], ["Gaul", "Konstantin", ""], ["Berger", "Robert", ""], ["Aucar", "Gustavo A.", ""]], "extracted_entities": [{"text": "zeroth-order regular approximation", "label": "quantisation"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2404.07575", "submitter": "Tien-Hong Lo", "authors": "Tien-Hong Lo, Fu-An Chao, Tzu-I Wu, Yao-Ting Sung, Berlin Chen", "title": "An Effective Automated Speaking Assessment Approach to Mitigating Data\n  Scarcity and Imbalanced Distribution", "comments": "Accepted to NAACL 2024 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated speaking assessment (ASA) typically involves automatic speech\nrecognition (ASR) and hand-crafted feature extraction from the ASR transcript\nof a learner's speech. Recently, self-supervised learning (SSL) has shown\nstellar performance compared to traditional methods. However, SSL-based ASA\nsystems are faced with at least three data-related challenges: limited\nannotated data, uneven distribution of learner proficiency levels and\nnon-uniform score intervals between different CEFR proficiency levels. To\naddress these challenges, we explore the use of two novel modeling strategies:\nmetric-based classification and loss reweighting, leveraging distinct SSL-based\nembedding features. Extensive experimental results on the ICNALE benchmark\ndataset suggest that our approach can outperform existing strong baselines by a\nsizable margin, achieving a significant improvement of more than 10% in CEFR\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2024 09:06:49 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2024 01:22:47 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 07:19:22 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Lo", "Tien-Hong", ""], ["Chao", "Fu-An", ""], ["Wu", "Tzu-I", ""], ["Sung", "Yao-Ting", ""], ["Chen", "Berlin", ""]], "extracted_entities": [{"text": "self-supervised learning", "label": "Embedding"}, {"text": "SSL-based\nembedding features", "label": "Embedding"}], "human_readable_topic": "Automated Grading and Assessment with Large Language Models"}
{"id": "2404.08948", "submitter": "Chenhui Cui", "authors": "Chenhui Cui, Tao Li, Junjie Wang, Chunyang Chen, Dave Towey, Rubing\n  Huang", "title": "Large Language Models for Mobile GUI Text Input Generation: An Empirical\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile applications have become an essential part of our daily lives, making\nensuring their quality an important activity. Graphical User Interface (GUI)\ntesting is a quality assurance method that has frequently been used for mobile\napps. When conducting GUI testing, it is important to generate effective text\ninputs for the text-input components. Some GUIs require these text inputs to be\nable to move from one page to the next: This can be a challenge to achieving\ncomplete UI exploration. Recently, Large Language Models (LLMs) have\ndemonstrated excellent text-generation capabilities. To the best of our\nknowledge, there has not yet been any empirical study to evaluate different\npre-trained LLMs' effectiveness at generating text inputs for mobile GUI\ntesting. This paper reports on a large-scale empirical study that extensively\ninvestigates the effectiveness of nine state-of-the-art LLMs in Android\ntext-input generation for UI pages. We collected 114 UI pages from 62\nopen-source Android apps and extracted contextual information from the UI pages\nto construct prompts for LLMs to generate text inputs. The experimental results\nshow that some LLMs can generate more effective and higher-quality text inputs,\nachieving a 50.58% to 66.67% page-pass-through rate (PPTR). We also found that\nusing more complete UI contextual information can increase the PPTRs of LLMs\nfor generating text inputs. We conducted an experiment to evaluate the\nbug-detection capabilities of LLMs by directly generating invalid text inputs.\nWe collected 37 real-world bugs related to text inputs. The results show that\nusing LLMs to directly generate invalid text inputs for bug detection is\ninsufficient: The bug-detection rates of the nine LLMs are all less than 23%.\nIn addition, we also describe six insights gained regarding the use of LLMs for\nAndroid testing: These insights will benefit the Android testing community.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2024 09:56:50 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 06:23:35 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Cui", "Chenhui", ""], ["Li", "Tao", ""], ["Wang", "Junjie", ""], ["Chen", "Chunyang", ""], ["Towey", "Dave", ""], ["Huang", "Rubing", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompts", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Large Language Models for Mobile GUI Testing"}
{"id": "2404.09656", "submitter": "Boris Shaposhnikov", "authors": "Alexey Gorbatovski, Boris Shaposhnikov, Alexey Malakhov, Nikita\n  Surnachev, Yaroslav Aksenov, Ian Maksimov, Nikita Balagansky, Daniil Gavrilov", "title": "Learn Your Reference Model for Real Good Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the fact that offline methods for Large Language Models (LLMs)\nalignment do not require a direct reward model, they remain susceptible to\noveroptimization. This issue arises when the trained model deviates excessively\nfrom the reference policy, leading to a decrease in sample quality. We propose\na new paradigm of offline alignment methods, called Trust Region (including\nvariants TR-DPO, TR-IPO, TR-KTO), which dynamically updates the reference\npolicy throughout the training process. Our results show that TR alignment\nmethods effectively mitigate overoptimization, enabling models to maintain\nstrong performance even when substantially deviating from the initial reference\npolicy. We demonstrate the efficacy of these approaches not only through toy\nexamples that exhibit reduced overoptimization, but also through direct,\nside-by-side comparisons in specific tasks such as helpful and harmless\ndialogue, as well as summarization, where they surpass conventional methods.\nAdditionally, we report significant improvements in general-purpose assistant\nsetups with the Llama3 model on the AlpacaEval 2 and Arena-Hard benchmarks,\nhighlighting the advantages of Trust Region methods over classical approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2024 10:44:31 GMT"}, {"version": "v2", "created": "Tue, 21 May 2024 15:04:12 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2024 13:42:12 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 10:19:35 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Gorbatovski", "Alexey", ""], ["Shaposhnikov", "Boris", ""], ["Malakhov", "Alexey", ""], ["Surnachev", "Nikita", ""], ["Aksenov", "Yaroslav", ""], ["Maksimov", "Ian", ""], ["Balagansky", "Nikita", ""], ["Gavrilov", "Daniil", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "summarization", "label": "Knowledge distillation"}, {"text": "Llama3", "label": "Llama"}], "human_readable_topic": "Parameter-Efficient Fine-Tuning for Large Language Models"}
{"id": "2404.10171", "submitter": "Thanh-Dung Le", "authors": "Boammani Aser Lompo, Thanh-Dung Le, Philippe Jouvet, Rita Noumeir", "title": "Are Medium-Sized Transformers Models still Relevant for Medical Records\n  Processing?", "comments": "Under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As large language models (LLMs) become the standard in many NLP applications,\nwe explore the potential of medium-sized pretrained transformer models as a\nviable alternative for medical record processing. Medical records generated by\nhealthcare professionals during patient admissions remain underutilized due to\nchallenges such as complex medical terminology, the limited ability of\npretrained models to interpret numerical data, and the scarcity of annotated\ntraining datasets. Objective: This study aims to classify numerical values\nextracted from medical records into seven distinct physiological categories\nusing CamemBERT-bio. Previous research has suggested that transformer-based\nmodels may underperform compared to traditional NLP approaches in this context.\nMethods: To enhance the performance of CamemBERT-bio, we propose two key\ninnovations: (1) incorporating keyword embeddings to refine the model's\nattention mechanisms and (2) adopting a number-agnostic strategy by removing\nnumerical values from the text to encourage context-driven learning.\nAdditionally, we assess the criticality of extracted numerical data by\nverifying whether values fall within established standard ranges. Results: Our\nfindings demonstrate significant performance improvements, with CamemBERT-bio\nachieving an F1 score of 0.89 - an increase of over 20% compared to the 0.73 F1\nscore of traditional methods and only 0.06 units lower than GPT-4. These\nresults were obtained despite the use of small and imbalanced training\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2024 22:50:42 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 19:45:11 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Lompo", "Boammani Aser", ""], ["Le", "Thanh-Dung", ""], ["Jouvet", "Philippe", ""], ["Noumeir", "Rita", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "keyword embeddings", "label": "contextual Embedding"}, {"text": "attention mechanisms", "label": "Attention mechanism"}, {"text": "context-driven learning", "label": "Few-shot Learning"}], "human_readable_topic": "Large Language Models in Healthcare Applications"}
{"id": "2404.10757", "submitter": "Yuyang Li", "authors": "Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria,\n  Jifeng Liu", "title": "Deep Learning and LLM-based Methods Applied to Stellar Lightcurve\n  Classification", "comments": "35 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.SR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Light curves serve as a valuable source of information on stellar formation\nand evolution. With the rapid advancement of machine learning techniques, it\ncan be effectively processed to extract astronomical patterns and information.\nIn this study, we present a comprehensive evaluation of deep-learning and large\nlanguage model (LLM) based models for the automatic classification of variable\nstar light curves, based on large datasets from the Kepler and K2 missions.\nSpecial emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries,\nexamining the influence of observational cadence and phase distribution on\nclassification precision. Employing AutoDL optimization, we achieve striking\nperformance with the 1D-Convolution+BiLSTM architecture and the Swin\nTransformer, hitting accuracies of 94\\% and 99\\% correspondingly, with the\nlatter demonstrating a notable 83\\% accuracy in discerning the elusive Type II\nCepheids-comprising merely 0.02\\% of the total dataset.We unveil StarWhisper\nLightCurve (LC), an innovative Series comprising three LLM-based models: LLM,\nmultimodal large language model (MLLM), and Large Audio Language Model (LALM).\nEach model is fine-tuned with strategic prompt engineering and customized\ntraining methods to explore the emergent abilities of these models for\nastronomical data. Remarkably, StarWhisper LC Series exhibit high accuracies\naround 90\\%, significantly reducing the need for explicit feature engineering,\nthereby paving the way for streamlined parallel data processing and the\nprogression of multifaceted multimodal models in astronomical applications. The\nstudy furnishes two detailed catalogs illustrating the impacts of phase and\nsampling intervals on deep learning classification accuracy, showing that a\nsubstantial decrease of up to 14\\% in observation duration and 21\\% in sampling\npoints can be realized without compromising accuracy by more than 10\\%.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2024 17:35:25 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 00:25:01 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Li", "Yu-Yang", ""], ["Bai", "Yu", ""], ["Wang", "Cunshi", ""], ["Qu", "Mengwei", ""], ["Lu", "Ziteng", ""], ["Soria", "Roberto", ""], ["Liu", "Jifeng", ""]], "extracted_entities": [{"text": "Swin\nTransformer", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "strategic prompt engineering", "label": "Prompting"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2404.11585", "submitter": "Carlos Pe\\~narrubia", "authors": "Carlos Penarrubia, Carlos Garrido-Munoz, Jose J. Valero-Mas, Jorge\n  Calvo-Zaragoza", "title": "Spatial Context-based Self-Supervised Learning for Handwritten Text\n  Recognition", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Handwritten Text Recognition (HTR) is a relevant problem in computer vision,\nand implies unique challenges owing to its inherent variability and the rich\ncontextualization required for its interpretation. Despite the success of\nSelf-Supervised Learning (SSL) in computer vision, its application to HTR has\nbeen rather scattered, leaving key SSL methodologies unexplored. This work\nfocuses on one of them, namely Spatial Context-based SSL. We investigate how\nthis family of approaches can be adapted and optimized for HTR and propose new\nworkflows that leverage the unique features of handwritten text. Our\nexperiments demonstrate that the methods considered lead to advancements in the\nstate-of-the-art of SSL for HTR in a number of benchmark cases.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2024 17:33:32 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 09:57:55 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Penarrubia", "Carlos", ""], ["Garrido-Munoz", "Carlos", ""], ["Valero-Mas", "Jose J.", ""], ["Calvo-Zaragoza", "Jorge", ""]], "extracted_entities": [{"text": "Self-Supervised Learning", "label": "Few-shot Learning"}, {"text": "Spatial Context-based SSL", "label": "Few-shot Learning"}], "human_readable_topic": "Handwritten Text Recognition and OCR"}
{"id": "2404.11922", "submitter": "Hans Jarett Ong", "authors": "Hans Jarett J. Ong, Brian Godwin S. Lim, Renzo Roel P. Tan, Kazushi\n  Ikeda", "title": "Redefining the Shortest Path Problem Formulation of the Linear\n  Non-Gaussian Acyclic Model: Pairwise Likelihood Ratios, Prior Knowledge, and\n  Path Enumeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective causal discovery is essential for learning the causal graph from\nobservational data. The linear non-Gaussian acyclic model (LiNGAM) operates\nunder the assumption of a linear data generating process with non-Gaussian\nnoise in determining the causal graph. Its assumption of unmeasured confounders\nbeing absent, however, poses practical limitations. In response, empirical\nresearch has shown that the reformulation of LiNGAM as a shortest path problem\n(LiNGAM-SPP) addresses this limitation. Within LiNGAM-SPP, mutual information\nis chosen to serve as the measure of independence. A challenge is introduced -\nparameter tuning is now needed due to its reliance on kNN mutual information\nestimators. The paper proposes a threefold enhancement to the LiNGAM-SPP\nframework.\n  First, the need for parameter tuning is eliminated by using the pairwise\nlikelihood ratio in lieu of kNN-based mutual information. This substitution is\nvalidated on a general data generating process and benchmark real-world data\nsets, outperforming existing methods especially when given a larger set of\nfeatures. The incorporation of prior knowledge is then enabled by a\nnode-skipping strategy implemented on the graph representation of all causal\norderings to eliminate violations based on the provided input of relative\norderings. Flexibility relative to existing approaches is achieved. Last among\nthe three enhancements is the utilization of the distribution of paths in the\ngraph representation of all causal orderings. From this, crucial properties of\nthe true causal graph such as the presence of unmeasured confounders and\nsparsity may be inferred. To some extent, the expected performance of the\ncausal discovery algorithm may be predicted. The refinements above advance the\npracticality and performance of LiNGAM-SPP, showcasing the potential of\ngraph-search-based methodologies in advancing causal discovery.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2024 05:59:28 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 07:32:41 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Ong", "Hans Jarett J.", ""], ["Lim", "Brian Godwin S.", ""], ["Tan", "Renzo Roel P.", ""], ["Ikeda", "Kazushi", ""]], "extracted_entities": [{"text": "parameter tuning", "label": "Fine-tuning"}, {"text": "parameter tuning", "label": "Fine-tuning"}], "human_readable_topic": "Causal Analysis with Large Language Models"}
{"id": "2404.12464", "submitter": "Abhinav Rao", "authors": "Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, Maarten\n  Sap", "title": "NormAd: A Framework for Measuring the Cultural Adaptability of Large\n  Language Models", "comments": "Accepted at NAACL 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To be effectively and safely deployed to global user populations, large\nlanguage models (LLMs) may need to adapt outputs to user values and cultures,\nnot just know about them. We introduce NormAd, an evaluation framework to\nassess LLMs' cultural adaptability, specifically measuring their ability to\njudge social acceptability across varying levels of cultural norm specificity,\nfrom abstract values to explicit social norms. As an instantiation of our\nframework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions\nrepresenting social-etiquette related cultural norms from 75 countries. Through\ncomprehensive experiments on NormAd-Eti, we find that LLMs struggle to\naccurately judge social acceptability across these varying degrees of cultural\ncontexts and show stronger adaptability to English-centric cultures over those\nfrom the Global South. Even in the simplest setting where the relevant social\nnorms are provided, the best LLMs' performance (< 82\\%) lags behind humans (>\n95\\%). In settings with abstract values and country information, model\nperformance drops substantially (< 60\\%), while human accuracy remains high (>\n90\\%). Furthermore, we find that models are better at recognizing socially\nacceptable versus unacceptable situations. Our findings showcase the current\npitfalls in socio-cultural reasoning of LLMs which hinder their adaptability\nfor global audiences.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2024 18:48:50 GMT"}, {"version": "v2", "created": "Thu, 23 May 2024 17:49:51 GMT"}, {"version": "v3", "created": "Mon, 27 May 2024 00:06:31 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2024 16:02:39 GMT"}, {"version": "v5", "created": "Thu, 11 Jul 2024 14:05:59 GMT"}, {"version": "v6", "created": "Sat, 19 Oct 2024 05:35:57 GMT"}, {"version": "v7", "created": "Mon, 28 Oct 2024 00:05:23 GMT"}, {"version": "v8", "created": "Mon, 24 Feb 2025 15:50:39 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Rao", "Abhinav", ""], ["Yerukola", "Akhila", ""], ["Shah", "Vishwa", ""], ["Reinecke", "Katharina", ""], ["Sap", "Maarten", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Cultural Sensitivity in Large Language Models"}
{"id": "2404.12589", "submitter": "Michael Choi", "authors": "Michael C.H. Choi, Youjia Wang, Geoffrey Wolfer", "title": "Geometry and factorization of multivariate Markov chains with\n  applications to the swapping algorithm", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.OC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyzes the factorizability and geometry of transition matrices\nof multivariate Markov chains. Specifically, we demonstrate that the induced\nchains on factors of a product space can be regarded as information projections\nwith respect to the Kullback-Leibler divergence. This perspective yields\nHan-Shearer type inequalities and submodularity of the entropy rate of Markov\nchains, as well as applications in the context of large deviations and mixing\ntime comparison. As a concrete algorithmic application, we introduce a\nprojection sampler based on the swapping algorithm, which resamples the\nhighest-temperature coordinate at stationarity at each step. We prove that such\npractice accelerates the mixing time by multiplicative factors related to the\nnumber of temperatures and the dimension of the underlying state space when\ncompared with the original swapping algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2024 02:35:03 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2024 03:37:39 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 13:14:02 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 03:54:52 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Choi", "Michael C. H.", ""], ["Wang", "Youjia", ""], ["Wolfer", "Geoffrey", ""]], "extracted_entities": [{"text": "Kullback-Leibler divergence", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2404.14979", "submitter": "Junsong Zhang", "authors": "Junsong Zhang, Zisong Chen, Chunyu Lin, Lang Nie, Zhijie Shen, Kang\n  Liao, Junda Huang, Yao Zhao", "title": "SGFormer: Spherical Geometry Transformer for 360 Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Panoramic distortion poses a significant challenge in 360 depth estimation,\nparticularly pronounced at the north and south poles. Existing methods either\nadopt a bi-projection fusion strategy to remove distortions or model long-range\ndependencies to capture global structures, which can result in either unclear\nstructure or insufficient local perception. In this paper, we propose a\nspherical geometry transformer, named SGFormer, to address the above issues,\nwith an innovative step to integrate spherical geometric priors into vision\ntransformers. To this end, we retarget the transformer decoder to a spherical\nprior decoder (termed SPDecoder), which endeavors to uphold the integrity of\nspherical structures during decoding. Concretely, we leverage bipolar\nre-projection, circular rotation, and curve local embedding to preserve the\nspherical characteristics of equidistortion, continuity, and surface distance,\nrespectively. Furthermore, we present a query-based global conditional position\nembedding to compensate for spatial structure at varying resolutions. It not\nonly boosts the global perception of spatial position but also sharpens the\ndepth structure across different patches. Finally, we conduct extensive\nexperiments on popular benchmarks, demonstrating our superiority over\nstate-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2024 12:36:24 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2024 03:09:38 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 15:14:30 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Zhang", "Junsong", ""], ["Chen", "Zisong", ""], ["Lin", "Chunyu", ""], ["Nie", "Lang", ""], ["Shen", "Zhijie", ""], ["Liao", "Kang", ""], ["Huang", "Junda", ""], ["Zhao", "Yao", ""]], "extracted_entities": [{"text": "vision\ntransformers", "label": "Transformers"}, {"text": "curve local embedding", "label": "Embedding"}, {"text": "query-based global conditional position\nembedding", "label": "Embedding"}], "human_readable_topic": "Monocular Depth Estimation with Transformers and CNNs"}
{"id": "2404.15548", "submitter": "Eduardo Serrano Ens\\'astiga", "authors": "Eduardo Serrano-Ens\\'astiga, Chryssomalis Chryssomalakos, and John\n  Martin", "title": "Quantum metrology of rotations with mixed spin states", "comments": "15 pages, 3 figures", "journal-ref": "Phys. Rev. A 111, 022435 (2025)", "doi": "10.1103/PhysRevA.111.022435", "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of a quantum metrology protocol can be significantly\ndiminished by the interaction of the system with its environment, leading to a\nloss of purity and, as a result, a mixed state for the probing system. An\nexample is the measurement of a magnetic field through the rotation of a spin\nthat is subject to decoherence due to its coupling to a surrounding spin or\nbosonic bath. In this work, we define mixed optimal quantum rotosensors (OQRs)\nas mixed spin-$j$ states that achieve maximum sensitivity to estimate\ninfinitesimal rotations, when the rotation axis is unknown. We study two\nscenarios, where the probe states saturate the averaged fidelity or the\naveraged quantum Cram\\'er-Rao bound, the latter giving the ultimate\nsensitivity. We find that mixed OQRs can achieve sensitivity equal to that of\npure states and are obtained by mixing states from linear subspaces of\nanticoherent states. We present several examples of mixed OQRs and their\nassociated anticoherent subspaces. We also show that OQRs maximize entanglement\nin a specific sense, preserving the known relation between entanglement and\noptimal rotation sensitivity for pure states, even in the context of mixed\nstates. Our results highlight the interconnection between quantum metrology of\nrotations, anticoherence and entanglement in mixed spin states.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2024 22:33:05 GMT"}, {"version": "v2", "created": "Sat, 11 May 2024 06:14:05 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 13:26:01 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Serrano-Ens\u00e1stiga", "Eduardo", ""], ["Chryssomalakos", "Chryssomalis", ""], ["Martin", "John", ""]], "extracted_entities": [{"text": "decoherence", "label": "quantisation"}, {"text": "mixed spin-$j$ states", "label": "LLMs"}, {"text": "OQRs", "label": "LLMs"}, {"text": "entanglement", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}, {"text": "anticoherence", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2404.16496", "submitter": "Domniki Ladopoulou", "authors": "Filippo Fiocchi, Domna Ladopoulou and Petros Dellaportas", "title": "Probabilistic Multi-Layer Perceptrons for Wind Farm Condition Monitoring", "comments": "10 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a condition monitoring system for wind farms, based on normal\nbehaviour modelling using a probabilistic multi-layer perceptron with transfer\nlearning via fine-tuning. The model predicts the output power of the wind\nturbine under normal behaviour based on features retrieved from supervisory\ncontrol and data acquisition (SCADA) systems. Its advantages are that (i) it\ncan be trained with SCADA data of at least a few years, (ii) it can incorporate\nall SCADA data of all wind turbines in a wind farm as features, (iii) it\nassumes that the output power follows a normal density with heteroscedastic\nvariance and (iv) it can predict the output of one wind turbine by borrowing\nstrength from the data of all other wind turbines in a farm. Probabilistic\nguidelines for condition monitoring are given via a cumulative sum (CUSUM)\ncontrol chart, which is specifically designed based on a real-data\nclassification exercise and, hence, is adapted to the needs of a wind farm. We\nillustrate the performance of our model in a real SCADA data example which\nprovides evidence that it outperforms other probabilistic prediction models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2024 10:41:12 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 11:14:25 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Fiocchi", "Filippo", ""], ["Ladopoulou", "Domna", ""], ["Dellaportas", "Petros", ""]], "extracted_entities": [{"text": "transfer\nlearning", "label": "Few-shot Learning"}, {"text": "fine-tuning", "label": "Fine-tuning"}, {"text": "model", "label": "AI model"}], "human_readable_topic": "Machine Learning for Complex Systems Modeling"}
{"id": "2404.16704", "submitter": "Gaoyong Sun", "authors": "Chen-Chang Zeng, Zhen Cai, Guang-Heng Wang and Gaoyong Sun", "title": "Fidelity and criticality in the nonreciprocal Aubry-Andr{\\'e}-Harper\n  model", "comments": "6 pages, 5 figures", "journal-ref": "Europhysics Letters 149, 38001 (2025)", "doi": "10.1209/0295-5075/ada8d6", "report-no": null, "categories": "cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the critical behaviors of the ground and first excited states in the\none-dimensional nonreciprocal Aubry-Andr{\\'e}-Harper model using both the\nself-normal and biorthogonal fidelity susceptibilities. We demonstrate that\nfidelity susceptibility serves as a probe for the phase transition in the\nnonreciprocal AAH model. For ground states, characterized by real eigenenergies\nacross the entire regime, both fidelity susceptibilities near the critical\npoints scale as $N^{2}$, akin to the Hermitian AAH model. However, for the\nfirst-excited states, the fidelity susceptibilities exhibit distinct scaling\nlaws, contingent upon whether the lattice consists of even or odd sites. For\neven lattices, both the self-normal and biorthogonal fidelity susceptibilities\nnear the critical points continue to scale as $N^{2}$. In contrast, for odd\nlattices, the biorthogonal fidelity susceptibilities diverge, while the\nself-normal fidelity susceptibilities exhibit linear behavior, indicating a\nnovel scaling law.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2024 16:07:55 GMT"}, {"version": "v2", "created": "Wed, 1 May 2024 00:28:44 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 05:45:53 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zeng", "Chen-Chang", ""], ["Cai", "Zhen", ""], ["Wang", "Guang-Heng", ""], ["Sun", "Gaoyong", ""]], "extracted_entities": [{"text": "Hermitian AAH model", "label": "AI model"}, {"text": "novel scaling law", "label": "Scaling law"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2404.17042", "submitter": "Manuel Cuerno", "authors": "Manuel Cuerno, Fernando Galaz-Garc\\'ia, Sergio Galaz-Garc\\'ia and\n  Telmo P\\'erez-Izquierdo", "title": "Finding patterns of meaning: Reassessing Construal Clustering via\n  Bipolar Class Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical research on \\textit{construals}--social affinity groups that share\nsimilar patterns of meaning--has advanced significantly in recent years. This\nprogress is largely driven by the development of \\textit{Construal Clustering\nMethods} (CCMs), which group survey respondents into construal clusters based\non similarities in their response patterns. We identify key limitations of\nexisting CCMs, which affect their accuracy when applied to the typical\nstructures of available data, and introduce Bipolar Class Analysis (BCA), a CCM\ndesigned to address these shortcomings. BCA measures similarity in response\nshifts between expressions of support and rejection across survey respondents,\naddressing conceptual and measurement challenges in existing methods. We\nformally define BCA and demonstrate its advantages through extensive simulation\nanalyses, where it consistently outperforms existing CCMs in accurately\nidentifying construals. Along the way, we develop a novel data-generation\nprocess that approximates more closely how individuals map latent opinions onto\nobservable survey responses, as well as a new metric to evaluate the\nperformance of CCMs. Additionally, we find that applying BCA to previously\nstudied real-world datasets reveals substantively different construal patterns\ncompared to those generated by existing CCMs in prior empirical analyses.\nFinally, we discuss limitations of BCA and outline directions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2024 21:07:06 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 13:48:55 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Cuerno", "Manuel", ""], ["Galaz-Garc\u00eda", "Fernando", ""], ["Galaz-Garc\u00eda", "Sergio", ""], ["P\u00e9rez-Izquierdo", "Telmo", ""]], "extracted_entities": [{"text": "CCMs", "label": "LLMs"}, {"text": "CCMs", "label": "LLMs"}, {"text": "CCMs", "label": "LLMs"}, {"text": "CCMs", "label": "LLMs"}], "human_readable_topic": "Large Language Models for Social Science Classification"}
{"id": "2404.17335", "submitter": "Xin Zhang", "authors": "Xin Zhang, Liangxiu Han, Tam Sobeih, Lianghao Han, and Darren Dancey", "title": "A Novel Spike Transformer Network for Depth Estimation from Event\n  Cameras via Cross-modality Knowledge Distillation", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depth estimation is a critical task in computer vision, with applications in\nautonomous navigation, robotics, and augmented reality. Event cameras, which\nencode temporal changes in light intensity as asynchronous binary spikes, offer\nunique advantages such as low latency, high dynamic range, and energy\nefficiency. However, their unconventional spiking output and the scarcity of\nlabelled datasets pose significant challenges to traditional image-based depth\nestimation methods. To address these challenges, we propose a novel\nenergy-efficient Spike-Driven Transformer Network (SDT) for depth estimation,\nleveraging the unique properties of spiking data. The proposed SDT introduces\nthree key innovations: (1) a purely spike-driven transformer architecture that\nincorporates spike-based attention and residual mechanisms, enabling precise\ndepth estimation with minimal energy consumption; (2) a fusion depth estimation\nhead that combines multi-stage features for fine-grained depth prediction while\nensuring computational efficiency; and (3) a cross-modality knowledge\ndistillation framework that utilises a pre-trained vision foundation model\n(DINOv2) to enhance the training of the spiking network despite limited data\navailability.This work represents the first exploration of transformer-based\nspiking neural networks for depth estimation, providing a significant step\nforward in energy-efficient neuromorphic computing for real-world vision\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2024 11:32:53 GMT"}, {"version": "v2", "created": "Wed, 1 May 2024 08:54:54 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 10:47:58 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhang", "Xin", ""], ["Han", "Liangxiu", ""], ["Sobeih", "Tam", ""], ["Han", "Lianghao", ""], ["Dancey", "Darren", ""]], "extracted_entities": [{"text": "spike-based attention and residual mechanisms", "label": "Attention mechanism"}, {"text": "cross-modality knowledge\ndistillation", "label": "Knowledge distillation"}, {"text": "DINOv2", "label": "Foundation Model"}], "human_readable_topic": "Monocular Depth Estimation with Transformers and CNNs"}
{"id": "2404.17641", "submitter": "Vitali Telezki", "authors": "Vitali Telezki and Stefan Klumpp", "title": "Patterns of active dipolar particles in external magnetic fields", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Active particles with a (magnetic) dipole moment are of interest for steering\nself-propelled motion, but also result in novel collective effects due to their\ndipole-dipole interaction. Here systems of active dipolar particles are studied\nwith Brownian dynamics simulations to systematically characterize the different\npatterns they form, specifically in the presence of an external (magnetic)\nfield. The combination of three types of order - clustering, orientational\nalignment and chain formation - is used to classify the patterns observed in\nthese systems. In the presence of an external field, oriented chains and bands\nare found to be dominant. These structures show some similarities with columnar\ncluster seen in (passive) ferrofluids and display columnar spacing and number\nof lanes per cluster that both decrease with increasing field strength.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2024 18:01:06 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:30:55 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Telezki", "Vitali", ""], ["Klumpp", "Stefan", ""]], "extracted_entities": [{"text": "chain formation", "label": "Chain of thought"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2404.18598", "submitter": "Tianyidan Xie", "authors": "Tianyidan Xie, Rui Ma, Qian Wang, Xiaoqian Ye, Feixuan Liu, Ying Tai,\n  Zhenyu Zhang, Lanjun Wang, Zili Yi", "title": "Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse\n  Foreground-Conditioned Image Generation", "comments": "18 pages, 15 figures, project page:\n  https://anywheremultiagent.github.io, Accepted at AAAI 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in image-conditioned image generation have demonstrated\nsubstantial progress. However, foreground-conditioned image generation remains\nunderexplored, encountering challenges such as compromised object integrity,\nforeground-background inconsistencies, limited diversity, and reduced control\nflexibility. These challenges arise from current end-to-end inpainting models,\nwhich suffer from inaccurate training masks, limited foreground semantic\nunderstanding, data distribution biases, and inherent interference between\nvisual and textual prompts. To overcome these limitations, we present Anywhere,\na multi-agent framework that departs from the traditional end-to-end approach.\nIn this framework, each agent is specialized in a distinct aspect, such as\nforeground understanding, diversity enhancement, object integrity protection,\nand textual prompt consistency. Our framework is further enhanced with the\nability to incorporate optional user textual inputs, perform automated quality\nassessments, and initiate re-generation as needed. Comprehensive experiments\ndemonstrate that this modular design effectively overcomes the limitations of\nexisting end-to-end models, resulting in higher fidelity, quality, diversity\nand controllability in foreground-conditioned image generation. Additionally,\nthe Anywhere framework is extensible, allowing it to benefit from future\nadvancements in each individual agent.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2024 11:13:37 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 15:59:18 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Xie", "Tianyidan", ""], ["Ma", "Rui", ""], ["Wang", "Qian", ""], ["Ye", "Xiaoqian", ""], ["Liu", "Feixuan", ""], ["Tai", "Ying", ""], ["Zhang", "Zhenyu", ""], ["Wang", "Lanjun", ""], ["Yi", "Zili", ""]], "extracted_entities": [{"text": "data distribution biases", "label": "Model Bias and Fairness"}, {"text": "visual and textual prompts", "label": "Prompting"}, {"text": "textual prompt consistency", "label": "Prompting"}], "human_readable_topic": "Synthetic Image Generation for Deep Learning"}
{"id": "2404.19075", "submitter": "Kadri Aditya Mohan", "authors": "K. Aditya Mohan, Massimiliano Ferrucci, Chuck Divin, Garrett A.\n  Stevenson, Hyojin Kim", "title": "Distributed Stochastic Optimization of a Neural Representation Network\n  for Time-Space Tomography Reconstruction", "comments": "accepted for publication at IEEE Transactions in Computational\n  Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  4D time-space reconstruction of dynamic events or deforming objects using\nX-ray computed tomography (CT) is an important inverse problem in\nnon-destructive evaluation. Conventional back-projection based reconstruction\nmethods assume that the object remains static for the duration of several tens\nor hundreds of X-ray projection measurement images (reconstruction of\nconsecutive limited-angle CT scans). However, this is an unrealistic assumption\nfor many in-situ experiments that causes spurious artifacts and inaccurate\nmorphological reconstructions of the object. To solve this problem, we propose\nto perform a 4D time-space reconstruction using a distributed implicit neural\nrepresentation (DINR) network that is trained using a novel distributed\nstochastic training algorithm. Our DINR network learns to reconstruct the\nobject at its output by iterative optimization of its network parameters such\nthat the measured projection images best match the output of the CT forward\nmeasurement model. We use a forward measurement model that is a function of the\nDINR outputs at a sparsely sampled set of continuous valued 4D object\ncoordinates. Unlike previous neural representation architectures that forward\nand back propagate through dense voxel grids that sample the object's entire\ntime-space coordinates, we only propagate through the DINR at a small subset of\nobject coordinates in each iteration resulting in an order-of-magnitude\nreduction in memory and compute for training. DINR leverages distributed\ncomputation across several compute nodes and GPUs to produce high-fidelity 4D\ntime-space reconstructions. We use both simulated parallel-beam and\nexperimental cone-beam X-ray CT datasets to demonstrate the superior\nperformance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2024 19:41:51 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 00:31:31 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Mohan", "K. Aditya", ""], ["Ferrucci", "Massimiliano", ""], ["Divin", "Chuck", ""], ["Stevenson", "Garrett A.", ""], ["Kim", "Hyojin", ""]], "extracted_entities": [{"text": "forward\nmeasurement model", "label": "Neural Language Model"}, {"text": "forward measurement model", "label": "Neural Language Model"}], "human_readable_topic": "Self-Supervised Learning in Medical Imaging"}
{"id": "2404.19227", "submitter": "Anudeep Das", "authors": "Anudeep Das, Vasisht Duddu, Rui Zhang, N. Asokan", "title": "Espresso: Robust Concept Filtering in Text-to-Image Models", "comments": "ACM Conference on Data and Application Security and Privacy\n  (CODASPY), 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion based text-to-image models are trained on large datasets scraped\nfrom the Internet, potentially containing unacceptable concepts (e.g.,\ncopyright-infringing or unsafe). We need concept removal techniques (CRTs)\nwhich are i) effective in preventing the generation of images with unacceptable\nconcepts, ii) utility-preserving on acceptable concepts, and, iii) robust\nagainst evasion with adversarial prompts. No prior CRT satisfies all these\nrequirements simultaneously. We introduce Espresso, the first robust concept\nfilter based on Contrastive Language-Image Pre-Training (CLIP). We identify\nunacceptable concepts by using the distance between the embedding of a\ngenerated image to the text embeddings of both unacceptable and acceptable\nconcepts. This lets us fine-tune for robustness by separating the text\nembeddings of unacceptable and acceptable concepts while preserving utility. We\npresent a pipeline to evaluate various CRTs to show that Espresso is more\neffective and robust than prior CRTs, while retaining utility.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2024 03:13:06 GMT"}, {"version": "v2", "created": "Wed, 1 May 2024 18:30:14 GMT"}, {"version": "v3", "created": "Wed, 8 May 2024 00:22:32 GMT"}, {"version": "v4", "created": "Fri, 7 Jun 2024 14:28:24 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2024 16:51:21 GMT"}, {"version": "v6", "created": "Sun, 15 Dec 2024 16:20:37 GMT"}, {"version": "v7", "created": "Wed, 26 Feb 2025 14:53:47 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Das", "Anudeep", ""], ["Duddu", "Vasisht", ""], ["Zhang", "Rui", ""], ["Asokan", "N.", ""]], "extracted_entities": [{"text": "adversarial prompts", "label": "Prompting"}, {"text": "text embeddings", "label": "Embedding"}, {"text": "fine-tune for robustness", "label": "Fine-tuning"}, {"text": "text\nembeddings", "label": "Embedding"}], "human_readable_topic": "Concept Erasure in Text-to-Image Models"}
{"id": "2405.00556", "submitter": "Elham Shammar Miss", "authors": "Elham Shammar, Xiaohui Cui and Mohammed A. A. Al-qaness", "title": "Swarm Learning: A Survey of Concepts, Applications, and Trends", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have raised privacy and security concerns due to their\nreliance on large datasets on central servers. As the number of Internet of\nThings (IoT) devices increases, artificial intelligence (AI) will be crucial\nfor resource management, data processing, and knowledge acquisition. To address\nthose issues, federated learning (FL) has introduced a novel approach to\nbuilding a versatile, large-scale machine learning framework that operates in a\ndecentralized and hardware-agnostic manner. However, FL faces network bandwidth\nlimitations and data breaches. To reduce the central dependency in FL and\nincrease scalability, swarm learning (SL) has been proposed in collaboration\nwith Hewlett Packard Enterprise (HPE). SL represents a decentralized machine\nlearning framework that leverages blockchain technology for secure, scalable,\nand private data management. A blockchain-based network enables the exchange\nand aggregation of model parameters among participants, thus mitigating the\nrisk of a single point of failure and eliminating communication bottlenecks. To\nthe best of our knowledge, this survey is the first to introduce the principles\nof Swarm Learning, its architectural design, and its fields of application. In\naddition, it highlights numerous research avenues that require further\nexploration by academic and industry communities to unlock the full potential\nand applications of SL.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2024 14:59:24 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 13:21:30 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Shammar", "Elham", ""], ["Cui", "Xiaohui", ""], ["Al-qaness", "Mohammed A. A.", ""]], "extracted_entities": [{"text": "swarm learning", "label": "Few-shot Learning"}, {"text": "Swarm Learning", "label": "Few-shot Learning"}], "human_readable_topic": "Federated Learning for Private Data"}
{"id": "2405.00915", "submitter": "Evin P{\\i}nar \\\"Ornek", "authors": "Guangyao Zhai, Evin P{\\i}nar \\\"Ornek, Dave Zhenyu Chen, Ruotong Liao,\n  Yan Di, Nassir Navab, Federico Tombari, Benjamin Busam", "title": "EchoScene: Indoor Scene Generation via Information Echo over Scene Graph\n  Diffusion", "comments": "Nectar Track at 3DV 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present EchoScene, an interactive and controllable generative model that\ngenerates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch\ndiffusion model that dynamically adapts to scene graphs. Existing methods\nstruggle to handle scene graphs due to varying numbers of nodes, multiple edge\ncombinations, and manipulator-induced node-edge operations. EchoScene overcomes\nthis by associating each node with a denoising process and enables\ncollaborative information exchange, enhancing controllable and consistent\ngeneration aware of global constraints. This is achieved through an information\necho scheme in both shape and layout branches. At every denoising step, all\nprocesses share their denoising data with an information exchange unit that\ncombines these updates using graph convolution. The scheme ensures that the\ndenoising processes are influenced by a holistic understanding of the scene\ngraph, facilitating the generation of globally coherent scenes. The resulting\nscenes can be manipulated during inference by editing the input scene graph and\nsampling the noise in the diffusion model. Extensive experiments validate our\napproach, which maintains scene controllability and surpasses previous methods\nin generation fidelity. Moreover, the generated scenes are of high quality and\nthus directly compatible with off-the-shelf texture generation. Code and\ntrained models are open-sourced.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2024 00:04:02 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 12:28:21 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhai", "Guangyao", ""], ["\u00d6rnek", "Evin P\u0131nar", ""], ["Chen", "Dave Zhenyu", ""], ["Liao", "Ruotong", ""], ["Di", "Yan", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""], ["Busam", "Benjamin", ""]], "extracted_entities": [{"text": "open-sourced", "label": "Open-source LLMs"}], "human_readable_topic": "Text-to-3D Scene Generation and Understanding"}
{"id": "2405.01462", "submitter": "Dominik Fuchsgruber", "authors": "Dominik Fuchsgruber, Tom Wollschl\\\"ager, Bertrand Charpentier, Antonio\n  Oroz, Stephan G\\\"unnemann", "title": "Uncertainty for Active Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty Sampling is an Active Learning strategy that aims to improve the\ndata efficiency of machine learning models by iteratively acquiring labels of\ndata points with the highest uncertainty. While it has proven effective for\nindependent data its applicability to graphs remains under-explored. We propose\nthe first extensive study of Uncertainty Sampling for node classification: (1)\nWe benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a\nsignificant performance gap to other Active Learning strategies. (2) We develop\nground-truth Bayesian uncertainty estimates in terms of the data generating\nprocess and prove their effectiveness in guiding Uncertainty Sampling toward\noptimal queries. We confirm our results on synthetic data and design an\napproximate approach that consistently outperforms other uncertainty estimators\non real datasets. (3) Based on this analysis, we relate pitfalls in modeling\nuncertainty to existing methods. Our analysis enables and informs the\ndevelopment of principled uncertainty estimation on graphs.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2024 16:50:47 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2024 16:11:33 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 11:45:57 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Fuchsgruber", "Dominik", ""], ["Wollschl\u00e4ger", "Tom", ""], ["Charpentier", "Bertrand", ""], ["Oroz", "Antonio", ""], ["G\u00fcnnemann", "Stephan", ""]], "extracted_entities": [{"text": "Uncertainty Sampling", "label": "Zero-shot Learning"}, {"text": "Uncertainty Sampling", "label": "Zero-shot Learning"}, {"text": "Uncertainty Sampling", "label": "Zero-shot Learning"}, {"text": "Uncertainty Sampling", "label": "Zero-shot Learning"}], "human_readable_topic": "Uncertainty in Large Language Models"}
{"id": "2405.01550", "submitter": "Mohammad Jobayer Hossain", "authors": "Anika Tabassum Raisa, Syed Nazmus Sakib, Mohammad Jobayer Hossain,\n  Kaiser Ahmed Rocky, Abu Kowsar", "title": "Advances in multijunction solar cells: an overview", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advanced multijunction solar cell (MJSC) has emerged as a frontrunner in\nphotovoltaic literature due to its superior photoconversion efficiency (PCE)\nowing to its complex fabrication procedure and high costs. This article aims to\nsystematically review the advancements of III-V MJSCs by focusing on\ncomputational modelling and experimental fabrication methodologies. In\naddition, it addresses the technical barriers that have hindered the\nprogression of MJSC technology while also evaluating the current status and\nprospects of these cells. The findings indicate that III-V MJSCs hold\nsignificant promise for space applications. However, advancements in materials\nscience, growth techniques, and structural optimization are crucial for\nreducing fabrication costs to make these cells more viable for terrestrial use.\nIn this context, alternatives such as perovskite/Si or perovskite/chalcogenide\ntandem solar cells emerge as viable options. By synthesizing insights from a\nthorough analysis of recent literature, this review serves as a valuable\nresource for researchers, industry practitioners, and newcomers seeking to\ndeepen their understanding of the research methodologies, growth techniques,\nand the associated challenges and opportunities within the realm of MJSCs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2024 17:11:27 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 14:01:36 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Raisa", "Anika Tabassum", ""], ["Sakib", "Syed Nazmus", ""], ["Hossain", "Mohammad Jobayer", ""], ["Rocky", "Kaiser Ahmed", ""], ["Kowsar", "Abu", ""]], "extracted_entities": [{"text": "MJSCs", "label": "LLMs"}], "human_readable_topic": "Uncategorized"}
{"id": "2405.03546", "submitter": "Xin Ding Dr.", "authors": "Xin Ding and Yongwei Wang and Kao Zhang and Z. Jane Wang", "title": "CCDM: Continuous Conditional Diffusion Models for Image Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous Conditional Generative Modeling (CCGM) estimates high-dimensional\ndata distributions, such as images, conditioned on scalar continuous variables\n(aka regression labels). While Continuous Conditional Generative Adversarial\nNetworks (CcGANs) were designed for this task, their instability during\nadversarial learning often leads to suboptimal results. Conditional Diffusion\nModels (CDMs) offer a promising alternative, generating more realistic images,\nbut their diffusion processes, label conditioning, and model fitting procedures\nare either not optimized for or incompatible with CCGM, making it difficult to\nintegrate CcGANs' vicinal approach. To address these issues, we introduce\nContinuous Conditional Diffusion Models (CCDMs), the first CDM specifically\ntailored for CCGM. CCDMs address existing limitations with specially designed\nconditional diffusion processes, a novel hard vicinal image denoising loss, a\ncustomized label embedding method, and efficient conditional sampling\nprocedures. Through comprehensive experiments on four datasets with resolutions\nranging from 64x64 to 192x192, we demonstrate that CCDMs outperform\nstate-of-the-art CCGM models, establishing a new benchmark. Ablation studies\nfurther validate the model design and implementation, highlighting that some\nwidely used CDM implementations are ineffective for the CCGM task. Our code is\npublicly available at https://github.com/UBCDingXin/CCDM.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2024 15:10:19 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 12:45:40 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Ding", "Xin", ""], ["Wang", "Yongwei", ""], ["Zhang", "Kao", ""], ["Wang", "Z. Jane", ""]], "extracted_entities": [{"text": "adversarial learning", "label": "Few-shot Learning"}, {"text": "CCDMs", "label": "LLMs"}, {"text": "CCDMs", "label": "LLMs"}], "human_readable_topic": "Generative Adversarial Networks (GANs)"}
{"id": "2405.05255", "submitter": "Nayantara Mudur", "authors": "Nayantara Mudur, Carolina Cuesta-Lazaro, Douglas P. Finkbeiner", "title": "Diffusion-HMC: Parameter Inference with Diffusion-model-driven\n  Hamiltonian Monte Carlo", "comments": "Published in ApJ, Updated with the accepted version", "journal-ref": "The Astrophysical Journal, 978:64 (14pp), 2025", "doi": "10.3847/1538-4357/ad8bc3", "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diffusion generative models have excelled at diverse image generation and\nreconstruction tasks across fields. A less explored avenue is their application\nto discriminative tasks involving regression or classification problems. The\ncornerstone of modern cosmology is the ability to generate predictions for\nobserved astrophysical fields from theory and constrain physical models from\nobservations using these predictions. This work uses a single diffusion\ngenerative model to address these interlinked objectives -- as a surrogate\nmodel or emulator for cold dark matter density fields conditional on input\ncosmological parameters, and as a parameter inference model that solves the\ninverse problem of constraining the cosmological parameters of an input field.\nThe model is able to emulate fields with summary statistics consistent with\nthose of the simulated target distribution. We then leverage the approximate\nlikelihood of the diffusion generative model to derive tight constraints on\ncosmology by using the Hamiltonian Monte Carlo method to sample the posterior\non cosmological parameters for a given test image. Finally, we demonstrate that\nthis parameter inference approach is more robust to small perturbations of\nnoise to the field than baseline parameter inference networks.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2024 17:59:03 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 18:59:56 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Mudur", "Nayantara", ""], ["Cuesta-Lazaro", "Carolina", ""], ["Finkbeiner", "Douglas P.", ""]], "extracted_entities": [{"text": "diffusion\ngenerative model", "label": "AI model"}, {"text": "diffusion generative model", "label": "AI model"}], "human_readable_topic": "Generative AI and Variational Models"}
{"id": "2405.05930", "submitter": "Siyuan Li", "authors": "Siyuan Li, Xi Lin, Yaju Liu, Xiang Chen, Jianhua Li", "title": "Trustworthy AI-Generative Content for Intelligent Network Service:\n  Robustness, Security, and Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-generated content (AIGC) models, represented by large language models\n(LLM), have revolutionized content creation. High-speed next-generation\ncommunication technology is an ideal platform for providing powerful AIGC\nnetwork services. At the same time, advanced AIGC techniques can also make\nfuture network services more intelligent, especially various online content\ngeneration services. However, the significant untrustworthiness concerns of\ncurrent AIGC models, such as robustness, security, and fairness, greatly affect\nthe credibility of intelligent network services, especially in ensuring secure\nAIGC services. This paper proposes TrustGAIN, a trustworthy AIGC framework that\nincorporates robust, secure, and fair network services. We first discuss the\nrobustness to adversarial attacks faced by AIGC models in network systems and\nthe corresponding protection issues. Subsequently, we emphasize the importance\nof avoiding unsafe and illegal services and ensuring the fairness of the AIGC\nnetwork services. Then as a case study, we propose a novel sentiment\nanalysis-based detection method to guide the robust detection of unsafe content\nin network services. We conduct our experiments on fake news, malicious code,\nand unsafe review datasets to represent LLM application scenarios. Our results\nindicate that TrustGAIN is an exploration of future networks that can support\ntrustworthy AIGC network services.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2024 17:16:20 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 08:09:23 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Li", "Siyuan", ""], ["Lin", "Xi", ""], ["Liu", "Yaju", ""], ["Chen", "Xiang", ""], ["Li", "Jianhua", ""]], "extracted_entities": [{"text": "fairness", "label": "Model Bias and Fairness"}, {"text": "fair", "label": "Model Bias and Fairness"}, {"text": "robustness", "label": "Model Bias and Fairness"}, {"text": "fairness", "label": "Model Bias and Fairness"}, {"text": "LLM", "label": "Large Language Model"}], "human_readable_topic": "Fake News Detection in AI-Generated Content"}
{"id": "2405.06327", "submitter": "Miryam Gnazzo", "authors": "Miryam Gnazzo and Leonardo Robol", "title": "Backward errors for multiple eigenpairs in structured and unstructured\n  nonlinear eigenvalue problems", "comments": "26 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a nonlinear matrix-valued function $F(\\lambda)$ and approximate\neigenpairs $(\\lambda_i, v_i)$, we discuss how to determine the smallest\nperturbation $\\delta F$ such that $[F + \\delta F](\\lambda_i) v_i = 0$; we call\nthe distance between the $F$ and $F + \\delta F$ the backward error for this set\nof approximate eigenpairs. We focus on the case where $F(\\lambda)$ is given as\na linear combination of scalar functions multiplying matrix coefficients $F_i$,\nand the perturbation is done on the matrix coefficients. We provide inexpensive\nupper bounds, and a way to accurately compute the backward error by means of\ndirect computations or through Riemannian optimization. We also discuss how the\nbackward error can be determined when the $F_i$ have particular structures\n(such as symmetry, sparsity, or low-rank), and the perturbations are required\nto preserve them. For special cases (such as for symmetric coefficients),\nexplicit and inexpensive formulas to compute the $\\delta F_i$ are also given.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2024 08:57:26 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 17:57:56 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Gnazzo", "Miryam", ""], ["Robol", "Leonardo", ""]], "extracted_entities": [{"text": "Riemannian optimization", "label": "Fine-tuning"}], "human_readable_topic": "Hyperparameter Optimization Methods"}
{"id": "2405.11563", "submitter": "Kwangjae Lee", "authors": "Kwangjae Lee, Jung Hoon Lee, and Wan Choi", "title": "User-Centric Association and Feedback Bit Allocation for FDD Cell-Free\n  Massive MIMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel approach to user-centric association and\nfeedback bit allocation for the downlink of a cell-free massive MIMO (CF-mMIMO)\nsystem, operating under limited feedback constraints. In CF-mMIMO systems\nemploying frequency division duplexing, each access point (AP) relies on\nchannel information provided by its associated user equipments (UEs) for\nbeamforming design. Since the uplink control channel is typically shared among\nUEs, we take account of each AP's total feedback budget, which is distributed\namong its associated UEs. By employing the Saleh-Valenzuela multi-resolvable\npath channel model with different average path gains, we first identify\nnecessary feedback information for each UE, along with an appropriate codebook\nstructure. This structure facilitates adaptive quantization of multiple paths\nbased on their dominance. We then formulate a joint optimization problem\naddressing user-centric UE-AP association and feedback bit allocation. To\naddress this challenge, we analyze the impact of feedback bit allocation and\nderive our proposed scheme from the solution of an alternative optimization\nproblem aimed at devising long-term policies, explicitly considering the\neffects of feedback bit allocation. Numerical results show that our proposed\nscheme effectively enhances the performance of conventional approaches in\nCF-mMIMO systems.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2024 14:29:02 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 02:30:09 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Lee", "Kwangjae", ""], ["Lee", "Jung Hoon", ""], ["Choi", "Wan", ""]], "extracted_entities": [{"text": "Saleh-Valenzuela multi-resolvable\npath channel model", "label": "AI model"}, {"text": "adaptive quantization", "label": "quantisation"}], "human_readable_topic": "Massive MIMO Channel Prediction and Reconstruction"}
{"id": "2405.11874", "submitter": "Zhiyu Li", "authors": "Qingchen Yu, Zifan Zheng, Shichao Song, Zhiyu Li, Feiyu Xiong, Bo\n  Tang, Ding Chen", "title": "xFinder: Large Language Models as Automated Evaluators for Reliable\n  Evaluation", "comments": "Accepted by ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous advancement of large language models (LLMs) has brought\nincreasing attention to the critical issue of developing fair and reliable\nmethods for evaluating their performance. Particularly, the emergence of\ncheating phenomena, such as test set leakage and prompt format overfitting,\nposes significant challenges to the reliable evaluation of LLMs. As evaluation\nframeworks commonly use Regular Expression (RegEx) for answer extraction,\nmodels may adjust their responses to fit formats easily handled by RegEx.\nNevertheless, the key answer extraction module based on RegEx frequently\nsuffers from extraction errors. Furthermore, recent studies proposing\nfine-tuned LLMs as judge models for automated evaluation face challenges in\nterms of generalization ability and fairness. This paper comprehensively\nanalyzes the entire LLM evaluation chain and demonstrates that optimizing the\nkey answer extraction module improves extraction accuracy and enhances\nevaluation reliability. Our findings suggest that improving the key answer\nextraction module can lead to higher judgment accuracy and improved evaluation\nefficiency compared to the judge models. To address these issues, we propose\nxFinder, a novel evaluator for answer extraction and matching in LLM\nevaluation. As part of this process, we create a specialized dataset, the\n\\textbf{K}ey \\textbf{A}nswer \\textbf{F}inder (KAF) dataset, to ensure effective\nmodel training and evaluation. Generalization tests and real-world evaluations\nshow that the smallest xFinder model, with only 500 million parameters,\nachieves an average extraction accuracy of 93.42\\%. In contrast, RegEx accuracy\nin the best evaluation framework is 74.38\\%. The final judgment accuracy of\nxFinder reaches 97.61\\%, outperforming existing evaluation frameworks and judge\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2024 08:30:13 GMT"}, {"version": "v2", "created": "Thu, 23 May 2024 07:00:45 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 11:04:02 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Yu", "Qingchen", ""], ["Zheng", "Zifan", ""], ["Song", "Shichao", ""], ["Li", "Zhiyu", ""], ["Xiong", "Feiyu", ""], ["Tang", "Bo", ""], ["Chen", "Ding", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "fairness", "label": "Model Bias and Fairness"}], "human_readable_topic": "Evaluating Large Language Models for Reliable Answering"}
{"id": "2405.12910", "submitter": "Holli Sargeant", "authors": "Holli Sargeant, Ahmed Izzidien, Felix Steffek", "title": "Topic Classification of Case Law Using a Large Language Model and a New\n  Taxonomy for UK Law: AI Insights into Summary Judgment", "comments": null, "journal-ref": "Artificial Intelligence and Law (2025)", "doi": "10.1007/s10506-025-09434-0", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2024 16:30:25 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2024 15:40:54 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 10:56:25 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Sargeant", "Holli", ""], ["Izzidien", "Ahmed", ""], ["Steffek", "Felix", ""]], "extracted_entities": [{"text": "Claude 3 Opus", "label": "Large Language Model"}, {"text": "Claude 3 Opus", "label": "Large Language Model"}], "human_readable_topic": "Legal Language Models Evaluation"}
{"id": "2405.13576", "submitter": "Jiajie Jin", "authors": "Jiajie Jin, Yutao Zhu, Guanting Dong, Yuyao Zhang, Xinyu Yang,\n  Chenghao Zhang, Tong Zhao, Zhao Yang, Zhicheng Dou, Ji-Rong Wen", "title": "FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\n  Research", "comments": "The paper is accepted by WWW2025 Resource Track", "journal-ref": null, "doi": "10.1145/3701716.3715313.", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advent of large language models (LLMs) and multimodal large language\nmodels (MLLMs), the potential of retrieval-augmented generation (RAG) has\nattracted considerable research attention. Various novel algorithms and models\nhave been introduced to enhance different aspects of RAG systems. However, the\nabsence of a standardized framework for implementation, coupled with the\ninherently complex RAG process, makes it challenging and time-consuming for\nresearchers to compare and evaluate these approaches in a consistent\nenvironment. Existing RAG toolkits, such as LangChain and LlamaIndex, while\navailable, are often heavy and inflexibly, failing to meet the customization\nneeds of researchers. In response to this challenge, we develop \\ours{}, an\nefficient and modular open-source toolkit designed to assist researchers in\nreproducing and comparing existing RAG methods and developing their own\nalgorithms within a unified framework. Our toolkit has implemented 16 advanced\nRAG methods and gathered and organized 38 benchmark datasets. It has various\nfeatures, including a customizable modular framework, multimodal RAG\ncapabilities, a rich collection of pre-implemented RAG works, comprehensive\ndatasets, efficient auxiliary pre-processing scripts, and extensive and\nstandard evaluation metrics. Our toolkit and resources are available at\nhttps://github.com/RUC-NLPIR/FlashRAG.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2024 12:12:40 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 02:46:52 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Jin", "Jiajie", ""], ["Zhu", "Yutao", ""], ["Dong", "Guanting", ""], ["Zhang", "Yuyao", ""], ["Yang", "Xinyu", ""], ["Zhang", "Chenghao", ""], ["Zhao", "Tong", ""], ["Yang", "Zhao", ""], ["Dou", "Zhicheng", ""], ["Wen", "Ji-Rong", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "multimodal large language\nmodels", "label": "Large Language Model"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}, {"text": "LangChain", "label": "Llama"}, {"text": "LlamaIndex", "label": "Llama"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}, {"text": "RAG", "label": "RAG"}], "human_readable_topic": "Retrieval-Augmented Generation for Large Language Models"}
{"id": "2405.13861", "submitter": "Jiuqi Wang", "authors": "Jiuqi Wang, Ethan Blaser, Hadi Daneshmand, Shangtong Zhang", "title": "Transformers Can Learn Temporal Difference Methods for In-Context\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, reinforcement learning (RL) agents learn to solve new tasks by\nupdating their neural network parameters through interactions with the task\nenvironment. However, recent works demonstrate that some RL agents, after\ncertain pretraining procedures, can learn to solve unseen new tasks without\nparameter updates, a phenomenon known as in-context reinforcement learning\n(ICRL). The empirical success of ICRL is widely attributed to the hypothesis\nthat the forward pass of the pretrained agent neural network implements an RL\nalgorithm. In this paper, we support this hypothesis by showing, both\nempirically and theoretically, that when a transformer is trained for policy\nevaluation tasks, it can discover and learn to implement temporal difference\nlearning in its forward pass.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2024 17:38:16 GMT"}, {"version": "v2", "created": "Sun, 26 May 2024 21:27:03 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2024 15:10:28 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 20:47:35 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Wang", "Jiuqi", ""], ["Blaser", "Ethan", ""], ["Daneshmand", "Hadi", ""], ["Zhang", "Shangtong", ""]], "extracted_entities": [{"text": "in-context reinforcement learning", "label": "Few-shot Learning"}, {"text": "ICRL", "label": "Few-shot Learning"}, {"text": "temporal difference\nlearning", "label": "Few-shot Learning"}], "human_readable_topic": "Reinforcement Learning with Transformers"}
{"id": "2405.13922", "submitter": "Cornelius Emde", "authors": "Cornelius Emde, Francesco Pinto, Thomas Lukasiewicz, Philip H.S. Torr,\n  Adel Bibi", "title": "Towards Certification of Uncertainty Calibration under Adversarial\n  Attacks", "comments": "10 pages main paper, appendix included Published at: International\n  Conference on Learning Representations (ICLR) 2025", "journal-ref": "International Conference on Learning Representations (ICLR) 2025", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since neural classifiers are known to be sensitive to adversarial\nperturbations that alter their accuracy, \\textit{certification methods} have\nbeen developed to provide provable guarantees on the insensitivity of their\npredictions to such perturbations. Furthermore, in safety-critical\napplications, the frequentist interpretation of the confidence of a classifier\n(also known as model calibration) can be of utmost importance. This property\ncan be measured via the Brier score or the expected calibration error. We show\nthat attacks can significantly harm calibration, and thus propose certified\ncalibration as worst-case bounds on calibration under adversarial\nperturbations. Specifically, we produce analytic bounds for the Brier score and\napproximate bounds via the solution of a mixed-integer program on the expected\ncalibration error. Finally, we propose novel calibration attacks and\ndemonstrate how they can improve model calibration through \\textit{adversarial\ncalibration training}.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2024 18:52:09 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 16:29:29 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 10:19:07 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Emde", "Cornelius", ""], ["Pinto", "Francesco", ""], ["Lukasiewicz", "Thomas", ""], ["Torr", "Philip H. S.", ""], ["Bibi", "Adel", ""]], "extracted_entities": [{"text": "Brier score", "label": "BERT"}, {"text": "Brier score", "label": "BERT"}], "human_readable_topic": "Adversarial Robustness in Deep Learning Models"}
{"id": "2405.13929", "submitter": "Aleksandr Nikolich", "authors": "Aleksandr Nikolich, Konstantin Korolev, Sergei Bratchikov, Igor\n  Kiselev, Artem Shelmanov", "title": "Vikhr: Constructing a State-of-the-art Bilingual Open-Source\n  Instruction-Following Large Language Model for Russian", "comments": "Accepted at WMRL @ EMNLP-2024", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a surge in developing various Large Language Models (LLMs).\nHowever, text generation for languages other than English often faces\nsignificant challenges, including poor generation quality and reduced\ncomputational performance due to the disproportionate representation of tokens\nin the model's vocabulary. In this work, we address these issues by developing\na pipeline for adapting English-oriented pre-trained models to other languages\nand constructing efficient bilingual LLMs. Using this pipeline, we construct\nVikhr, a state-of-the-art bilingual open-source instruction-following LLM\ndesigned specifically for the Russian language. \"Vikhr\" refers to the name of\nthe Mistral LLM series and means a \"strong gust of wind.\" Unlike previous\nRussian-language models that typically rely on LoRA adapters on top of\nEnglish-oriented models, sacrificing performance for lower training costs,\nVikhr features an adapted tokenizer vocabulary and undergoes continued\npre-training and instruction tuning of all weights. This not only enhances the\nmodel's performance but also significantly improves its computational and\ncontextual efficiency. The remarkable performance of Vikhr across various\nRussian-language benchmarks can also be attributed to our efforts in expanding\ninstruction datasets and corpora for continued pre-training. Vikhr not only\nsets a new state of the art among open-source LLMs for Russian but even\noutperforms some proprietary closed-source models on certain benchmarks. The\nmodel weights, instruction sets, and code are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2024 18:58:58 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2024 17:32:23 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2024 08:47:36 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2024 10:57:21 GMT"}, {"version": "v5", "created": "Mon, 24 Feb 2025 13:24:20 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Nikolich", "Aleksandr", ""], ["Korolev", "Konstantin", ""], ["Bratchikov", "Sergei", ""], ["Kiselev", "Igor", ""], ["Shelmanov", "Artem", ""]], "extracted_entities": [{"text": "Mistral", "label": "Mistral"}, {"text": "instruction tuning", "label": "Fine-tuning"}], "human_readable_topic": "Improving Instruction Following in Large Language Models"}
{"id": "2405.14117", "submitter": "Chen Yuheng", "authors": "Yuheng Chen, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao", "title": "Knowledge Localization: Mission Not Accomplished? Enter Query\n  Localization!", "comments": "ICLR 2025 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large language models (LLMs) store extensive factual knowledge, but the\nmechanisms behind how they store and express this knowledge remain unclear. The\nKnowledge Neuron (KN) thesis is a prominent theory for explaining these\nmechanisms. This theory is based on the Knowledge Localization (KL) assumption,\nwhich suggests that a fact can be localized to a few knowledge storage units,\nnamely knowledge neurons.\n  However, this assumption has two limitations: first, it may be too rigid\nregarding knowledge storage, and second, it neglects the role of the attention\nmodule in knowledge expression.\n  In this paper, we first re-examine the KL assumption and demonstrate that its\nlimitations do indeed exist. To address these, we then present two new\nfindings, each targeting one of the limitations: one focusing on knowledge\nstorage and the other on knowledge expression. We summarize these findings as\n\\textbf{Query Localization} (QL) assumption and argue that the KL assumption\ncan be viewed as a simplification of the QL assumption. Based on QL assumption,\nwe further propose the Consistency-Aware KN modification method, which improves\nthe performance of knowledge modification, further validating our new\nassumption. We conduct 39 sets of experiments, along with additional\nvisualization experiments, to rigorously confirm our conclusions. Code is\navailable at https://github.com/heng840/KnowledgeLocalization.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2024 02:44:12 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 12:29:11 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Chen", "Yuheng", ""], ["Cao", "Pengfei", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]], "extracted_entities": [{"text": "Large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "attention\nmodule", "label": "Attention mechanism"}], "human_readable_topic": "Knowledge Editing in Large Language Models"}
{"id": "2405.14660", "submitter": "Zhuowei Li", "authors": "Zhuowei Li, Zihao Xu, Ligong Han, Yunhe Gao, Song Wen, Di Liu, Hao\n  Wang, Dimitris N. Metaxas", "title": "Implicit In-context Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In-context Learning (ICL) empowers large language models (LLMs) to swiftly\nadapt to unseen tasks at inference-time by prefixing a few demonstration\nexamples before queries. Despite its versatility, ICL incurs substantial\ncomputational and memory overheads compared to zero-shot learning and is\nsensitive to the selection and order of demonstration examples. In this work,\nwe introduce Implicit In-context Learning (I2CL), an innovative paradigm that\nreduces the inference cost of ICL to that of zero-shot learning with minimal\ninformation loss. I2CL operates by first generating a condensed vector\nrepresentation, namely a context vector, extracted from the demonstration\nexamples. It then conducts an inference-time intervention through injecting a\nlinear combination of the context vector and query activations back into the\nmodel's residual streams. Empirical evaluation on nine real-world tasks across\nthree model architectures demonstrates that I2CL achieves few-shot level\nperformance at zero-shot inference cost, and it exhibits robustness against\nvariations in demonstration examples. Furthermore, I2CL facilitates a novel\nrepresentation of task-ids, enhancing task similarity detection and fostering\neffective transfer learning. We also perform a comprehensive analysis and\nablation study on I2CL, offering deeper insights into its internal mechanisms.\nCode is available at https://github.com/LzVv123456/I2CL.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2024 14:57:52 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 14:49:33 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Li", "Zhuowei", ""], ["Xu", "Zihao", ""], ["Han", "Ligong", ""], ["Gao", "Yunhe", ""], ["Wen", "Song", ""], ["Liu", "Di", ""], ["Wang", "Hao", ""], ["Metaxas", "Dimitris N.", ""]], "extracted_entities": [{"text": "ICL", "label": "Zero-shot Learning"}, {"text": "zero-shot learning", "label": "Zero-shot Learning"}, {"text": "ICL", "label": "Zero-shot Learning"}, {"text": "zero-shot learning", "label": "Zero-shot Learning"}], "human_readable_topic": "In-Context Learning for NLP Tasks"}
{"id": "2405.14804", "submitter": "Xin Xu", "authors": "Xin Xu, Tong Xiao, Zitong Chao, Zhenya Huang, Can Yang, Yang Wang", "title": "Can LLMs Solve longer Math Word Problems Better?", "comments": "Accepted to ICLR 2025", "journal-ref": "International Conference on Learning Representations (ICLR 2025)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Math Word Problems (MWPs) play a vital role in assessing the capabilities of\nLarge Language Models (LLMs), yet current research primarily focuses on\nquestions with concise contexts. The impact of longer contexts on mathematical\nreasoning remains under-explored. This study pioneers the investigation of\nContext Length Generalizability (CoLeG), which refers to the ability of LLMs to\nsolve MWPs with extended narratives. We introduce Extended Grade-School Math\n(E-GSM), a collection of MWPs featuring lengthy narratives, and propose two\nnovel metrics to evaluate the efficacy and resilience of LLMs in tackling these\nproblems. Our analysis of existing zero-shot prompting techniques with\nproprietary LLMs along with open-source LLMs reveals a general deficiency in\nCoLeG. To alleviate these issues, we propose tailored approaches for different\ncategories of LLMs. For proprietary LLMs, we introduce a new instructional\nprompt designed to mitigate the impact of long contexts. For open-source LLMs,\nwe develop a novel auxiliary task for fine-tuning to enhance CoLeG. Our\ncomprehensive results demonstrate the effectiveness of our proposed methods,\nshowing improved performance on E-GSM. Additionally, we conduct an in-depth\nanalysis to differentiate the effects of semantic understanding and reasoning\nefficacy, showing that our methods improves the latter. We also establish the\ngeneralizability of our methods across several other MWP benchmarks. Our\nfindings highlight the limitations of current LLMs and offer practical\nsolutions correspondingly, paving the way for further exploration of model\ngeneralizability and training methodologies.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2024 17:13:50 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2025 15:47:09 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 07:58:27 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 02:21:40 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Xu", "Xin", ""], ["Xiao", "Tong", ""], ["Chao", "Zitong", ""], ["Huang", "Zhenya", ""], ["Yang", "Can", ""], ["Wang", "Yang", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "open-source LLMs", "label": "Open-source LLMs"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "instructional\nprompt", "label": "Prompting"}, {"text": "open-source LLMs", "label": "Open-source LLMs"}, {"text": "fine-tuning", "label": "Fine-tuning"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Prompt Engineering for Large Language Models"}
{"id": "2405.14860", "submitter": "Joshua Engels", "authors": "Joshua Engels, Eric J. Michaud, Isaac Liao, Wes Gurnee, Max Tegmark", "title": "Not All Language Model Features Are One-Dimensionally Linear", "comments": "Accepted to ICLR 2025. Code and data at\n  https://github.com/JoshEngels/MultiDimensionalFeatures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has proposed that language models perform computation by\nmanipulating one-dimensional representations of concepts (\"features\") in\nactivation space. In contrast, we explore whether some language model\nrepresentations may be inherently multi-dimensional. We begin by developing a\nrigorous definition of irreducible multi-dimensional features based on whether\nthey can be decomposed into either independent or non-co-occurring\nlower-dimensional features. Motivated by these definitions, we design a\nscalable method that uses sparse autoencoders to automatically find\nmulti-dimensional features in GPT-2 and Mistral 7B. These auto-discovered\nfeatures include strikingly interpretable examples, e.g. circular features\nrepresenting days of the week and months of the year. We identify tasks where\nthese exact circles are used to solve computational problems involving modular\narithmetic in days of the week and months of the year. Next, we provide\nevidence that these circular features are indeed the fundamental unit of\ncomputation in these tasks with intervention experiments on Mistral 7B and\nLlama 3 8B, and we examine the continuity of the days of the week feature in\nMistral 7B. Overall, our work argues that understanding multi-dimensional\nfeatures is necessary to mechanistically decompose some model behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2024 17:59:04 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2024 14:23:17 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 03:03:59 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Engels", "Joshua", ""], ["Michaud", "Eric J.", ""], ["Liao", "Isaac", ""], ["Gurnee", "Wes", ""], ["Tegmark", "Max", ""]], "extracted_entities": [{"text": "GPT-2", "label": "GPT"}, {"text": "Mistral 7B", "label": "Mistral"}, {"text": "Mistral 7B", "label": "Mistral"}, {"text": "Llama 3 8B", "label": "Llama"}, {"text": "Mistral 7B", "label": "Mistral"}], "human_readable_topic": "Machine Unlearning in Large Language Models"}
{"id": "2405.15120", "submitter": "Raghav Singal", "authors": "Martin Haugh and Raghav Singal", "title": "A Counterfactual Analysis of the Dishonest Casino", "comments": "arXiv admin note: text overlap with arXiv:2205.13832", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dishonest casino is a well-known hidden Markov model (HMM) used in\neducational settings to introduce HMMs and graphical models. Here, a sequence\nof die rolls is observed, with the casino switching between a fair and a loaded\ndie. Typically, the goal is to use the observed rolls to infer the pattern of\nfair and loaded dice, leading to filtering, smoothing, and Viterbi algorithms.\nThis paper, however, explores how much of the winnings is attributable to the\ncasino's cheating, a counterfactual question beyond the scope of HMM\nprimitives. To address this, we introduce a structural causal model (SCM)\nconsistent with the HMM and show the expected winnings attributable to cheating\n(EWAC) (which is only partially identifiable) can be bounded using linear\nprograms (LPs). Through numerical experiments, we compute these bounds and\ndevelop intuition using benchmark SCMs based on independence, comonotonic, and\ncounter-monotonic copulas. We show that tighter bounds are obtained with a\ntime-homogeneity condition on the SCM, while looser bounds allow for an almost\nexplicit LP solution. Domain-specific knowledge such as pathwise monotonicity\nor counterfactual stability can be incorporated via linear constraints. We also\nshow the time-average EWAC is fully identifiable in the limit as the number of\ntime periods goes to infinity. Our work contributes to bounding counterfactuals\nin causal inference and is the first to develop LP bounds in a dynamic HMM\nsetting, benefiting educational contexts where counterfactual inference is\ntaught.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 00:26:54 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 17:01:51 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Haugh", "Martin", ""], ["Singal", "Raghav", ""]], "extracted_entities": [{"text": "counterfactual stability", "label": "Model Bias and Fairness"}], "human_readable_topic": "Causal Analysis with Large Language Models"}
{"id": "2405.15349", "submitter": "Deng Jingcheng", "authors": "Jingcheng Deng, Zihao Wei, Liang Pang, Hanxing Ding, Huawei Shen,\n  Xueqi Cheng", "title": "Everything is Editable: Extend Knowledge Editing to Unstructured Data in\n  Large Language Models", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent knowledge editing methods have primarily focused on modifying\nstructured knowledge in large language models. However, this task setting\noverlooks the fact that a significant portion of real-world knowledge is stored\nin an unstructured format, characterized by long-form content, noise, and a\ncomplex yet comprehensive nature. Techniques like \"local layer key-value\nstorage\" and \"term-driven optimization\", as used in previous methods like\nMEMIT, are not effective for handling unstructured knowledge. To address these\nchallenges, we propose a novel Unstructured Knowledge Editing method, namely\nUnKE, which extends previous assumptions in the layer dimension and token\ndimension. Firstly, in the layer dimension, we propose non-local block\nkey-value storage to replace local layer key-value storage, increasing the\nrepresentation ability of key-value pairs and incorporating attention layer\nknowledge. Secondly, in the token dimension, we replace \"term-driven\noptimization\" with \"cause-driven optimization\", which edits the last token\ndirectly while preserving context, avoiding the need to locate terms and\npreventing the loss of context information. Results on newly proposed\nunstructured knowledge editing dataset (UnKEBench) and traditional structured\ndatasets demonstrate that UnKE achieves remarkable performance, surpassing\nstrong baselines. In addition, UnKE has robust batch editing and sequential\nediting capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 08:42:40 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2024 04:32:49 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 03:33:47 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Deng", "Jingcheng", ""], ["Wei", "Zihao", ""], ["Pang", "Liang", ""], ["Ding", "Hanxing", ""], ["Shen", "Huawei", ""], ["Cheng", "Xueqi", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}], "human_readable_topic": "Knowledge Editing in Large Language Models"}
{"id": "2405.15401", "submitter": "Stein Meereboer", "authors": "Stein Meereboer", "title": "Symmetries for spherical functions of type $\\chi$ for quantum symmetric\n  pairs", "comments": "To appear in Transformation Groups", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT math.QA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Let $\\mathfrak{g}$ be a complex semisimple Lie algebra and let\n$\\mathbf{U}_q(\\mathfrak{g})$ denote the associated Drinfel'd Jimbo quantized\nenveloping algebra. In this paper we study spherical functions of\n$\\mathbf{U}_q(\\mathfrak{g})$ related to characters. We show invariance under\nthe Wang-Zhang braid group operators and show relative Weyl group invariance,\nwhen restricted to the quantum torus.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 09:57:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 16:05:26 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Meereboer", "Stein", ""]], "extracted_entities": [{"text": "invariance", "label": "quantisation"}], "human_readable_topic": "Quantization and Manifold Embeddings"}
{"id": "2405.15618", "submitter": "William Tong", "authors": "William L. Tong and Cengiz Pehlevan", "title": "MLPs Learn In-Context on Regression and Classification Tasks", "comments": "Published at ICLR 2025. 30 pages, 10 figures, code available at\n  https://github.com/wtong98/mlp-icl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In-context learning (ICL), the remarkable ability to solve a task from only\ninput exemplars, is often assumed to be a unique hallmark of Transformer\nmodels. By examining commonly employed synthetic ICL tasks, we demonstrate that\nmulti-layer perceptrons (MLPs) can also learn in-context. Moreover, MLPs, and\nthe closely related MLP-Mixer models, learn in-context comparably with\nTransformers under the same compute budget in this setting. We further show\nthat MLPs outperform Transformers on a series of classical tasks from\npsychology designed to test relational reasoning, which are closely related to\nin-context classification. These results underscore a need for studying\nin-context learning beyond attention-based architectures, while also\nchallenging prior arguments against MLPs' ability to solve relational tasks.\nAltogether, our results highlight the unexpected competence of MLPs in a\nsynthetic setting, and support the growing interest in all-MLP alternatives to\nTransformer architectures. It remains unclear how MLPs perform against\nTransformers at scale on real-world tasks, and where a performance gap may\noriginate. We encourage further exploration of these architectures in more\ncomplex settings to better understand the potential comparative advantage of\nattention-based schemes.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 15:04:36 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2024 16:05:30 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 16:27:38 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Tong", "William L.", ""], ["Pehlevan", "Cengiz", ""]], "extracted_entities": [{"text": "In-context learning", "label": "contextual Embedding"}, {"text": "ICL", "label": "contextual Embedding"}, {"text": "ICL", "label": "contextual Embedding"}, {"text": "MLPs", "label": "Neural Language Model"}, {"text": "in-context", "label": "contextual Embedding"}, {"text": "MLPs", "label": "Neural Language Model"}, {"text": "in-context", "label": "contextual Embedding"}, {"text": "Transformers", "label": "Transformers"}, {"text": "MLPs", "label": "Neural Language Model"}, {"text": "Transformers", "label": "Transformers"}, {"text": "in-context", "label": "contextual Embedding"}, {"text": "in-context learning", "label": "contextual Embedding"}, {"text": "MLPs", "label": "Neural Language Model"}, {"text": "MLPs", "label": "Neural Language Model"}, {"text": "MLPs", "label": "Neural Language Model"}], "human_readable_topic": "In-Context Learning with Transformers"}
{"id": "2405.15932", "submitter": "Soumyabrata Kundu", "authors": "Soumyabrata Kundu and Risi Kondor", "title": "Steerable Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we introduce Steerable Transformers, an extension of the Vision\nTransformer mechanism that maintains equivariance to the special Euclidean\ngroup $\\mathrm{SE}(d)$. We propose an equivariant attention mechanism that\noperates on features extracted by steerable convolutions. Operating in Fourier\nspace, our network utilizes Fourier space non-linearities. Our experiments in\nboth two and three dimensions show that adding steerable transformer layers to\nsteerable convolutional networks enhances performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 20:43:19 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 17:10:11 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Kundu", "Soumyabrata", ""], ["Kondor", "Risi", ""]], "extracted_entities": [{"text": "Steerable Transformers", "label": "Transformers"}, {"text": "Vision\nTransformer mechanism", "label": "Attention mechanism"}, {"text": "equivariant attention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Vision Transformers with Convolutional Layers"}
{"id": "2405.16498", "submitter": "Menghao Waiyan William Zhu", "authors": "Menghao Waiyan William Zhu and Ercan Engin Kuruo\\u{g}lu", "title": "On Sequential Maximum a Posteriori Inference for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate sequential maximum a posteriori inference as a recursion of loss\nfunctions and reduce the problem of continual learning to approximating the\nprevious loss function. We then propose two coreset-free methods: autodiff\nquadratic consolidation, which uses an accurate and full quadratic\napproximation, and neural consolidation, which uses a neural network\napproximation. These methods are not scalable with respect to the neural\nnetwork size, and we study them for classification tasks in combination with a\nfixed pre-trained feature extractor. We also introduce simple but challenging\nclassical task sequences based on Iris and Wine datasets. We find that neural\nconsolidation performs well in the classical task sequences, where the input\ndimension is small, while autodiff quadratic consolidation performs\nconsistently well in image task sequences with a fixed pre-trained feature\nextractor, achieving comparable performance to joint training in many cases.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2024 09:20:47 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2024 05:18:42 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 07:14:47 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhu", "Menghao Waiyan William", ""], ["Kuruo\u011flu", "Ercan Engin", ""]], "extracted_entities": [{"text": "autodiff\nquadratic consolidation", "label": "Embedding"}, {"text": "neural consolidation", "label": "Embedding"}, {"text": "neural\nconsolidation", "label": "Embedding"}, {"text": "autodiff quadratic consolidation", "label": "Embedding"}], "human_readable_topic": "Continual Learning for Image Segmentation"}
{"id": "2405.16865", "submitter": "Dehong Xu", "authors": "Dehong Xu, Ruiqi Gao, Wen-Hao Zhang, Xue-Xin Wei, Ying Nian Wu", "title": "On Conformal Isometry of Grid Cells: Learning Distance-Preserving\n  Position Embedding", "comments": "arXiv admin note: text overlap with arXiv:2310.19192", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the conformal isometry hypothesis as a potential\nexplanation for the hexagonal periodic patterns in grid cell response maps. We\nposit that grid cell activities form a high-dimensional vector in neural space,\nencoding the agent's position in 2D physical space. As the agent moves, this\nvector rotates within a 2D manifold in the neural space, driven by a recurrent\nneural network. The conformal hypothesis proposes that this neural manifold is\na conformal isometric embedding of 2D physical space, where local physical\ndistance is preserved by the embedding up to a scaling factor (or unit of\nmetric). Such distance-preserving position embedding is indispensable for path\nplanning in navigation, especially planning local straight path segments. We\nconduct numerical experiments to show that this hypothesis leads to the\nhexagonal grid firing patterns by learning maximally distance-preserving\nposition embedding, agnostic to the choice of the recurrent neural network.\nFurthermore, we present a theoretical explanation of why hexagon periodic\npatterns emerge by minimizing our loss function by showing that hexagon flat\ntorus is maximally distance preserving.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2024 06:31:39 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2024 06:27:11 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2025 19:39:12 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 07:31:38 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Xu", "Dehong", ""], ["Gao", "Ruiqi", ""], ["Zhang", "Wen-Hao", ""], ["Wei", "Xue-Xin", ""], ["Wu", "Ying Nian", ""]], "extracted_entities": [{"text": "embedding", "label": "Embedding"}, {"text": "embedding", "label": "Embedding"}, {"text": "scaling factor", "label": "Scaling law"}, {"text": "maximally distance-preserving\nposition embedding", "label": "Embedding"}], "human_readable_topic": "Neural Networks and Brain Computation Dynamics"}
{"id": "2405.17082", "submitter": "Cong Wang", "authors": "Cong Wang, Kuan Tian, Yonghang Guan, Fei Shen, Zhiwei Jiang, Qing Gu,\n  Jun Zhang", "title": "Ensembling Diffusion Models via Adaptive Feature Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of the text-guided diffusion model has inspired the development\nand release of numerous powerful diffusion models within the open-source\ncommunity. These models are typically fine-tuned on various expert datasets,\nshowcasing diverse denoising capabilities. Leveraging multiple high-quality\nmodels to produce stronger generation ability is valuable, but has not been\nextensively studied. Existing methods primarily adopt parameter merging\nstrategies to produce a new static model. However, they overlook the fact that\nthe divergent denoising capabilities of the models may dynamically change\nacross different states, such as when experiencing different prompts, initial\nnoises, denoising steps, and spatial locations. In this paper, we propose a\nnovel ensembling method, Adaptive Feature Aggregation (AFA), which dynamically\nadjusts the contributions of multiple models at the feature level according to\nvarious states (i.e., prompts, initial noises, denoising steps, and spatial\nlocations), thereby keeping the advantages of multiple diffusion models, while\nsuppressing their disadvantages. Specifically, we design a lightweight\nSpatial-Aware Block-Wise (SABW) feature aggregator that adaptive aggregates the\nblock-wise intermediate features from multiple U-Net denoisers into a unified\none. The core idea lies in dynamically producing an individual attention map\nfor each model's features by comprehensively considering various states. It is\nworth noting that only SABW is trainable with about 50 million parameters,\nwhile other models are frozen. Both the quantitative and qualitative\nexperiments demonstrate the effectiveness of our proposed Adaptive Feature\nAggregation method.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2024 11:55:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 07:35:14 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wang", "Cong", ""], ["Tian", "Kuan", ""], ["Guan", "Yonghang", ""], ["Shen", "Fei", ""], ["Jiang", "Zhiwei", ""], ["Gu", "Qing", ""], ["Zhang", "Jun", ""]], "extracted_entities": [{"text": "open-source\ncommunity", "label": "Open-source LLMs"}, {"text": "prompts", "label": "Prompting"}, {"text": "denoising steps", "label": "Attention mechanism"}, {"text": "prompts", "label": "Prompting"}, {"text": "denoising steps", "label": "Attention mechanism"}], "human_readable_topic": "Knowledge Distillation for CNNs"}
{"id": "2405.17177", "submitter": "Torsten Weber", "authors": "Torsten Weber, Jarod Tall, Fabian Haneder, Juan Diego Urbina and Klaus\n  Richter", "title": "Unorientable topological gravity and orthogonal random matrix\n  universality", "comments": "version fixing typos (that don't affect the results) in eq. 2.68, eq.\n  2.69 and subsequent mentions", "journal-ref": "J. High Energ. Phys. 2024, 267 (2024)", "doi": "10.1007/JHEP07(2024)267", "report-no": null, "categories": "hep-th nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The duality of Jackiw-Teitelboim (JT) gravity and a double scaled matrix\nintegral has led to studies of the canonical spectral form factor (SFF) in the\nso called $\\tau-$scaled limit of large times, $t \\to \\infty$, and fixed\ntemperature in order to demonstrate agreement with universal random matrix\ntheory (RMT). Though this has been established for the unitary case, extensions\nto other symmetry classes requires the inclusion of unorientable manifolds in\nthe sum over geometries, necessary to address time reversal invariance, and\nregularization of the corresponding prime geometrical objects, the\nWeil-Petersson (WP) volumes. We report here how universal signatures of quantum\nchaos, witnessed by the fidelity to the Gaussian orthogonal ensemble, emerge\nfor the low-energy limit of unorientable JT gravity, i.e. the Airy\nmodel/topological gravity. To this end, we implement the loop equations for the\ncorresponding dual (double-scaled) matrix model and find the generic form of\nthe Airy WP volumes, supported by calculations using unorientable Kontsevich\ngraphs. In an apparent violation of the gravity/chaos duality, the\n$\\tau-$scaled SFF on the gravity side acquires both logarithmic and power law\ncontributions in $t$, not manifestly present on the RMT side. We show the\nexpressions can be made to agree by means of bootstrapping-like relations\nhidden in the asymptotic expansions of generalized hypergeometric functions.\nThus, we are able to establish strong evidence of the quantum chaotic nature of\nunorientable topological gravity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2024 13:57:01 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2024 11:56:11 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2024 18:57:51 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 11:44:16 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Weber", "Torsten", ""], ["Tall", "Jarod", ""], ["Haneder", "Fabian", ""], ["Urbina", "Juan Diego", ""], ["Richter", "Klaus", ""]], "extracted_entities": [{"text": "power law", "label": "Scaling law"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2405.17428", "submitter": "Wei Ping", "authors": "Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad\n  Shoeybi, Bryan Catanzaro, Wei Ping", "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding\n  Models", "comments": "ICLR 2025 (Spotlight). We open-source the model at:\n  https://huggingface.co/nvidia/NV-Embed-v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decoder-only LLM-based embedding models are beginning to outperform BERT or\nT5-based embedding models in general-purpose text embedding tasks, including\ndense vector-based retrieval. In this work, we introduce NV-Embed,\nincorporating architectural designs, training procedures, and curated datasets\nto significantly enhance the performance of LLM as a versatile embedding model,\nwhile maintaining its simplicity and reproducibility. For model architecture,\nwe propose a latent attention layer to obtain pooled embeddings, which\nconsistently improves retrieval and downstream task accuracy compared to mean\npooling or using the last <EOS> token embedding from LLMs. To enhance\nrepresentation learning, we remove the causal attention mask of LLMs during\ncontrastive training. For training algorithm, we introduce a two-stage\ncontrastive instruction-tuning method. It first applies contrastive training\nwith instructions on retrieval datasets, utilizing in-batch negatives and\ncurated hard negative examples. At stage-2, it blends various non-retrieval\ninto instruction tuning, which not only enhances non-retrieval task accuracy\nbut also improves retrieval performance. For training data, we utilize the\nhard-negative mining, synthetic data generation and existing public available\ndatasets to boost the performance of embedding model. By combining these\ntechniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position\non the MTEB leaderboard (as of May 24 and August 30, 2024, respectively) across\n56 tasks, demonstrating the sustained effectiveness of the proposed methods\nover time. It also achieved the highest scores in the Long Doc section and the\nsecond-highest scores in the QA section of the AIR Benchmark, which covers a\nrange of out-of-domain information retrieval topics beyond those in MTEB. We\nfurther provide the analysis of model compression techniques for generalist\nembedding models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2024 17:59:45 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2025 22:27:06 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 00:35:18 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Lee", "Chankyu", ""], ["Roy", "Rajarshi", ""], ["Xu", "Mengyao", ""], ["Raiman", "Jonathan", ""], ["Shoeybi", "Mohammad", ""], ["Catanzaro", "Bryan", ""], ["Ping", "Wei", ""]], "extracted_entities": [{"text": "BERT", "label": "BERT"}, {"text": "pooled embeddings", "label": "Embedding"}, {"text": "last <EOS> token embedding", "label": "Embedding"}, {"text": "representation learning", "label": "Few-shot Learning"}, {"text": "causal attention mask", "label": "Attention mechanism"}, {"text": "instruction tuning", "label": "Fine-tuning"}], "human_readable_topic": "Sentence Embeddings and Semantic Meaning Analysis"}
{"id": "2405.17814", "submitter": "Hanjun Luo", "authors": "Hanjun Luo, Ziye Deng, Ruizhe Chen, and Zuozhu Liu", "title": "FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in\n  Text-to-Image Models", "comments": "Accepted by ICML DMLR 2024", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development and reduced barriers to entry for Text-to-Image (T2I)\nmodels have raised concerns about the biases in their outputs, but existing\nresearch lacks a holistic definition and evaluation framework of biases,\nlimiting the enhancement of debiasing techniques. To address this issue, we\nintroduce FAIntbench, a holistic and precise benchmark for biases in T2I\nmodels. In contrast to existing benchmarks that evaluate bias in limited\naspects, FAIntbench evaluate biases from four dimensions: manifestation of\nbias, visibility of bias, acquired attributes, and protected attributes. We\napplied FAIntbench to evaluate seven recent large-scale T2I models and\nconducted human evaluation, whose results demonstrated the effectiveness of\nFAIntbench in identifying various biases. Our study also revealed new research\nquestions about biases, including the side-effect of distillation. The findings\npresented here are preliminary, highlighting the potential of FAIntbench to\nadvance future research aimed at mitigating the biases in T2I models. Our\nbenchmark is publicly available to ensure the reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2024 04:18:00 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2024 04:23:06 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2024 13:41:36 GMT"}, {"version": "v4", "created": "Mon, 22 Jul 2024 16:38:07 GMT"}, {"version": "v5", "created": "Wed, 18 Sep 2024 04:40:40 GMT"}, {"version": "v6", "created": "Mon, 24 Feb 2025 08:49:32 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Luo", "Hanjun", ""], ["Deng", "Ziye", ""], ["Chen", "Ruizhe", ""], ["Liu", "Zuozhu", ""]], "extracted_entities": [{"text": "manifestation of\nbias", "label": "Model Bias and Fairness"}, {"text": "visibility of bias", "label": "Model Bias and Fairness"}, {"text": "acquired attributes", "label": "Model Bias and Fairness"}, {"text": "protected attributes", "label": "Model Bias and Fairness"}, {"text": "side-effect of distillation", "label": "Knowledge distillation"}, {"text": "publicly available", "label": "Open-source LLMs"}], "human_readable_topic": "Cognitive Biases in Large Language Models"}
{"id": "2405.17842", "submitter": "Akio Hayakawa", "authors": "Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji", "title": "MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for\n  Joint Audio and Video Generation", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study aims to construct an audio-video generative model with minimal\ncomputational cost by leveraging pre-trained single-modal generative models for\naudio and video. To achieve this, we propose a novel method that guides\nsingle-modal models to cooperatively generate well-aligned samples across\nmodalities. Specifically, given two pre-trained base diffusion models, we train\na lightweight joint guidance module to adjust scores separately estimated by\nthe base models to match the score of joint distribution over audio and video.\nWe show that this guidance can be computed using the gradient of the optimal\ndiscriminator, which distinguishes real audio-video pairs from fake ones\nindependently generated by the base models. Based on this analysis, we\nconstruct a joint guidance module by training this discriminator. Additionally,\nwe adopt a loss function to stabilize the discriminator's gradient and make it\nwork as a noise estimator, as in standard diffusion models. Empirical\nevaluations on several benchmark datasets demonstrate that our method improves\nboth single-modal fidelity and multimodal alignment with relatively few\nparameters. The code is available at: https://github.com/SonyResearch/MMDisCo.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2024 05:43:03 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 09:34:26 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Hayakawa", "Akio", ""], ["Ishii", "Masato", ""], ["Shibuya", "Takashi", ""], ["Mitsufuji", "Yuki", ""]], "extracted_entities": [{"text": "base models", "label": "Foundation Model"}, {"text": "base models", "label": "Foundation Model"}], "human_readable_topic": "Video Understanding with Large Multimodal Models"}
{"id": "2405.18548", "submitter": "Marco S\\\"alzer", "authors": "Marco S\\\"alzer, Eric Alsmann, Martin Lange", "title": "Transformer Encoder Satisfiability: Complexity and Impact on Formal\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse the complexity of the satisfiability problem, or similarly\nfeasibility problem, (trSAT) for transformer encoders (TE), which naturally\noccurs in formal verification or interpretation, collectively referred to as\nformal reasoning. We find that trSAT is undecidable when considering TE as they\nare commonly studied in the expressiveness community. Furthermore, we identify\npractical scenarios where trSAT is decidable and establish corresponding\ncomplexity bounds. Beyond trivial cases, we find that quantized TE, those\nrestricted by fixed-width arithmetic, lead to the decidability of trSAT due to\ntheir limited attention capabilities. However, the problem remains difficult,\nas we establish scenarios where trSAT is NEXPTIME-hard and others where it is\nsolvable in NEXPTIME for quantized TE. To complement our complexity results, we\nplace our findings and their implications in the broader context of formal\nreasoning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2024 19:30:43 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2024 16:20:02 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 06:37:14 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["S\u00e4lzer", "Marco", ""], ["Alsmann", "Eric", ""], ["Lange", "Martin", ""]], "extracted_entities": [{"text": "quantized TE", "label": "quantisation"}, {"text": "limited attention capabilities", "label": "Attention mechanism"}, {"text": "TE", "label": "BERT"}], "human_readable_topic": "Reasoning Capabilities of Large Language Models"}
{"id": "2405.19492", "submitter": "Jakob Wasserthal", "authors": "Tugba Akinci D'Antonoli, Lucas K. Berger, Ashraya K. Indrakanti,\n  Nathan Vishwanathan, Jakob Wei{\\ss}, Matthias Jung, Zeynep Berkarda,\n  Alexander Rau, Marco Reisert, Thomas K\\\"ustner, Alexandra Walter, Elmar M.\n  Merkle, Daniel Boll, Hanns-Christian Breit, Andrew Phillip Nicoli, Martin\n  Segeroth, Joshy Cyriac, Shan Yang, Jakob Wasserthal", "title": "TotalSegmentator MRI: Robust Sequence-independent Segmentation of\n  Multiple Anatomic Structures in MRI", "comments": "Published in Radiology", "journal-ref": "Radiology 314.2 (2025): e241613", "doi": "10.1148/radiol.241613", "report-no": null, "categories": "eess.IV cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction of TotalSegmentator CT, there is demand for a similar\nrobust automated MRI segmentation tool that can be applied across all MRI\nsequences and anatomic structures. In this retrospective study, a nnU-Net model\n(TotalSegmentator) was trained on MRI and CT examinations to segment 80\nanatomic structures relevant for use cases such as organ volumetry, disease\ncharacterization, surgical planning and opportunistic screening. Examinations\nwere randomly sampled from routine clinical studies to represent real-world\nexamples. Dice scores were calculated between the predicted segmentations and\nexpert radiologist reference standard segmentations to evaluate model\nperformance on an internal test set, two external test sets and against two\npublicly available models, and TotalSegmentator CT. The model was applied to an\ninternal dataset containing abdominal MRIs to investigate age-dependent volume\nchanges. A total of 1143 examinations (616 MRIs, 527 CTs) (median age 61 years,\nIQR 50-72) were split into training (n=1088, CT and MRI) and an internal test\nset (n=55; only MRI), two external test sets (AMOS, n=20; CHAOS, n=20; only\nMRI), and an internal aging-study dataset of 8672 abdominal MRIs (median age 59\nyears, IQR 45-70) were included. The model showed a Dice Score of 0.839 on the\ninternal test set and outperformed two other models (Dice Score, 0.862 versus\n0.759; and 0.838 versus 0.560; p<.001 for both). The proposed open-source,\neasy-to-use model allows for automatic, robust segmentation of 80 structures,\nextending the capabilities of TotalSegmentator to MRIs of any sequence. The\nready-to-use online tool is available at https://totalsegmentator.com, the\nmodel at https://github.com/wasserth/TotalSegmentator, and the dataset at\nhttps://zenodo.org/records/14710732.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2024 20:15:54 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 12:27:21 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["D'Antonoli", "Tugba Akinci", ""], ["Berger", "Lucas K.", ""], ["Indrakanti", "Ashraya K.", ""], ["Vishwanathan", "Nathan", ""], ["Wei\u00df", "Jakob", ""], ["Jung", "Matthias", ""], ["Berkarda", "Zeynep", ""], ["Rau", "Alexander", ""], ["Reisert", "Marco", ""], ["K\u00fcstner", "Thomas", ""], ["Walter", "Alexandra", ""], ["Merkle", "Elmar M.", ""], ["Boll", "Daniel", ""], ["Breit", "Hanns-Christian", ""], ["Nicoli", "Andrew Phillip", ""], ["Segeroth", "Martin", ""], ["Cyriac", "Joshy", ""], ["Yang", "Shan", ""], ["Wasserthal", "Jakob", ""]], "extracted_entities": [{"text": "nnU-Net model", "label": "AI model"}], "human_readable_topic": "Medical Image Segmentation with Transformers and CNNs"}
{"id": "2405.19799", "submitter": "Jiahui Xu", "authors": "Jiahui Xu, Feng Jiang, Anningzhe Gao, Luis Fernando D'Haro, Haizhou Li", "title": "Unsupervised Mutual Learning of Discourse Parsing and Topic Segmentation\n  in Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialogue systems, discourse plays a crucial role in managing\nconversational focus and coordinating interactions. It consists of two key\nstructures: rhetorical structure and topic structure. The former captures the\nlogical flow of conversations, while the latter detects transitions between\ntopics. Together, they improve the ability of a dialogue system to track\nconversation dynamics and generate contextually relevant high-quality\nresponses. These structures are typically identified through discourse parsing\nand topic segmentation, respectively. However, existing supervised methods rely\non costly manual annotations, while unsupervised methods often focus on a\nsingle task, overlooking the deep linguistic interplay between rhetorical and\ntopic structures. To address these issues, we first introduce a unified\nrepresentation that integrates rhetorical and topic structures, ensuring\nsemantic consistency between them. Under the unified representation, we further\npropose two linguistically grounded hypotheses based on discourse theories: (1)\nLocal Discourse Coupling, where rhetorical cues dynamically enhance topic-aware\ninformation flow, and (2) Global Topology Constraint, where topic structure\npatterns probabilistically constrain rhetorical relation distributions.\nBuilding on the unified representation and two hypotheses, we propose an\nunsupervised mutual learning framework (UMLF) that jointly models rhetorical\nand topic structures, allowing them to mutually reinforce each other without\nrequiring additional annotations. We evaluate our approach on two rhetorical\ndatasets and three topic segmentation datasets. Experimental results\ndemonstrate that our method surpasses all strong baselines built on pre-trained\nlanguage models. Furthermore, when applied to LLMs, our framework achieves\nnotable improvements, demonstrating its effectiveness in improving discourse\nstructure modeling.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2024 08:10:50 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2024 08:13:10 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2025 09:22:19 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 09:50:00 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Xu", "Jiahui", ""], ["Jiang", "Feng", ""], ["Gao", "Anningzhe", ""], ["D'Haro", "Luis Fernando", ""], ["Li", "Haizhou", ""]], "extracted_entities": [{"text": "unified representation", "label": "contextual Embedding"}, {"text": "LLMs", "label": "LLM"}], "human_readable_topic": "Conversational Intent Understanding and Dialogue Systems"}
{"id": "2405.20318", "submitter": "Zhijing Jin", "authors": "Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Am\\'elie Reymond,\n  Rada Mihalcea, Bernhard Sch\\\"olkopf, Mrinmaya Sachan, Zhijing Jin", "title": "Quriosity: Analyzing Human Questioning Behavior and Causal Inquiry\n  through Curiosity-Driven Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent progress in Large Language Model (LLM) technology has changed our role\nin interacting with these models. Instead of primarily testing these models\nwith questions we already know answers to, we are now using them for queries\nwhere the answers are unknown to us, driven by human curiosity. This shift\nhighlights the growing need to understand curiosity-driven human questions -\nthose that are more complex, open-ended, and reflective of real-world needs. To\nthis end, we present Quriosity, a collection of 13.5K naturally occurring\nquestions from three diverse sources: human-to-search-engine queries,\nhuman-to-human interactions, and human-to-LLM conversations. Our comprehensive\ncollection enables a rich understanding of human curiosity across various\ndomains and contexts. Our analysis reveals a significant presence of causal\nquestions (up to 42%) in the dataset, for which we develop an iterative prompt\nimprovement framework to identify all causal queries and examine their unique\nlinguistic properties, cognitive complexity and source distribution. Our paper\npaves the way for future work on causal question identification and open-ended\nchatbot interactions.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2024 17:55:28 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2024 09:21:38 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 16:42:25 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Ceraolo", "Roberto", ""], ["Kharlapenko", "Dmitrii", ""], ["Khan", "Ahmad", ""], ["Reymond", "Am\u00e9lie", ""], ["Mihalcea", "Rada", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Sachan", "Mrinmaya", ""], ["Jin", "Zhijing", ""]], "extracted_entities": [{"text": "Large Language Model", "label": "Large Language Model"}, {"text": "iterative prompt\nimprovement framework", "label": "Prompting"}, {"text": "open-ended\nchatbot interactions", "label": "ChatGPT"}], "human_readable_topic": "Conversational Search and Retrieval Systems"}
{"id": "2405.20513", "submitter": "Rebecca Russell", "authors": "Aastha Acharya, Caleb Lee, Marissa D'Alonzo, Jared Shamwell, Nisar R.\n  Ahmed, Rebecca Russell", "title": "Deep Modeling of Non-Gaussian Aleatoric Uncertainty", "comments": "8 pages, 7 figures", "journal-ref": "IEEE Robotics and Automation Letters, vol. 10, no. 1, pp. 660-667,\n  Jan. 2025", "doi": "10.1109/LRA.2024.3511376", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning offers promising new ways to accurately model aleatoric\nuncertainty in robotic state estimation systems, particularly when the\nuncertainty distributions do not conform to traditional assumptions of being\nfixed and Gaussian. In this study, we formulate and evaluate three fundamental\ndeep learning approaches for conditional probability density modeling to\nquantify non-Gaussian aleatoric uncertainty: parametric, discretized, and\ngenerative modeling. We systematically compare the respective strengths and\nweaknesses of these three methods on simulated non-Gaussian densities as well\nas on real-world terrain-relative navigation data. Our results show that these\ndeep learning methods can accurately capture complex uncertainty patterns,\nhighlighting their potential for improving the reliability and robustness of\nestimation systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2024 22:13:17 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 16:35:59 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Acharya", "Aastha", ""], ["Lee", "Caleb", ""], ["D'Alonzo", "Marissa", ""], ["Shamwell", "Jared", ""], ["Ahmed", "Nisar R.", ""], ["Russell", "Rebecca", ""]], "extracted_entities": [{"text": "generative modeling", "label": "Few-shot Learning"}], "human_readable_topic": "Adversarial Robustness in Deep Learning Models"}
{"id": "2405.20681", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang, Yahao Pang, Yan Kang, Wei Chen, Lixin Fan, Hai Jin,\n  Qiang Yang", "title": "No Free Lunch Theorem for Privacy-Preserving LLM Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals and businesses have been significantly benefited by Large\nLanguage Models (LLMs) including PaLM, Gemini and ChatGPT in various ways. For\nexample, LLMs enhance productivity, reduce costs, and enable us to focus on\nmore valuable tasks. Furthermore, LLMs possess the capacity to sift through\nextensive datasets, uncover underlying patterns, and furnish critical insights\nthat propel the frontiers of technology and science. However, LLMs also pose\nprivacy concerns. Users' interactions with LLMs may expose their sensitive\npersonal or company information. A lack of robust privacy safeguards and legal\nframeworks could permit the unwarranted intrusion or improper handling of\nindividual data, thereby risking infringements of privacy and the theft of\npersonal identities. To ensure privacy, it is essential to minimize the\ndependency between shared prompts and private information. Various\nrandomization approaches have been proposed to protect prompts' privacy, but\nthey may incur utility loss compared to unprotected LLMs prompting. Therefore,\nit is essential to evaluate the balance between the risk of privacy leakage and\nloss of utility when conducting effective protection mechanisms. The current\nstudy develops a framework for inferring privacy-protected Large Language\nModels (LLMs) and lays down a solid theoretical basis for examining the\ninterplay between privacy preservation and utility. The core insight is\nencapsulated within a theorem that is called as the NFL (abbreviation of the\nword No-Free-Lunch) Theorem.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2024 08:22:53 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 01:55:21 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhang", "Xiaojin", ""], ["Pang", "Yahao", ""], ["Kang", "Yan", ""], ["Chen", "Wei", ""], ["Fan", "Lixin", ""], ["Jin", "Hai", ""], ["Yang", "Qiang", ""]], "extracted_entities": [{"text": "Large\nLanguage Models", "label": "Large Language Model"}, {"text": "Gemini", "label": "ChatGPT"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompts", "label": "Prompting"}, {"text": "prompts", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "Large Language\nModels", "label": "Large Language Model"}], "human_readable_topic": "Large Language Model Privacy Protection"}
{"id": "2405.20777", "submitter": "Thibaud Gloaguen", "authors": "Thibaud Gloaguen, Nikola Jovanovi\\'c, Robin Staab, Martin Vechev", "title": "Black-Box Detection of Language Model Watermarks", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Watermarking has emerged as a promising way to detect LLM-generated text, by\naugmenting LLM generations with later detectable signals. Recent work has\nproposed multiple families of watermarking schemes, several of which focus on\npreserving the LLM distribution. This distribution-preservation property is\nmotivated by the fact that it is a tractable proxy for retaining LLM\ncapabilities, as well as the inherently implied undetectability of the\nwatermark by downstream users. Yet, despite much discourse around\nundetectability, no prior work has investigated the practical detectability of\nany of the current watermarking schemes in a realistic black-box setting. In\nthis work we tackle this for the first time, developing rigorous statistical\ntests to detect the presence, and estimate parameters, of all three popular\nwatermarking scheme families, using only a limited number of black-box queries.\nWe experimentally confirm the effectiveness of our methods on a range of\nschemes and a diverse set of open-source models. Further, we validate the\nfeasibility of our tests on real-world APIs. Our findings indicate that current\nwatermarking schemes are more detectable than previously believed.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2024 08:41:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2024 15:47:35 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 14:06:41 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Gloaguen", "Thibaud", ""], ["Jovanovi\u0107", "Nikola", ""], ["Staab", "Robin", ""], ["Vechev", "Martin", ""]], "extracted_entities": [{"text": "LLM", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Watermarking Techniques for Large Language Models"}
{"id": "2406.00023", "submitter": "Jing Li", "authors": "Jing Li, Zhijie Sun, Dachao Lin, Xuan He, Binfan Zheng, Yi Lin,\n  Rongqian Zhao, Xin Chen", "title": "Expert-Token Resonance MoE: Bidirectional Routing with Efficiency\n  Affinity-Driven Active Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Mixture-of-Experts (MoE) architectures have emerged as a paradigm-shifting\napproach for large language models (LLMs), offering unprecedented computational\nefficiency. However, these architectures grapple with challenges of token\ndistribution imbalance and expert homogenization, impeding optimal semantic\ngeneralization. We propose a novel expert routing framework that incorporates:\n(1) An efficient routing mechanism with lightweight computation. (2) An\nadaptive bidirectional selection mechanism leveraging resonance between experts\nand tokens. (3) A module that determines the lower bounds of expert capacity\nbased on dynamic token distribution analysis, specifically designed to address\ndrop-and-pad strategies. It is also integrated with orthogonal feature\nextraction module and an optimized loss function for expert localization. This\nframework effectively reduces expert homogeneity while enhancing the\nperformance of the expert selection module. Additionally, we introduce a local\nexpert strategy that simultaneously improves load balancing and reduces network\ncommunication overhead. It achieves a 40\\% reduction in token processed by each\nexpert without compromising model convergence or efficacy. When coupled with\ncommunication optimizations, the training efficiency improvements of 5.4\\% to\n46.6\\% can be observed. After supervised fine-tuning, it exhibits performance\ngains of 9.7\\% to 14.1\\% across GDAD, GPQA, and TeleQnA benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2024 02:50:44 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2024 11:32:48 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 03:28:51 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Li", "Jing", ""], ["Sun", "Zhijie", ""], ["Lin", "Dachao", ""], ["He", "Xuan", ""], ["Zheng", "Binfan", ""], ["Lin", "Yi", ""], ["Zhao", "Rongqian", ""], ["Chen", "Xin", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "supervised fine-tuning", "label": "Fine-tuning"}], "human_readable_topic": "Mixture of Experts (MoE) for Large Language Models"}
{"id": "2406.00034", "submitter": "Yinghao Zhu", "authors": "Tianlong Wang, Xianfeng Jiao, Yinghao Zhu, Zhongzhi Chen, Yifan He, Xu\n  Chu, Junyi Gao, Yasha Wang, Liantao Ma", "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement\n  Method for Diverse Hallucinations Categories", "comments": "ACM TheWebConf 2025 Conference (WWW 2025) Research Track", "journal-ref": null, "doi": "10.1145/3696410.3714640", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have indicated that Large Language Models (LLMs) harbor an\ninherent understanding of truthfulness, yet often fail to consistently express\nit and generate false statements. This gap between \"knowing\" and \"telling\"\nposes a challenge for ensuring the truthfulness of generated content. Inspired\nby recent work on the practice of encoding human-interpretable concepts\nlinearly within large language models, we treat truthfulness as a specially\nlinearly encoded concept within LLMs, and introduce Adaptive Activation\nSteering (ACT), a tuning-free method that adaptively shifts LLM's activations\nin the \"truthful\" direction during inference. ACT addresses diverse categories\nof hallucinations by utilizing diverse truthfulness-related steering vectors\nand adjusting the steering intensity adaptively. Applied as an add-on across\nvarious models, ACT significantly improves truthfulness in LLaMA ($\\uparrow$\n142%), LLaMA2 ($\\uparrow$ 24%), Alpaca ($\\uparrow$ 36%), Vicuna ($\\uparrow$\n28%), LLaMA2-Chat ($\\uparrow$ 19%), and LLaMA3($\\uparrow$ 34%). Furthermore, we\nverify ACT's scalability across larger models (13B, 33B, 65B), underscoring the\nadaptability of ACT to large-scale language models. Our code is available at\nhttps://github.com/tianlwang/ACT.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2024 21:39:53 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 14:07:05 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Wang", "Tianlong", ""], ["Jiao", "Xianfeng", ""], ["Zhu", "Yinghao", ""], ["Chen", "Zhongzhi", ""], ["He", "Yifan", ""], ["Chu", "Xu", ""], ["Gao", "Junyi", ""], ["Wang", "Yasha", ""], ["Ma", "Liantao", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "Alpaca", "label": "Llama"}], "human_readable_topic": "Large Language Model Hallucinations"}
{"id": "2406.00036", "submitter": "Yinghao Zhu", "authors": "Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie,\n  Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan", "title": "EMERGE: Enhancing Multimodal Electronic Health Records Predictive\n  Modeling with Retrieval-Augmented Generation", "comments": "CIKM 2024 Full Research Paper; arXiv admin note: text overlap with\n  arXiv:2402.07016", "journal-ref": null, "doi": "10.1145/3627673.3679582", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of multimodal Electronic Health Records (EHR) data has\nsignificantly advanced clinical predictive capabilities. Existing models, which\nutilize clinical notes and multivariate time-series EHR data, often fall short\nof incorporating the necessary medical context for accurate clinical tasks,\nwhile previous approaches with knowledge graphs (KGs) primarily focus on\nstructured knowledge extraction. In response, we propose EMERGE, a\nRetrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR\npredictive modeling. We extract entities from both time-series data and\nclinical notes by prompting Large Language Models (LLMs) and align them with\nprofessional PrimeKG, ensuring consistency. In addition to triplet\nrelationships, we incorporate entities' definitions and descriptions for richer\nsemantics. The extracted knowledge is then used to generate task-relevant\nsummaries of patients' health statuses. Finally, we fuse the summary with other\nmodalities using an adaptive multimodal fusion network with cross-attention.\nExtensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital\nmortality and 30-day readmission tasks demonstrate the superior performance of\nthe EMERGE framework over baseline models. Comprehensive ablation studies and\nanalysis highlight the efficacy of each designed module and robustness to data\nsparsity. EMERGE contributes to refining the utilization of multimodal EHR data\nin healthcare, bridging the gap with nuanced medical contexts essential for\ninformed clinical predictions. We have publicly released the code at\nhttps://github.com/yhzhu99/EMERGE.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2024 10:53:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 13:18:09 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhu", "Yinghao", ""], ["Ren", "Changyu", ""], ["Wang", "Zixiang", ""], ["Zheng", "Xiaochen", ""], ["Xie", "Shiyun", ""], ["Feng", "Junlan", ""], ["Zhu", "Xi", ""], ["Li", "Zhoujun", ""], ["Ma", "Liantao", ""], ["Pan", "Chengwei", ""]], "extracted_entities": [{"text": "EMERGE", "label": "RAG"}, {"text": "prompting", "label": "Prompting"}, {"text": "Large Language Models", "label": "Large Language Model"}, {"text": "cross-attention", "label": "Attention mechanism"}, {"text": "EMERGE", "label": "RAG"}, {"text": "EMERGE", "label": "RAG"}], "human_readable_topic": "Multimodal Learning for Medical Prediction"}
{"id": "2406.00660", "submitter": "Yingcun Xia", "authors": "Haoran Zhan, Jingli Wang, Yingcun Xia", "title": "Non-asymptotic Properties of Generalized Mondrian Forests in Statistical\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests have been extensively used in regression and classification,\ninspiring the development of various forest-based methods. Among these,\nMondrian Forests, derived from the Mondrian process, mark a significant\nadvancement. Expanding on Mondrian Forests, this paper presents a general\nframework for statistical learning, encompassing a range of common learning\ntasks such as least squares regression, $\\ell_1$ regression, quantile\nregression, and classification. Under mild assumptions on the loss functions,\nwe provide upper bounds on the regret/risk functions for the estimators and\ndemonstrate their statistical consistency.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2024 08:09:22 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2024 06:06:44 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 13:49:00 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhan", "Haoran", ""], ["Wang", "Jingli", ""], ["Xia", "Yingcun", ""]], "extracted_entities": [{"text": "statistical learning", "label": "Few-shot Learning"}, {"text": "least squares regression", "label": "Zero-shot Learning"}, {"text": "quantile\nregression", "label": "Zero-shot Learning"}], "human_readable_topic": "Influence Functions for Machine Learning Models"}
{"id": "2406.01668", "submitter": "Han Wu", "authors": "Han Wu, Edward Hardy, Ningqiang Song", "title": "Searching for heavy millicharged particles from the atmosphere", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph astro-ph.CO hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  If millicharged particles (MCPs) exist they can be created in the atmosphere\nwhen high energy cosmic rays collide with nuclei and could subsequently be\ndetected at neutrino experiments. We extend previous work, which considered\nMCPs from decays of light mesons and proton bremsstrahlung, by including\nproduction from $\\Upsilon$ meson decays and the Drell-Yan process. MCPs with\nmasses below a GeV primarily arise from proton bremsstrahlung, while heavier\nMCPs predominantly originate from heavy meson decays and Drell-Yan. We analyse\nthe resulting single scatter and multiple scatter signals at SuperK and JUNO.\nSearches for low energy coincident signals at JUNO will be sensitive to MCPs\nwith milli-charges up to an order of magnitude beyond current constraints for\nMCP masses between 2 GeV and 10 GeV.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2024 18:00:00 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2024 16:19:02 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 19:55:35 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Wu", "Han", ""], ["Hardy", "Edward", ""], ["Song", "Ningqiang", ""]], "extracted_entities": [{"text": "millicharged particles", "label": "LLMs"}, {"text": "MCPs", "label": "LLMs"}, {"text": "MCPs", "label": "LLMs"}, {"text": "MCPs", "label": "LLMs"}, {"text": "MCPs", "label": "LLMs"}, {"text": "MCPs", "label": "LLMs"}], "human_readable_topic": "Particle Detection and Classification in High Energy Physics"}
{"id": "2406.02336", "submitter": "Madison Cooley", "authors": "Madison Cooley, Shandian Zhe, Robert M. Kirby, Varun Shankar", "title": "Polynomial-Augmented Neural Networks (PANNs) with Weak Orthogonality\n  Constraints for Enhanced Function and PDE Approximation", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present polynomial-augmented neural networks (PANNs), a novel machine\nlearning architecture that combines deep neural networks (DNNs) with a\npolynomial approximant. PANNs combine the strengths of DNNs (flexibility and\nefficiency in higher-dimensional approximation) with those of polynomial\napproximation (rapid convergence rates for smooth functions). To aid in both\nstable training and enhanced accuracy over a variety of problems, we present\n(1) a family of orthogonality constraints that impose mutual orthogonality\nbetween the polynomial and the DNN within a PANN; (2) a simple basis pruning\napproach to combat the curse of dimensionality introduced by the polynomial\ncomponent; and (3) an adaptation of a polynomial preconditioning strategy to\nboth DNNs and polynomials. We test the resulting architecture for its\npolynomial reproduction properties, ability to approximate both smooth\nfunctions and functions of limited smoothness, and as a method for the solution\nof partial differential equations (PDEs). Through these experiments, we\ndemonstrate that PANNs offer superior approximation properties to DNNs for both\nregression and the numerical solution of PDEs, while also offering enhanced\naccuracy over both polynomial and DNN-based regression (each) when regressing\nfunctions with limited smoothness.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2024 14:06:15 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 16:20:04 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Cooley", "Madison", ""], ["Zhe", "Shandian", ""], ["Kirby", "Robert M.", ""], ["Shankar", "Varun", ""]], "extracted_entities": [{"text": "DNNs", "label": "AI model"}, {"text": "DNNs", "label": "AI model"}, {"text": "DNNs", "label": "AI model"}], "human_readable_topic": "Optimization Methods for Neural Networks"}
{"id": "2406.03402", "submitter": "Jinsheng Yuan", "authors": "Jinsheng Yuan, Zhuangkun Wei, Weisi Guo", "title": "Mixed-Precision Federated Learning via Multi-Precision Over-The-Air\n  Aggregation", "comments": "Accepted by WCNC 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-the-Air Federated Learning (OTA-FL) is a privacy-preserving distributed\nlearning mechanism, by aggregating updates in the electromagnetic channel\nrather than at the server. A critical research gap in existing OTA-FL research\nis the assumption of homogeneous client computational bit precision. While in\nreal world application, clients with varying hardware resources may exploit\napproximate computing (AxC) to operate at different bit precisions optimized\nfor energy and computational efficiency. And model updates of various\nprecisions amongst clients poses an open challenge for OTA-FL, as it is\nincompatible in the wireless modulation superposition. Here, we propose an\nmixed-precision OTA-FL framework of clients with multiple bit precisions,\ndemonstrating the following innovations: (i) the superior trade-off for both\nserver and clients within the constraints of varying edge computing\ncapabilities, energy efficiency, and learning accuracy requirements comparing\nto homogeneous client bit precision, and (ii) a multi-precision gradient\nmodulation scheme to ensure compatibility with OTA aggregation and eliminate\nthe overheads of precision conversion. Through case study with real world data,\nwe validate our modulation scheme that enables AxC based mixed-precision\nOTA-FL. In comparison to homogeneous standard precision of 32-bit and 16-bit,\nour framework presents more than 10% in 4-bit ultra low precision client\nperformance and over 65%and 13% of energy savings respectively. This\ndemonstrates the great potential of our mixed-precision OTA-FL approach in\nheterogeneous edge computing environments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2024 09:07:45 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2024 10:14:36 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 14:21:21 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Yuan", "Jinsheng", ""], ["Wei", "Zhuangkun", ""], ["Guo", "Weisi", ""]], "extracted_entities": [{"text": "Over-the-Air Federated Learning", "label": "Zero-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}, {"text": "AxC", "label": "Few-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}, {"text": "OTA-FL", "label": "Zero-shot Learning"}], "human_readable_topic": "Wireless Networks and Federated Learning"}
{"id": "2406.04273", "submitter": "Elisa Tsai", "authors": "Haizhong Zheng, Elisa Tsai, Yifu Lu, Jiachen Sun, Brian R. Bartoldson,\n  Bhavya Kailkhura, Atul Prakash", "title": "ELFS: Label-Free Coreset Selection with Proxy Training Dynamics", "comments": "Accepted to ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-quality human-annotated data is crucial for modern deep learning\npipelines, yet the human annotation process is both costly and time-consuming.\nGiven a constrained human labeling budget, selecting an informative and\nrepresentative data subset for labeling can significantly reduce human\nannotation effort. Well-performing state-of-the-art (SOTA) coreset selection\nmethods require ground truth labels over the whole dataset, failing to reduce\nthe human labeling burden. Meanwhile, SOTA label-free coreset selection methods\ndeliver inferior performance due to poor geometry-based difficulty scores. In\nthis paper, we introduce ELFS (Effective Label-Free Coreset Selection), a novel\nlabel-free coreset selection method. ELFS significantly improves label-free\ncoreset selection by addressing two challenges: 1) ELFS utilizes deep\nclustering to estimate training dynamics-based data difficulty scores without\nground truth labels; 2) Pseudo-labels introduce a distribution shift in the\ndata difficulty scores, and we propose a simple but effective double-end\npruning method to mitigate bias on calculated scores. We evaluate ELFS on four\nvision benchmarks and show that, given the same vision encoder, ELFS\nconsistently outperforms SOTA label-free baselines. For instance, when using\nSwAV as the encoder, ELFS outperforms D2 by up to 10.2% in accuracy on\nImageNet-1K. We make our code publicly available on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2024 17:23:05 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 14:56:11 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zheng", "Haizhong", ""], ["Tsai", "Elisa", ""], ["Lu", "Yifu", ""], ["Sun", "Jiachen", ""], ["Bartoldson", "Brian R.", ""], ["Kailkhura", "Bhavya", ""], ["Prakash", "Atul", ""]], "extracted_entities": [{"text": "GitHub", "label": "Open-source LLMs"}], "human_readable_topic": "AI-Assisted Text Annotation and Labeling"}
{"id": "2406.04508", "submitter": "Dujian Ding", "authors": "Dujian Ding, Bicheng Xu, Laks V.S. Lakshmanan", "title": "OCCAM: Towards Cost-Efficient and Accuracy-Aware Classification\n  Inference", "comments": "ICLR 2025 (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification tasks play a fundamental role in various applications,\nspanning domains such as healthcare, natural language processing and computer\nvision. With the growing popularity and capacity of machine learning models,\npeople can easily access trained classifiers as a service online or offline.\nHowever, model use comes with a cost and classifiers of higher capacity (such\nas large foundation models) usually incur higher inference costs. To harness\nthe respective strengths of different classifiers, we propose a principled\napproach, OCCAM, to compute the best classifier assignment strategy over\nclassification queries (termed as the optimal model portfolio) so that the\naggregated accuracy is maximized, under user-specified cost budgets. Our\napproach uses an unbiased and low-variance accuracy estimator and effectively\ncomputes the optimal solution by solving an integer linear programming problem.\nOn a variety of real-world datasets, OCCAM achieves 40% cost reduction with\nlittle to no accuracy drop.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2024 21:05:39 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 03:15:20 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Ding", "Dujian", ""], ["Xu", "Bicheng", ""], ["Lakshmanan", "Laks V. S.", ""]], "extracted_entities": [{"text": "large foundation models", "label": "Foundation Model"}], "human_readable_topic": "Concept Bottleneck Models for Visual Classification"}
{"id": "2406.05011", "submitter": "George Datseris Dr", "authors": "George Datseris, Kristian Agas{\\o}ster Haaga", "title": "{ComplexityMeasures.jl}: scalable software to unify and accelerate\n  entropy and complexity timeseries analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IT math.IT nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the nonlinear timeseries analysis literature, countless quantities have\nbeen presented as new ``entropy'' or ``complexity'' measures, often with\nsimilar roles. The ever-increasing pool of such measures makes creating a\nsustainable and all-encompassing software for them difficult both conceptually\nand pragmatically. Such a software however would be an important tool that can\naid researchers make an informed decision of which measure to use and for which\napplication, as well as accelerate novel research. Here we present\n{ComplexityMeasures.jl}, an easily extendable and highly performant open-source\nsoftware that implements a vast selection of complexity measures. The software\nprovides 1638 measures with 3,841 lines of source code, averaging only 2.3\nlines of code per exported quantity (version 3.7). This is made possible by its\nmathematically rigorous composable design. In this paper we discuss the\nsoftware design and demonstrate how it can accelerate complexity-related\nresearch in the future. We carefully compare it with alternative software and\nconclude that {ComplexityMeasures.jl} outclasses the alternatives in several\nobjective aspects of comparison, such as computational performance, overall\namount of measures, reliability, and extendability. {ComplexityMeasures.jl} is\nalso a component of the {DynamicalSystems.jl} library for nonlinear dynamics\nand nonlinear timeseries analysis and follows open source development practices\nfor creating a sustainable community of developers and contributors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2024 15:22:45 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 17:44:28 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Datseris", "George", ""], ["Haaga", "Kristian Agas\u00f8ster", ""]], "extracted_entities": [{"text": "ComplexityMeasures.jl", "label": "Open-source LLMs"}, {"text": "ComplexityMeasures.jl", "label": "Open-source LLMs"}, {"text": "ComplexityMeasures.jl", "label": "Open-source LLMs"}], "human_readable_topic": "Log Parsing and Analysis Techniques"}
{"id": "2406.05127", "submitter": "Xiangtai Li Dr", "authors": "Shengqiong Wu, Hao Fei, Xiangtai Li, Jiayi Ji, Hanwang Zhang, Tat-Seng\n  Chua, Shuicheng Yan", "title": "Towards Semantic Equivalence of Tokenization in Multimodal LLM", "comments": "ICLR-2025. The project page: https://chocowu.github.io/SeTok-web/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal Large Language Models (MLLMs) have demonstrated exceptional\ncapabilities in processing vision-language tasks. One of the crux of MLLMs lies\nin vision tokenization, which involves efficiently transforming input visual\nsignals into feature representations that are most beneficial for LLMs.\nHowever, existing vision tokenizers, essential for semantic alignment between\nvision and language, remain problematic. Existing methods aggressively fragment\nvisual input, corrupting the visual semantic integrity. To address this, this\npaper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer (SeTok),\nwhich groups visual features into semantic units via a dynamic clustering\nalgorithm, flexibly determining the number of tokens based on image complexity.\nThe resulting vision tokens effectively preserve semantic integrity and capture\nboth low-frequency and high-frequency visual features. The proposed MLLM\n(Setokim) equipped with SeTok significantly demonstrates superior performance\nacross various tasks, as evidenced by our experimental results. The project\npage is at https://chocowu.github.io/SeTok-web/.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2024 17:55:43 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2024 17:35:45 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2024 12:01:24 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 02:55:53 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Wu", "Shengqiong", ""], ["Fei", "Hao", ""], ["Li", "Xiangtai", ""], ["Ji", "Jiayi", ""], ["Zhang", "Hanwang", ""], ["Chua", "Tat-Seng", ""], ["Yan", "Shuicheng", ""]], "extracted_entities": [{"text": "Multimodal Large Language Models", "label": "Large Language Model"}, {"text": "MLLMs", "label": "Large Language Model"}, {"text": "MLLMs", "label": "Large Language Model"}], "human_readable_topic": "Vision Language Models (VLMs)"}
{"id": "2406.05315", "submitter": "Mehrdad Khatir", "authors": "Mehrdad Khatir, Sanchit Kabra, Chandan K. Reddy", "title": "Aligned at the Start: Conceptual Groupings in LLM Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper shifts focus to the often-overlooked input embeddings - the\ninitial representations fed into transformer blocks. Using fuzzy graph,\nk-nearest neighbor (k-NN), and community detection, we analyze embeddings from\ndiverse LLMs, finding significant categorical community structure aligned with\npredefined concepts and categories aligned with humans. We observe these\ngroupings exhibit within-cluster organization (such as hierarchies, topological\nordering, etc.), hypothesizing a fundamental structure that precedes contextual\nprocessing. To further investigate the conceptual nature of these groupings, we\nexplore cross-model alignments across different LLM categories within their\ninput embeddings, observing a medium to high degree of alignment. Furthermore,\nprovide evidence that manipulating these groupings can play a functional role\nin mitigating ethnicity bias in LLM tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2024 01:27:19 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2025 23:26:33 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 17:53:06 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Khatir", "Mehrdad", ""], ["Kabra", "Sanchit", ""], ["Reddy", "Chandan K.", ""]], "extracted_entities": [{"text": "input embeddings", "label": "contextual Embedding"}, {"text": "embeddings", "label": "Embedding"}, {"text": "LLMs", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "input embeddings", "label": "contextual Embedding"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Network Embeddings and Community Detection"}
{"id": "2406.05516", "submitter": "Hengguan Huang", "authors": "Hengguan Huang, Xing Shen, Songtao Wang, Lingfa Meng, Dianbo Liu, Hao\n  Wang, Samir Bhatt", "title": "Verbalized Probabilistic Graphical Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2024 16:35:31 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 13:56:16 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Huang", "Hengguan", ""], ["Shen", "Xing", ""], ["Wang", "Songtao", ""], ["Meng", "Lingfa", ""], ["Liu", "Dianbo", ""], ["Wang", "Hao", ""], ["Bhatt", "Samir", ""]], "extracted_entities": [{"text": "Large\nLanguage Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "chain-of-thought reasoning", "label": "Chain of thought"}, {"text": "Bayesian prompting", "label": "Prompting"}, {"text": "vPGM", "label": "Prompting"}], "human_readable_topic": "Chain-of-Thought Reasoning in Large Language Models"}
{"id": "2406.05784", "submitter": "Seemab Latif", "authors": "Huma Ameer, Seemab Latif, Mehwish Fatima", "title": "Optimizing Multi-Stuttered Speech Classification: Leveraging Whisper's\n  Encoder for Efficient Parameter Reduction in Automated Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automated classification of stuttered speech has significant implications\nfor timely assessments providing assistance to speech language pathologists.\nDespite notable advancements in the field, the cases in which multiple\ndisfluencies occur in speech require attention. We have taken a progressive\napproach to fill this gap by classifying multi-stuttered speech more\nefficiently. The problem has been addressed by firstly curating a dataset of\nmulti-stuttered disfluencies from open source dataset SEP-28k audio clips.\nSecondly, employing Whisper, a state-of-the-art speech recognition model has\nbeen leveraged by using its encoder and taking the problem as multi label\nclassification. Thirdly, using a 6 encoder layer Whisper and experimenting with\nvarious layer freezing strategies, a computationally efficient configuration of\nthe model was identified. The proposed configuration achieved micro, macro, and\nweighted F1-scores of 0.88, 0.85, and 0.87, correspondingly on an external test\ndataset i.e. Fluency-Bank. In addition, through layer freezing strategies, we\nwere able to achieve the aforementioned results by fine-tuning a single encoder\nlayer, consequently, reducing the model's trainable parameters from 20.27\nmillion to 3.29 million. This research study unveils the contribution of the\nlast encoder layer in the identification of disfluencies in stuttered speech.\nConsequently, it has led to a computationally efficient approach, 83.7% less\nparameters to train, making the proposed approach more adaptable for various\ndialects and languages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2024 13:42:51 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2024 06:13:36 GMT"}, {"version": "v3", "created": "Sat, 20 Jul 2024 16:00:30 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 17:31:34 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Ameer", "Huma", ""], ["Latif", "Seemab", ""], ["Fatima", "Mehwish", ""]], "extracted_entities": [{"text": "attention", "label": "Attention mechanism"}, {"text": "SEP-28k", "label": "Open-source LLMs"}], "human_readable_topic": "Speech-to-Text and Audio Processing"}
{"id": "2406.06389", "submitter": "Eoin \\'O Colg\\'ain", "authors": "Eoin \\'O Colg\\'ain, Saeed Pourojaghi, M. M. Sheikh-Jabbari", "title": "Implications of DES 5YR SNe Dataset for $\\Lambda$CDM", "comments": "Redshift dependent cosmological parameters in DES 5YR SNe; v2 wording\n  improved, reference added; v3 to appear in EPJC, whether frequentist or\n  Bayesian, the result is the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO gr-qc hep-ph hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dark Energy Survey five-year supernovae data (DES 5YR SNe) in conjunction\nwith Planck CMB and Dark Energy Spectroscopic Instrument (DESI) BAO data has\ndetected a strong dynamical dark energy (DE) deviation from the $\\Lambda$CDM\nmodel.Here we shift the focus of DES data to the pressureless matter sector in\nthe $\\Lambda$CDM model by studying the matter density parameter $\\Omega_m$.\nEmploying primarily frequentist profile likelihoods, supported by complementary\nBayesian methods, we demonstrate that $\\Omega_m$ increases with effective\nredshift in the DES data up to a point that there is a $2.5 \\sigma$ discrepancy\nwith Planck. We relax the traditional $\\Omega_m \\leq 1$ prior to demonstrate\nnegative DE densities $\\Omega_m > 1$ at the highest effective redshift probed.\nNevertheless, the largest discrepancy with Planck occurs for profile\nlikelihoods and posteriors peaked at $\\Omega_m < 1$ in the traditional\n$\\Lambda$CDM regime. Our findings corroborate earlier observations in Pantheon\nand Pantheon+ datasets with an independent SNe dataset with a higher effective\nredshift. In an appendix, we confirm that curvature $\\Omega_k$ decreases with\neffective redshift disfavouring a flat Universe in higher redshift DES SNe at\n$> 3 \\sigma$. Our choice of $\\Omega_k$ prior leads to an underestimation of the\ntension with a flat Universe.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2024 15:45:15 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2024 08:23:24 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 16:54:15 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Colg\u00e1in", "Eoin \u00d3", ""], ["Pourojaghi", "Saeed", ""], ["Sheikh-Jabbari", "M. M.", ""]], "extracted_entities": [{"text": "$\\Lambda$CDM\nmodel", "label": "AI model"}, {"text": "$\\Lambda$CDM model", "label": "AI model"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2406.06418", "submitter": "Oliver Hahn", "authors": "Oliver Hahn, Giulia Ferrini, Ryuji Takagi", "title": "Bridging magic and non-Gaussian resources via Gottesman-Kitaev-Preskill\n  encoding", "comments": null, "journal-ref": "PRX Quantum 6, 010330 (2025)", "doi": "10.1103/PRXQuantum.6.010330", "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the similarity between non-stabilizer states -- also known as magic\nstates -- in discrete-variable systems and non-Gaussian states in\ncontinuous-variable systems has widely been recognized, the precise connections\nbetween these two notions have still been unclear. We establish a fundamental\nlink between these two quantum resources via the Gottesman-Kitaev-Preskill\n(GKP) encoding. We show that the negativity of the continuous-variable Wigner\nfunction for an encoded GKP state coincides with a magic measure we introduce,\nwhich matches the negativity of the discrete Wigner function for odd\ndimensions. We also provide a continuous-variable representation of the\nstabilizer R\\'enyi entropy -- a recent proposal for a magic measure for\nmulti-qubit states. With this in hand, we give a classical simulation algorithm\nwith runtime scaling with the resource contents, quantified by our magic\nmeasures. We also employ our results to prove that implementing a multi-qubit\nlogical non-Clifford operation in the GKP code subspace requires a non-Gaussian\noperation even at the limit of perfect encoding, despite the fact that the\nideal GKP states already come with a large amount of non-Gaussianity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2024 16:09:45 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2024 01:17:41 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 00:48:28 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Hahn", "Oliver", ""], ["Ferrini", "Giulia", ""], ["Takagi", "Ryuji", ""]], "extracted_entities": [{"text": "runtime scaling", "label": "Scaling law"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2406.06526", "submitter": "Haozhe Xie", "authors": "Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu", "title": "Generative Gaussian Splatting for Unbounded 3D City Generation", "comments": "CVPR 2025. Project Page: https://haozhexie.com/project/gaussian-city", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D city generation with NeRF-based methods shows promising generation results\nbut is computationally inefficient. Recently 3D Gaussian Splatting (3D-GS) has\nemerged as a highly efficient alternative for object-level 3D generation.\nHowever, adapting 3D-GS from finite-scale 3D objects and humans to\ninfinite-scale 3D cities is non-trivial. Unbounded 3D city generation entails\nsignificant storage overhead (out-of-memory issues), arising from the need to\nexpand points to billions, often demanding hundreds of Gigabytes of VRAM for a\ncity scene spanning 10km^2. In this paper, we propose GaussianCity, a\ngenerative Gaussian Splatting framework dedicated to efficiently synthesizing\nunbounded 3D cities with a single feed-forward pass. Our key insights are\ntwo-fold: 1) Compact 3D Scene Representation: We introduce BEV-Point as a\nhighly compact intermediate representation, ensuring that the growth in VRAM\nusage for unbounded scenes remains constant, thus enabling unbounded city\ngeneration. 2) Spatial-aware Gaussian Attribute Decoder: We present\nspatial-aware BEV-Point decoder to produce 3D Gaussian attributes, which\nleverages Point Serializer to integrate the structural and contextual\ncharacteristics of BEV points. Extensive experiments demonstrate that\nGaussianCity achieves state-of-the-art results in both drone-view and\nstreet-view 3D city generation. Notably, compared to CityDreamer, GaussianCity\nexhibits superior performance with a speedup of 60 times (10.72 FPS v.s. 0.18\nFPS).\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2024 17:59:55 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2024 07:29:33 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 05:39:54 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Xie", "Haozhe", ""], ["Chen", "Zhaoxi", ""], ["Hong", "Fangzhou", ""], ["Liu", "Ziwei", ""]], "extracted_entities": [{"text": "Point Serializer", "label": "Embedding"}], "human_readable_topic": "Language-Guided 3D Scene Generation"}
{"id": "2406.06608", "submitter": "Sander Schulhoff", "authors": "Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze,\n  Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien\n  Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta\n  Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava,\n  Hevander Da Costa, Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe\n  Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal\n  Anadkat, Alexander Hoyle, Philip Resnik", "title": "The Prompt Report: A Systematic Survey of Prompt Engineering Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Artificial Intelligence (GenAI) systems are increasingly being\ndeployed across diverse industries and research domains. Developers and\nend-users interact with these systems through the use of prompting and prompt\nengineering. Although prompt engineering is a widely adopted and extensively\nresearched area, it suffers from conflicting terminology and a fragmented\nontological understanding of what constitutes an effective prompt due to its\nrelatively recent emergence. We establish a structured understanding of prompt\nengineering by assembling a taxonomy of prompting techniques and analyzing\ntheir applications. We present a detailed vocabulary of 33 vocabulary terms, a\ntaxonomy of 58 LLM prompting techniques, and 40 techniques for other\nmodalities. Additionally, we provide best practices and guidelines for prompt\nengineering, including advice for prompting state-of-the-art (SOTA) LLMs such\nas ChatGPT. We further present a meta-analysis of the entire literature on\nnatural language prefix-prompting. As a culmination of these efforts, this\npaper presents the most comprehensive survey on prompt engineering to date.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2024 18:10:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2024 01:28:09 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2024 03:17:50 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2024 18:38:36 GMT"}, {"version": "v5", "created": "Mon, 30 Dec 2024 19:33:09 GMT"}, {"version": "v6", "created": "Wed, 26 Feb 2025 18:59:01 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Schulhoff", "Sander", ""], ["Ilie", "Michael", ""], ["Balepur", "Nishant", ""], ["Kahadze", "Konstantine", ""], ["Liu", "Amanda", ""], ["Si", "Chenglei", ""], ["Li", "Yinheng", ""], ["Gupta", "Aayush", ""], ["Han", "HyoJung", ""], ["Schulhoff", "Sevien", ""], ["Dulepet", "Pranav Sandeep", ""], ["Vidyadhara", "Saurav", ""], ["Ki", "Dayeon", ""], ["Agrawal", "Sweta", ""], ["Pham", "Chau", ""], ["Kroiz", "Gerson", ""], ["Li", "Feileen", ""], ["Tao", "Hudson", ""], ["Srivastava", "Ashay", ""], ["Da Costa", "Hevander", ""], ["Gupta", "Saloni", ""], ["Rogers", "Megan L.", ""], ["Goncearenco", "Inna", ""], ["Sarli", "Giuseppe", ""], ["Galynker", "Igor", ""], ["Peskoff", "Denis", ""], ["Carpuat", "Marine", ""], ["White", "Jules", ""], ["Anadkat", "Shyamal", ""], ["Hoyle", "Alexander", ""], ["Resnik", "Philip", ""]], "extracted_entities": [{"text": "prompting", "label": "Prompting"}, {"text": "prompt\nengineering", "label": "Prompting"}, {"text": "prompt engineering", "label": "Prompting"}, {"text": "prompt\nengineering", "label": "Prompting"}, {"text": "prompting", "label": "Prompting"}, {"text": "prompting techniques", "label": "Prompting"}, {"text": "prompt\nengineering", "label": "Prompting"}, {"text": "prompting", "label": "Prompting"}, {"text": "ChatGPT", "label": "ChatGPT"}, {"text": "prompt engineering", "label": "Prompting"}], "human_readable_topic": "Prompt Engineering for Large Language Models"}
{"id": "2406.07212", "submitter": "Joshua Strong", "authors": "Joshua Strong, Qianhui Men, Alison Noble", "title": "Trustworthy and Practical AI for Healthcare: A Guided Deferral System\n  with Large Language Models", "comments": "AAAI-AISI 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large language models (LLMs) offer a valuable technology for various\napplications in healthcare. However, their tendency to hallucinate and the\nexisting reliance on proprietary systems pose challenges in environments\nconcerning critical decision-making and strict data privacy regulations, such\nas healthcare, where the trust in such systems is paramount. Through combining\nthe strengths and discounting the weaknesses of humans and AI, the field of\nHuman-AI Collaboration (HAIC) presents one front for tackling these challenges\nand hence improving trust. This paper presents a novel HAIC guided deferral\nsystem that can simultaneously parse medical reports for disorder\nclassification, and defer uncertain predictions with intelligent guidance to\nhumans. We develop methodology which builds efficient, effective and\nopen-source LLMs for this purpose, for the real-world deployment in healthcare.\nWe conduct a pilot study which showcases the effectiveness of our proposed\nsystem in practice. Additionally, we highlight drawbacks of standard\ncalibration metrics in imbalanced data scenarios commonly found in healthcare,\nand suggest a simple yet effective solution: the Imbalanced Expected\nCalibration Error.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2024 12:41:54 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2024 14:49:15 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 00:49:57 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Strong", "Joshua", ""], ["Men", "Qianhui", ""], ["Noble", "Alison", ""]], "extracted_entities": [{"text": "strict data privacy regulations", "label": "AI Ethics"}], "human_readable_topic": "Large Language Models in Healthcare Applications"}
{"id": "2406.07475", "submitter": "Anming Gu", "authors": "Anming Gu, Edward Chien, and Kristjan Greenewald", "title": "Partially Observed Trajectory Inference using Optimal Transport and a\n  Dynamics Prior", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trajectory inference seeks to recover the temporal dynamics of a population\nfrom snapshots of its (uncoupled) temporal marginals, i.e. where observed\nparticles are not tracked over time. Prior works addressed this challenging\nproblem under a stochastic differential equation (SDE) model with a\ngradient-driven drift in the observed space, introducing a minimum entropy\nestimator relative to the Wiener measure and a practical grid-free mean-field\nLangevin (MFL) algorithm using Schr\\\"odinger bridges. Motivated by the success\nof observable state space models in the traditional paired trajectory inference\nproblem (e.g. target tracking), we extend the above framework to a class of\nlatent SDEs in the form of observable state space models. In this setting, we\nuse partial observations to infer trajectories in the latent space under a\nspecified dynamics model (e.g. the constant velocity/acceleration models from\ntarget tracking). We introduce the PO-MFL algorithm to solve this latent\ntrajectory inference problem and provide theoretical guarantees to the\npartially observed setting. Experiments validate the robustness of our method\nand the exponential convergence of the MFL dynamics, and demonstrate\nsignificant outperformance over the latent-free baseline in key scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2024 17:21:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2025 22:59:29 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 14:58:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Gu", "Anming", ""], ["Chien", "Edward", ""], ["Greenewald", "Kristjan", ""]], "extracted_entities": [{"text": "observable state space models", "label": "AI model"}], "human_readable_topic": "Random Processes and Stochastic Dynamics"}
{"id": "2406.08155", "submitter": "Pingzhi Li", "authors": "Pingzhi Li, Xiaolong Jin, Zhen Tan, Yu Cheng, Tianlong Chen", "title": "QuantMoE-Bench: Examining Post-Training Quantization for\n  Mixture-of-Experts", "comments": "Our code for reproducing all our experiments is provided at\n  https://github.com/UNITES-Lab/moe-quantization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture-of-Experts (MoE) is a promising way to scale up the learning capacity\nof large language models. It increases the number of parameters while keeping\nFLOPs nearly constant during inference through sparse activation. Yet, it still\nsuffers from significant memory overheads due to the vast parameter size,\nnecessitating model compression techniques. Post-training quantization offers a\npowerful approach for model compression. Existing methods adopt a fixed\nquantization precision for the entire MoE model. This rigid setup can lead to\nsuboptimal performance, without considering the inherent sparse structure. For\nexample, MoE's sparse routing mechanism leads to different activation patterns,\nwhere shared experts are accessed by all tokens while token-conditioned experts\nare selectively activated. This activation disparity suggests different\nquantization requirements, with consistently activated shared experts\npotentially needing higher precision to maintain model quality. In this paper,\nwe study a fine-grained precision setup for MoE quantization. We explore MoE\nstructure-aware quantization heuristics, ranging from coarse (e.g., MoE layers)\nto fine granularity (e.g., linear layers). Our investigations reveal critical\nprinciples, where different MoE structures require varying numbers of bits for\neffective quantization. Conclusions are supported by extensive benchmarking\nacross two representative MoE models and six tasks including commonsense\nreasoning and natural language understanding. We further show that an MoE\nquantized in a fined-grained mixed precision achieved state-of-the-art 65.35%\nperformance on average compared to the baseline 64.30% (i.e., GPTQ). Moreover,\nbased on the findings, we introduce novel data-driven techniques for optimizing\nbit allocation in MoE quantization, including the outlier-aware linear layer\nscorer and MoE block importance predictor.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2024 12:44:48 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 18:29:54 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Li", "Pingzhi", ""], ["Jin", "Xiaolong", ""], ["Tan", "Zhen", ""], ["Cheng", "Yu", ""], ["Chen", "Tianlong", ""]], "extracted_entities": [{"text": "model compression techniques", "label": "quantisation"}, {"text": "Post-training quantization", "label": "quantisation"}], "human_readable_topic": "Mixture of Experts (MoE) for Large Language Models"}
{"id": "2406.08546", "submitter": "Hui Liu", "authors": "Hui Liu, Raul Perea-Causin, and Emil J. Bergholtz", "title": "Parafermions in Moir\\'e Minibands", "comments": "Add journal reference", "journal-ref": "Nature Communications volume 16, Article number: 1770 (2025)", "doi": "10.1038/s41467-025-57035-x", "report-no": null, "categories": "cond-mat.str-el cond-mat.mes-hall", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Moir\\'e materials provide a remarkably tunable platform for topological and\nstrongly correlated quantum phases of matter. Very recently, the first zero\nfield Abelian fractional Chern insulators (FCIs) have been experimentally\ndemonstrated and it has been theoretically predicted that non-Abelian states\nwith Majorana fermion excitations may be realized in the nearly dispersionless\nminibands of these systems. Here we provide telltale evidence in terms of\nlow-energy quantum numbers, spectral flow and entanglement spectra for the even\nmore exotic possibility of moir\\'e-based non-Abelian FCIs exhibiting Fibonacci\nparafermion excitations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2024 18:00:01 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2025 10:16:16 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 17:01:20 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Liu", "Hui", ""], ["Perea-Causin", "Raul", ""], ["Bergholtz", "Emil J.", ""]], "extracted_entities": [{"text": "Moir\\'e", "label": "Mistral"}, {"text": "moir\\'e-based", "label": "Mistral"}, {"text": "FCIs", "label": "LLMs"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2406.08772", "submitter": "Xuannan Liu", "authors": "Xuannan Liu and Zekun Li and Peipei Li and Huaibo Huang and Shuhan Xia\n  and Xing Cui and Linzhi Huang and Weihong Deng and Zhaofeng He", "title": "MMFakeBench: A Mixed-Source Multimodal Misinformation Detection\n  Benchmark for LVLMs", "comments": "Accepted by ICLR 2025, Project page:\n  https://liuxuannan.github.io/MMFakeBench.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current multimodal misinformation detection (MMD) methods often assume a\nsingle source and type of forgery for each sample, which is insufficient for\nreal-world scenarios where multiple forgery sources coexist. The lack of a\nbenchmark for mixed-source misinformation has hindered progress in this field.\nTo address this, we introduce MMFakeBench, the first comprehensive benchmark\nfor mixed-source MMD. MMFakeBench includes 3 critical sources: textual veracity\ndistortion, visual veracity distortion, and cross-modal consistency distortion,\nalong with 12 sub-categories of misinformation forgery types. We further\nconduct an extensive evaluation of 6 prevalent detection methods and 15 Large\nVision-Language Models (LVLMs) on MMFakeBench under a zero-shot setting. The\nresults indicate that current methods struggle under this challenging and\nrealistic mixed-source MMD setting. Additionally, we propose MMD-Agent, a novel\napproach to integrate the reasoning, action, and tool-use capabilities of LVLM\nagents, significantly enhancing accuracy and generalization. We believe this\nstudy will catalyze future research into more realistic mixed-source multimodal\nmisinformation and provide a fair evaluation of misinformation detection\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2024 03:04:28 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2024 05:00:04 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 03:19:48 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liu", "Xuannan", ""], ["Li", "Zekun", ""], ["Li", "Peipei", ""], ["Huang", "Huaibo", ""], ["Xia", "Shuhan", ""], ["Cui", "Xing", ""], ["Huang", "Linzhi", ""], ["Deng", "Weihong", ""], ["He", "Zhaofeng", ""]], "extracted_entities": [{"text": "zero-shot setting", "label": "Zero-shot Learning"}], "human_readable_topic": "Multimodal Misinformation Detection and Debunking"}
{"id": "2406.09179", "submitter": "Qizhou Wang", "authors": "Qizhou Wang, Bo Han, Puning Yang, Jianing Zhu, Tongliang Liu, Masashi\n  Sugiyama", "title": "Towards Effective Evaluations and Comparisons for LLM Unlearning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imperative to eliminate undesirable data memorization underscores the\nsignificance of machine unlearning for large language models (LLMs). Recent\nresearch has introduced a series of promising unlearning methods, notably\nboosting the practical significance of the field. Nevertheless, adopting a\nproper evaluation framework to reflect the true unlearning efficacy is also\nessential yet has not received adequate attention. This paper seeks to refine\nthe evaluation of LLM unlearning by addressing two key challenges -- a) the\nrobustness of evaluation metrics and b) the trade-offs between competing goals.\nThe first challenge stems from findings that current metrics are susceptible to\nvarious red teaming scenarios. It indicates that they may not reflect the true\nextent of knowledge retained by LLMs but rather tend to mirror superficial\nmodel behaviors, thus prone to attacks. We address this issue by devising and\nassessing a series of candidate metrics, selecting the most robust ones under\nvarious types of attacks. The second challenge arises from the conflicting\ngoals of eliminating unwanted knowledge while retaining those of others. This\ntrade-off between unlearning and retention often fails to conform the Pareto\nfrontier, rendering it subtle to compare the efficacy between methods that\nexcel only in either unlearning or retention. We handle this issue by proposing\na calibration method that can restore the original performance on non-targeted\ndata after unlearning, thereby allowing us to focus exclusively on assessing\nthe strength of unlearning. Our evaluation framework notably enhances the\neffectiveness when assessing and comparing various LLM unlearning methods,\nfurther allowing us to benchmark existing works, identify their proper\nhyper-parameters, and explore new tricks to enhance their practical efficacy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2024 14:41:00 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 03:42:38 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Wang", "Qizhou", ""], ["Han", "Bo", ""], ["Yang", "Puning", ""], ["Zhu", "Jianing", ""], ["Liu", "Tongliang", ""], ["Sugiyama", "Masashi", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Automated Red Teaming for Large Language Models"}
{"id": "2406.09288", "submitter": "Jinbin Zhang", "authors": "Jinbin Zhang, Nasib Ullah, Rohit Babbar", "title": "Large Language Model as a Teacher for Zero-shot Tagging at Extreme\n  Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme Multi-label Text Classification (XMC) entails selecting the most\nrelevant labels for an instance from a vast label set. Extreme Zero-shot XMC\n(EZ-XMC) extends this challenge by operating without annotated data, relying\nonly on raw text instances and a predefined label set, making it particularly\ncritical for addressing cold-start problems in large-scale recommendation and\ncategorization systems. State-of-the-art methods, such as MACLR and RTS,\nleverage lightweight bi-encoders but rely on suboptimal pseudo labels for\ntraining, such as document titles (MACLR) or document segments (RTS), which may\nnot align well with the intended tagging or categorization tasks. On the other\nhand, LLM-based approaches, like ICXML, achieve better label-instance alignment\nbut are computationally expensive and impractical for real-world EZ-XMC\napplications due to their heavy inference costs. In this paper, we introduce\nLMTX (Large language Model as Teacher for eXtreme classification), a novel\nframework that bridges the gap between these two approaches. LMTX utilizes an\nLLM to identify high-quality pseudo labels during training, while employing a\nlightweight bi-encoder for efficient inference. This design eliminates the need\nfor LLMs at inference time, offering the benefits of improved label alignment\nwithout sacrificing computational efficiency. Our approach achieves superior\nperformance and efficiency over both LLM and non-LLM based approaches,\nestablishing a new state-of-the-art in EZ-XMC.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2024 16:26:37 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 13:10:05 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhang", "Jinbin", ""], ["Ullah", "Nasib", ""], ["Babbar", "Rohit", ""]], "extracted_entities": [{"text": "Extreme Zero-shot XMC", "label": "Zero-shot Learning"}, {"text": "MACLR", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "LLMs", "label": "LLM"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Extreme Multi-label Text Classification"}
{"id": "2406.10126", "submitter": "Chen Hou", "authors": "Chen Hou, Zhibo Chen", "title": "Training-free Camera Control for Video Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a training-free and robust solution to offer camera movement\ncontrol for off-the-shelf video diffusion models. Unlike previous work, our\nmethod does not require any supervised finetuning on camera-annotated datasets\nor self-supervised training via data augmentation. Instead, it can be\nplug-and-play with most pretrained video diffusion models and generate\ncamera-controllable videos with a single image or text prompt as input. The\ninspiration for our work comes from the layout prior that intermediate latents\nencode for the generated results, thus rearranging noisy pixels in them will\ncause the output content to relocate as well. As camera moving could also be\nseen as a type of pixel rearrangement caused by perspective change, videos can\nbe reorganized following specific camera motion if their noisy latents change\naccordingly. Building on this, we propose CamTrol, which enables robust camera\ncontrol for video diffusion models. It is achieved by a two-stage process.\nFirst, we model image layout rearrangement through explicit camera movement in\n3D point cloud space. Second, we generate videos with camera motion by\nleveraging the layout prior of noisy latents formed by a series of rearranged\nimages. Extensive experiments have demonstrated its superior performance in\nboth video generation and camera motion alignment compared with other finetuned\nmethods. Furthermore, we show the capability of CamTrol to generalize to\nvarious base models, as well as its impressive applications in scalable motion\ncontrol, dealing with complicated trajectories and unsupervised 3D video\ngeneration. Videos available at https://lifedecoder.github.io/CamTrol/.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2024 15:33:00 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2024 10:25:23 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2024 03:13:09 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 00:32:29 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Hou", "Chen", ""], ["Chen", "Zhibo", ""]], "extracted_entities": [{"text": "supervised finetuning", "label": "Fine-tuning"}, {"text": "text prompt", "label": "Prompting"}], "human_readable_topic": "Diffusion-Based Video Generation"}
{"id": "2406.10354", "submitter": "Barbora Barancikova", "authors": "Barbora Barancikova, Zhuoyue Huang, Cristopher Salvi", "title": "SigDiffusions: Score-Based Diffusion Models for Time Series via\n  Log-Signature Embeddings", "comments": "Published at ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Score-based diffusion models have recently emerged as state-of-the-art\ngenerative models for a variety of data modalities. Nonetheless, it remains\nunclear how to adapt these models to generate long multivariate time series.\nViewing a time series as the discretisation of an underlying continuous\nprocess, we introduce SigDiffusion, a novel diffusion model operating on\nlog-signature embeddings of the data. The forward and backward processes\ngradually perturb and denoise log-signatures while preserving their algebraic\nstructure. To recover a signal from its log-signature, we provide new\nclosed-form inversion formulae expressing the coefficients obtained by\nexpanding the signal in a given basis (e.g. Fourier or orthogonal polynomials)\nas explicit polynomial functions of the log-signature. Finally, we show that\ncombining SigDiffusions with these inversion formulae results in high-quality\nlong time series generation, competitive with the current state-of-the-art on\nvarious datasets of synthetic and real-world examples.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2024 18:04:06 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 19:38:40 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Barancikova", "Barbora", ""], ["Huang", "Zhuoyue", ""], ["Salvi", "Cristopher", ""]], "extracted_entities": [{"text": "log-signature embeddings", "label": "Embedding"}], "human_readable_topic": "Watermarking Techniques for Generative Models"}
{"id": "2406.10875", "submitter": "Sergei Kuzenko", "authors": "Nowar E. Koning and Sergei M. Kuzenko", "title": "Embedding formalism for AdS superspaces in five dimensions", "comments": "44 pages; v2: comments and references added, more general\n  superparticle action given", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard geometric description of $d$-dimensional anti-de Sitter (AdS)\nspace is a quadric in ${\\mathbb R}^{d-1,2}$ defined by $(X^0)^2 - (X^1)^2 -\n\\dots - (X^{d-1})^2 + (X^d)^2 = \\ell^2 = \\text{const}$. In this paper we\nprovide a supersymmetric generalisation of this embedding construction in the\n$d=5$ case. Specifically, a bi-supertwistor realisation is given for the ${\\cal\nN}$-extended AdS superspace $\\text{AdS}^{5|8\\cal N}$, with ${\\cal N}\\geq 1$.\nThe proposed formalism offers a simple construction of AdS super-invariants. As\nan example, we present a new model for a massive superparticle in\n$\\text{AdS}^{5|8\\cal N}$ which is manifestly invariant under the AdS isometry\nsupergroup $\\mathsf{SU}(2,2|{\\cal N})$ and involves two independent\ntwo-derivative terms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2024 09:56:45 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 11:22:10 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Koning", "Nowar E.", ""], ["Kuzenko", "Sergei M.", ""]], "extracted_entities": [{"text": "bi-supertwistor realisation", "label": "Embedding"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2406.11138", "submitter": "Chunming He", "authors": "Chunming He, Yuqi Shen, Chengyu Fang, Fengyang Xiao, Longxiang Tang,\n  Yulun Zhang, Wangmeng Zuo, Zhenhua Guo, Xiu Li", "title": "Diffusion Models in Low-Level Vision: A Survey", "comments": "Accepted at IEEE TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have garnered significant attention in low-level\nvision tasks due to their generative capabilities. Among them, diffusion\nmodel-based solutions, characterized by a forward diffusion process and a\nreverse denoising process, have emerged as widely acclaimed for their ability\nto produce samples of superior quality and diversity. This ensures the\ngeneration of visually compelling results with intricate texture information.\nDespite their remarkable success, a noticeable gap exists in a comprehensive\nsurvey that amalgamates these pioneering diffusion model-based works and\norganizes the corresponding threads. This paper proposes the comprehensive\nreview of diffusion model-based techniques. We present three generic diffusion\nmodeling frameworks and explore their correlations with other deep generative\nmodels, establishing the theoretical foundation. Following this, we introduce a\nmulti-perspective categorization of diffusion models, considering both the\nunderlying framework and the target task. Additionally, we summarize extended\ndiffusion models applied in other tasks, including medical, remote sensing, and\nvideo scenarios. Moreover, we provide an overview of commonly used benchmarks\nand evaluation metrics. We conduct a thorough evaluation, encompassing both\nperformance and efficiency, of diffusion model-based techniques in three\nprominent tasks. Finally, we elucidate the limitations of current diffusion\nmodels and propose seven intriguing directions for future research. This\ncomprehensive examination aims to facilitate a profound understanding of the\nlandscape surrounding denoising diffusion models in the context of low-level\nvision tasks. A curated list of diffusion model-based techniques in over 20\nlow-level vision tasks can be found at\nhttps://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 01:49:27 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 03:53:24 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["He", "Chunming", ""], ["Shen", "Yuqi", ""], ["Fang", "Chengyu", ""], ["Xiao", "Fengyang", ""], ["Tang", "Longxiang", ""], ["Zhang", "Yulun", ""], ["Zuo", "Wangmeng", ""], ["Guo", "Zhenhua", ""], ["Li", "Xiu", ""]], "extracted_entities": [{"text": "Deep generative models", "label": "AI model"}, {"text": "diffusion\nmodel-based solutions", "label": "AI model"}, {"text": "deep generative\nmodels", "label": "AI model"}], "human_readable_topic": "Diffusion Transformers for Image Generation"}
{"id": "2406.11423", "submitter": "Evan Williams", "authors": "Evan M. Williams, Peter Carragher, Kathleen M. Carley", "title": "Bridging Social Media and Search Engines: Dredge Words and the Detection\n  of Unreliable Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proactive content moderation requires platforms to rapidly and continuously\nevaluate the credibility of websites. Leveraging the direct and indirect paths\nusers follow to unreliable websites, we develop a website credibility\nclassification and discovery system that integrates both webgraph and\nlarge-scale social media contexts. We additionally introduce the concept of\ndredge words, terms or phrases for which unreliable domains rank highly on\nsearch engines, and provide the first exploration of their usage on social\nmedia. Our graph neural networks that combine webgraph and social media\ncontexts generate to state-of-the-art results in website credibility\nclassification and significantly improves the top-k identification of\nunreliable domains. Additionally, we release a novel dataset of dredge words,\nhighlighting their strong connections to both social media and online commerce\nplatforms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 11:22:04 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2024 16:20:53 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 16:40:20 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Williams", "Evan M.", ""], ["Carragher", "Peter", ""], ["Carley", "Kathleen M.", ""]], "extracted_entities": [{"text": "large-scale social media contexts", "label": "Large Language Model"}], "human_readable_topic": "Fake Review Detection and Sentiment Analysis"}
{"id": "2406.11458", "submitter": "Maayan Ehrenberg", "authors": "Maayan Ehrenberg, Roy Ganz, Nir Rosenfeld", "title": "Adversaries With Incentives: A Strategic Alternative to Adversarial\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training aims to defend against *adversaries*: malicious\nopponents whose sole aim is to harm predictive performance in any way possible\n- a rather harsh perspective, which we assert results in unnecessarily\nconservative models. Instead, we propose to model opponents as simply pursuing\ntheir own goals, rather than working directly against the classifier. Employing\ntools from strategic modeling, our approach uses knowledge or beliefs regarding\nthe opponent's possible incentives as inductive bias for learning. Our method\nof *strategic training* is designed to defend against opponents within an\n*incentive uncertainty set*: this resorts to adversarial learning when the set\nis maximal, but offers potential gains when it can be appropriately reduced. We\nconduct a series of experiments that show how even mild knowledge regarding the\nadversary's incentives can be useful, and that the degree of potential gains\ndepends on how incentives relate to the structure of the learning task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 12:20:59 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 18:14:27 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Ehrenberg", "Maayan", ""], ["Ganz", "Roy", ""], ["Rosenfeld", "Nir", ""]], "extracted_entities": [{"text": "Adversarial training", "label": "Few-shot Learning"}, {"text": "inductive bias", "label": "Model Bias and Fairness"}, {"text": "adversarial learning", "label": "Few-shot Learning"}], "human_readable_topic": "Adversarial Robustness in Deep Learning Models"}
{"id": "2406.11630", "submitter": "Dalton Sakthivadivel", "authors": "Maxwell J D Ramstead, Dalton A R Sakthivadivel, Karl J Friston", "title": "A framework for the use of generative modelling in non-equilibrium\n  statistical mechanics", "comments": "15+3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech math-ph math.MP nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We discuss an approach to mathematically modelling systems made of objects\nthat are coupled together, using generative models of the dependence\nrelationships between states (or trajectories) of the things comprising such\nsystems. This broad class includes open or non-equilibrium systems and is\nespecially relevant to self-organising systems. The ensuing variational free\nenergy principle (FEP) has certain advantages over using random dynamical\nsystems explicitly, notably, by being more tractable and offering a\nparsimonious explanation of why the joint system evolves in the way that it\ndoes, based on the properties of the coupling between system components. Using\nthe FEP allows us to model the dynamics of an object as if it were a process of\nvariational inference, because variational free energy (or surprisal) is a\nLyapunov function for its dynamics. In short, we argue that using generative\nmodels to represent and track relations among subsystems leads us to a\nparticular statistical theory of interacting systems. Conversely, this theory\nenables us to construct nested models that respect the known relations among\nsubsystems. We point out that the fact that a physical object conforms to the\nFEP does not necessarily imply that this object performs inference in the\nliteral sense; rather, it is a useful explanatory fiction which replaces the\n`explicit' dynamics of the object with an `implicit' flow on free energy\ngradients -- a fiction that may or may not be entertained by the object itself.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 15:13:13 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 15:25:40 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Ramstead", "Maxwell J D", ""], ["Sakthivadivel", "Dalton A R", ""], ["Friston", "Karl J", ""]], "extracted_entities": [{"text": "generative models", "label": "AI model"}, {"text": "generative\nmodels", "label": "AI model"}], "human_readable_topic": "Generative AI and Variational Models"}
{"id": "2406.11667", "submitter": "Noah Golowich", "authors": "Constantinos Daskalakis and Noah Golowich", "title": "Is Efficient PAC Learning Possible with an Oracle That Responds 'Yes' or\n  'No'?", "comments": "COLT 2024", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical risk minimization (ERM) principle has been highly impactful in\nmachine learning, leading both to near-optimal theoretical guarantees for\nERM-based learning algorithms as well as driving many of the recent empirical\nsuccesses in deep learning. In this paper, we investigate the question of\nwhether the ability to perform ERM, which computes a hypothesis minimizing\nempirical risk on a given dataset, is necessary for efficient learning: in\nparticular, is there a weaker oracle than ERM which can nevertheless enable\nlearnability? We answer this question affirmatively, showing that in the\nrealizable setting of PAC learning for binary classification, a concept class\ncan be learned using an oracle which only returns a single bit indicating\nwhether a given dataset is realizable by some concept in the class. The sample\ncomplexity and oracle complexity of our algorithm depend polynomially on the VC\ndimension of the hypothesis class, thus showing that there is only a polynomial\nprice to pay for use of our weaker oracle. Our results extend to the agnostic\nlearning setting with a slight strengthening of the oracle, as well as to the\npartial concept, multiclass and real-valued learning settings. In the setting\nof partial concept classes, prior to our work no oracle-efficient algorithms\nwere known, even with a standard ERM oracle. Thus, our results address a\nquestion of Alon et al. (2021) who asked whether there are algorithmic\nprinciples which enable efficient learnability in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 15:50:08 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2024 04:18:17 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 02:38:04 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Golowich", "Noah", ""]], "extracted_entities": [{"text": "PAC learning", "label": "Few-shot Learning"}, {"text": "Alon et al.", "label": "ALBERT"}], "human_readable_topic": "Backdoor Attacks and Defenses in Deep Learning"}
{"id": "2406.12030", "submitter": "Yongting Zhang", "authors": "Yongting Zhang, Lu Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan\n  Fu, Zhenfei Yin, Senjie Jin, Yu Qiao, Xuanjing Huang, Feng Zhao, Tao Gui,\n  Jing Shao", "title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision\n  Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of Vision Language Models (VLMs) has brought unprecedented\nadvances in understanding multimodal information. The combination of textual\nand visual semantics in VLMs is highly complex and diverse, making the safety\nalignment of these models challenging. Furthermore, due to the limited study on\nthe safety alignment of VLMs, there is a lack of large-scale, high-quality\ndatasets. To address these limitations, we propose a Safety Preference\nAlignment dataset for Vision Language Models named SPA-VL. In terms of breadth,\nSPA-VL covers 6 harmfulness domains, 13 categories, and 53 subcategories, and\ncontains 100,788 samples of the quadruple (question, image, chosen response,\nrejected response). In terms of depth, the responses are collected from 12\nopen-source (e.g., QwenVL) and closed-source (e.g., Gemini) VLMs to ensure\ndiversity. The construction of preference data is fully automated, and the\nexperimental results indicate that models trained with alignment techniques on\nthe SPA-VL dataset exhibit substantial improvements in harmlessness and\nhelpfulness while maintaining core capabilities. SPA-VL, as a large-scale,\nhigh-quality, and diverse dataset, represents a significant milestone in\nensuring that VLMs achieve both harmlessness and helpfulness.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 18:57:37 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 04:18:50 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhang", "Yongting", ""], ["Chen", "Lu", ""], ["Zheng", "Guodong", ""], ["Gao", "Yifeng", ""], ["Zheng", "Rui", ""], ["Fu", "Jinlan", ""], ["Yin", "Zhenfei", ""], ["Jin", "Senjie", ""], ["Qiao", "Yu", ""], ["Huang", "Xuanjing", ""], ["Zhao", "Feng", ""], ["Gui", "Tao", ""], ["Shao", "Jing", ""]], "extracted_entities": [{"text": "Vision Language Models", "label": "Large Language Model"}, {"text": "VLMs", "label": "Large Language Model"}, {"text": "VLMs", "label": "Large Language Model"}, {"text": "VLMs", "label": "Large Language Model"}, {"text": "Vision Language Models", "label": "Large Language Model"}, {"text": "QwenVL", "label": "Open-source LLMs"}, {"text": "Gemini", "label": "Open-source LLMs"}, {"text": "VLMs", "label": "Large Language Model"}, {"text": "VLMs", "label": "Large Language Model"}], "human_readable_topic": "Vision Language Models (VLMs)"}
{"id": "2406.12120", "submitter": "Yulai Zhao", "authors": "Yulai Zhao, Masatoshi Uehara, Gabriele Scalia, Sunyuan Kung, Tommaso\n  Biancalani, Sergey Levine, Ehsan Hajiramezanali", "title": "Adding Conditional Control to Diffusion Models with Reinforcement\n  Learning", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diffusion models are powerful generative models that allow for precise\ncontrol over the characteristics of the generated samples. While these\ndiffusion models trained on large datasets have achieved success, there is\noften a need to introduce additional controls in downstream fine-tuning\nprocesses, treating these powerful models as pre-trained diffusion models. This\nwork presents a novel method based on reinforcement learning (RL) to add such\ncontrols using an offline dataset comprising inputs and labels. We formulate\nthis task as an RL problem, with the classifier learned from the offline\ndataset and the KL divergence against pre-trained models serving as the reward\nfunctions. Our method, $\\textbf{CTRL}$ ($\\textbf{C}$onditioning\npre-$\\textbf{T}$rained diffusion models with $\\textbf{R}$einforcement\n$\\textbf{L}$earning), produces soft-optimal policies that maximize the\nabovementioned reward functions. We formally demonstrate that our method\nenables sampling from the conditional distribution with additional controls\nduring inference. Our RL-based approach offers several advantages over existing\nmethods. Compared to classifier-free guidance, it improves sample efficiency\nand can greatly simplify dataset construction by leveraging conditional\nindependence between the inputs and additional controls. Additionally, unlike\nclassifier guidance, it eliminates the need to train classifiers from\nintermediate states to additional controls. The code is available at\nhttps://github.com/zhaoyl18/CTRL.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2024 22:00:26 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2025 04:08:17 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 02:16:23 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhao", "Yulai", ""], ["Uehara", "Masatoshi", ""], ["Scalia", "Gabriele", ""], ["Kung", "Sunyuan", ""], ["Biancalani", "Tommaso", ""], ["Levine", "Sergey", ""], ["Hajiramezanali", "Ehsan", ""]], "extracted_entities": [{"text": "Diffusion models", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "diffusion models", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "downstream fine-tuning\nprocesses", "label": "Fine-tuning"}, {"text": "diffusion models", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "reinforcement learning", "label": "Few-shot Learning"}], "human_readable_topic": "Offline-to-Online Reinforcement Learning"}
{"id": "2406.12221", "submitter": "Xueru Wen", "authors": "Xueru Wen, Jie Lou, Xinyu Lu, Ji Yuqiu, Xinyan Guan, Yaojie Lu, Hongyu\n  Lin, Ben He, Xianpei Han, Debing Zhang, Le Sun", "title": "On-Policy Self-Alignment with Fine-grained Knowledge Feedback for\n  Hallucination Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hallucination occurs when large language models exhibit behavior that\ndeviates from the boundaries of their knowledge during response generation. To\naddress this critical issue, previous learning-based methods attempt to\nfinetune models but are limited by off-policy sampling and coarse-grained\nfeedback. In this paper, we present \\textit{\\b{R}einforcement \\b{L}earning\n\\b{f}or \\b{H}allucination} (RLFH), an on-policy self-alignment approach that\nenables LLMs to actively explore their knowledge boundaries and self-correct\ngeneration behavior through fine-grained feedback signals. RLFH introduces a\nself-assessment framework where the policy serves as its own judge. Through\nthis framework, responses are automatically decomposed into atomic facts and\ntheir truthfulness and informativeness are assessed against external knowledge\nsources. The resulting fine-grained feedback at the statement level are then\nconverted into token-level dense reward signals. This enables online\nreinforcement learning to achieve precise and timely optimization without human\nintervention. Comprehensive evaluations on HotpotQA, SQuADv2, and Biography\nbenchmarks validate RLFH's effectiveness in hallucination mitigation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2024 02:43:49 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2025 05:20:32 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2025 11:00:17 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 06:05:45 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Wen", "Xueru", ""], ["Lou", "Jie", ""], ["Lu", "Xinyu", ""], ["Yuqiu", "Ji", ""], ["Guan", "Xinyan", ""], ["Lu", "Yaojie", ""], ["Lin", "Hongyu", ""], ["He", "Ben", ""], ["Han", "Xianpei", ""], ["Zhang", "Debing", ""], ["Sun", "Le", ""]], "extracted_entities": [{"text": "LLMs", "label": "LLM"}, {"text": "online\nreinforcement learning", "label": "Few-shot Learning"}], "human_readable_topic": "Self-Improvement Methods for Large Language Models"}
{"id": "2406.13474", "submitter": "Junhan Kim", "authors": "Junhan Kim, Ho-young Kim, Eulrang Cho, Chungman Lee, Joonyoung Kim,\n  Yongkweon Jeon", "title": "BoA: Attention-aware Post-training Quantization without Backpropagation", "comments": "19 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Post-training quantization (PTQ) is a promising solution for deploying large\nlanguage models (LLMs) on resource-constrained devices. Early methods developed\nfor smaller networks like ResNet rely on gradient-based optimization, which\nbecomes impractical for hyper-scale LLMs with billions of parameters. While\nrecently proposed backpropagation-free or transformation-based methods\nalleviate this issue, their performance remains limited by either a lack of\ninter-layer dependency consideration or the use of naive nearest-rounding-based\ninteger weight assignment to save the heavy computational cost of weight\noptimization. We thus introduce a novel backpropagation-free PTQ algorithm that\noptimizes integer weights by considering inter-layer dependencies. The key\ninnovation is the development of attention-aware Hessian matrices that capture\ninter-layer interactions within the attention module. Extensive experiments\ndemonstrate that our approach not only outperforms existing weight quantization\nmethods but also shows good synergy with conventional methods to suppress\nactivation outliers, leading to state-of-the-art weight-activation quantization\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2024 11:53:21 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 14:29:08 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Kim", "Junhan", ""], ["Kim", "Ho-young", ""], ["Cho", "Eulrang", ""], ["Lee", "Chungman", ""], ["Kim", "Joonyoung", ""], ["Jeon", "Yongkweon", ""]], "extracted_entities": [{"text": "Post-training quantization", "label": "quantisation"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "attention module", "label": "Attention mechanism"}], "human_readable_topic": "Quantization Techniques for Large Language Models"}
{"id": "2406.13489", "submitter": "Daniele Proverbio", "authors": "Uros Sutulovic, Daniele Proverbio, Rami Katz, Giulia Giordano", "title": "Efficient gPC-based quantification of probabilistic robustness for\n  systems in neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Robustness analysis is very important in biology and neuroscience, to unravel\nbehavioral patterns of systems that are conserved despite large parametric\nuncertainties. To make studies of probabilistic robustness more efficient and\nscalable in addressing complex neuroscience models, we propose an alternative\nto computationally expensive Monte Carlo (MC) methods by introducing and\nanalysing the generalised polynomial chaos (gPC) framework for uncertainty\nquantification. We consider both intrusive and non-intrusive gPC approaches,\nwhich turn out to be scalable and allow for a fast comprehensive exploration of\nparameter spaces. Focusing on widely used models of neural dynamics as case\nstudies, we explore the trade-off between efficiency and accuracy of gPC\nmethods, and we select effective computational settings to investigate\nparametric uncertainties in models that feature multiple dynamic regimes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2024 12:19:03 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:29:10 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Sutulovic", "Uros", ""], ["Proverbio", "Daniele", ""], ["Katz", "Rami", ""], ["Giordano", "Giulia", ""]], "extracted_entities": [{"text": "uncertainty\nquantification", "label": "quantisation"}], "human_readable_topic": "Neural Networks and Brain Computation Dynamics"}
{"id": "2406.13815", "submitter": "Alireza Aghelan", "authors": "Alireza Aghelan, Ali Amiryan, Abolfazl Zarghani, Modjtaba Rouhani", "title": "IG-CFAT: An Improved GAN-Based Framework for Effectively Exploiting\n  Transformers in Real-World Image Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of single image super-resolution (SISR), transformer-based\nmodels, have demonstrated significant advancements. However, the potential and\nefficiency of these models in applied fields such as real-world image\nsuper-resolution have been less noticed and there are substantial opportunities\nfor improvement. Recently, composite fusion attention transformer (CFAT),\noutperformed previous state-of-the-art (SOTA) models in classic image\nsuper-resolution. In this paper, we propose a novel GAN-based framework by\nincorporating the CFAT model to effectively exploit the performance of\ntransformers in real-world image super-resolution. In our proposed approach, we\nintegrate a semantic-aware discriminator to reconstruct fine details more\naccurately and employ an adaptive degradation model to better simulate\nreal-world degradations. Moreover, we introduce a new combination of loss\nfunctions by adding wavelet loss to loss functions of GAN-based models to\nbetter recover high-frequency details. Empirical results demonstrate that\nIG-CFAT significantly outperforms existing SOTA models in both quantitative and\nqualitative metrics. Our proposed model revolutionizes the field of real-world\nimage super-resolution and demonstrates substantially better performance in\nrecovering fine details and generating realistic textures. The introduction of\nIG-CFAT offers a robust and adaptable solution for real-world image\nsuper-resolution tasks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2024 20:21:26 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2024 20:50:09 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2024 17:31:53 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 17:52:38 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Aghelan", "Alireza", ""], ["Amiryan", "Ali", ""], ["Zarghani", "Abolfazl", ""], ["Rouhani", "Modjtaba", ""]], "extracted_entities": [{"text": "transformers", "label": "Transformers"}, {"text": "IG-CFAT", "label": "Transformer-based model"}, {"text": "IG-CFAT", "label": "Transformer-based model"}], "human_readable_topic": "Image Fusion with CNN and Transformer Networks"}
{"id": "2406.13930", "submitter": "Wentse Chen", "authors": "Wentse Chen, Shiyu Huang and Jeff Schneider", "title": "Soft-QMIX: Integrating Maximum Entropy For Monotonic Value Function\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent reinforcement learning (MARL) tasks often utilize a centralized\ntraining with decentralized execution (CTDE) framework. QMIX is a successful\nCTDE method that learns a credit assignment function to derive local value\nfunctions from a global value function, defining a deterministic local policy.\nHowever, QMIX is hindered by its poor exploration strategy. While maximum\nentropy reinforcement learning (RL) promotes better exploration through\nstochastic policies, QMIX's process of credit assignment conflicts with the\nmaximum entropy objective and the decentralized execution requirement, making\nit unsuitable for maximum entropy RL. In this paper, we propose an enhancement\nto QMIX by incorporating an additional local Q-value learning method within the\nmaximum entropy RL framework. Our approach constrains the local Q-value\nestimates to maintain the correct ordering of all actions. Due to the\nmonotonicity of the QMIX value function, these updates ensure that locally\noptimal actions align with globally optimal actions. We theoretically prove the\nmonotonic improvement and convergence of our method to an optimal solution.\nExperimentally, we validate our algorithm in matrix games, Multi-Agent Particle\nEnvironment and demonstrate state-of-the-art performance in SMAC-v2.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2024 01:55:08 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 17:16:36 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Chen", "Wentse", ""], ["Huang", "Shiyu", ""], ["Schneider", "Jeff", ""]], "extracted_entities": [{"text": "QMIX", "label": "AI model"}, {"text": "maximum\nentropy reinforcement learning", "label": "Few-shot Learning"}, {"text": "maximum entropy RL", "label": "Few-shot Learning"}], "human_readable_topic": "Offline-to-Online Reinforcement Learning"}
{"id": "2406.14115", "submitter": "Feng Jiang", "authors": "Ziche Liu, Rui Ke, Yajiao Liu, Feng Jiang, Haizhou Li", "title": "Take the essence and discard the dross: A Rethinking on Data Selection\n  for Fine-Tuning Large Language Models", "comments": "Accepted by the NAACL 2025 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data selection for fine-tuning large language models (LLMs) aims to choose a\nhigh-quality subset from existing datasets, allowing the trained model to\noutperform baselines trained on the full dataset. However, the expanding body\nof research lacks a clear, unified framework, and the variability in\nexperimental settings complicates systematic comparisons. While existing\nsurveys comprehensively overview the stages and methods of data selection, they\noften overlook an in-depth exploration of the fine-tuning phase. In this paper,\nwe conduct a focused review of recent data selection techniques for fine-tuning\nLLMs, analyzing a dozen key studies. We introduce a novel three-stage scheme -\ncomprising feature extraction, criteria design, and selector evaluation - to\nsystematically categorize and evaluate these methods. Additionally, we propose\na unified comparison approach that incorporates ratio-based efficiency and\nranking-based feasibility metrics to address inconsistencies across\nexperiments. Our findings reveal that methods emphasizing more targeted quality\nmeasurement achieve higher efficiency but at the cost of feasibility. Finally,\nwe discuss trends and highlight four key challenges in fine-tuning data\nselection, offering potential directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2024 08:58:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 07:59:00 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Liu", "Ziche", ""], ["Ke", "Rui", ""], ["Liu", "Yajiao", ""], ["Jiang", "Feng", ""], ["Li", "Haizhou", ""]], "extracted_entities": [{"text": "feature extraction", "label": "Fine-tuning"}, {"text": "criteria design", "label": "Fine-tuning"}, {"text": "selector evaluation", "label": "Fine-tuning"}, {"text": "ratio-based efficiency", "label": "Fine-tuning"}, {"text": "fine-tuning data\nselection", "label": "Fine-tuning"}], "human_readable_topic": "Parameter-Efficient Fine-Tuning for Large Language Models"}
{"id": "2406.14497", "submitter": "Zhiruo Wang", "authors": "Zora Zhiruo Wang, Akari Asai, Xinyan Velocity Yu, Frank F. Xu, Yiqing\n  Xie, Graham Neubig, Daniel Fried", "title": "CodeRAG-Bench: Can Retrieval Augment Code Generation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While language models (LMs) have proven remarkably adept at generating code,\nmany programs are challenging for LMs to generate using their parametric\nknowledge alone. Providing external contexts such as library documentation can\nfacilitate generating accurate and functional code. Despite the success of\nretrieval-augmented generation (RAG) in various text-oriented tasks, its\npotential for improving code generation remains under-explored. In this work,\nwe conduct a systematic, large-scale analysis by asking: in what scenarios can\nretrieval benefit code generation models? and what challenges remain? We first\ncurate a comprehensive evaluation benchmark, CodeRAG-Bench, encompassing three\ncategories of code generation tasks, including basic programming, open-domain,\nand repository-level problems. We aggregate documents from five sources for\nmodels to retrieve contexts: competition solutions, online tutorials, library\ndocumentation, StackOverflow posts, and GitHub repositories. We examine\ntop-performing models on CodeRAG-Bench by providing contexts retrieved from one\nor multiple sources. While notable gains are made in final code generation by\nretrieving high-quality contexts across various settings, our analysis reveals\nroom for improvement -- current retrievers still struggle to fetch useful\ncontexts especially with limited lexical overlap, and generators fail to\nimprove with limited context lengths or abilities to integrate additional\ncontexts. We hope CodeRAG-Bench serves as an effective testbed to encourage\nfurther development of advanced code-oriented RAG methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2024 16:59:52 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:10:36 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Wang", "Zora Zhiruo", ""], ["Asai", "Akari", ""], ["Yu", "Xinyan Velocity", ""], ["Xu", "Frank F.", ""], ["Xie", "Yiqing", ""], ["Neubig", "Graham", ""], ["Fried", "Daniel", ""]], "extracted_entities": [{"text": "RAG", "label": "RAG"}, {"text": "GitHub repositories", "label": "Open-source LLMs"}], "human_readable_topic": "Improving Code Generation with Large Language Models"}
{"id": "2406.15079", "submitter": "Darko Drakuli\\'c", "authors": "Darko Drakulic, Sofia Michel, Jean-Marc Andreoli", "title": "GOAL: A Generalist Combinatorial Optimization Agent Learner", "comments": "Accepted to ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning-based heuristics have recently shown impressive performance\nin solving a variety of hard combinatorial optimization problems (COPs).\nHowever, they generally rely on a separate neural model, specialized and\ntrained for each single problem. Any variation of a problem requires adjustment\nof its model and re-training from scratch. In this paper, we propose GOAL (for\nGeneralist combinatorial Optimization Agent Learner), a generalist model\ncapable of efficiently solving multiple COPs and which can be fine-tuned to\nsolve new COPs. GOAL consists of a single backbone plus light-weight\nproblem-specific adapters for input and output processing. The backbone is\nbased on a new form of mixed-attention blocks which allows to handle problems\ndefined on graphs with arbitrary combinations of node, edge and instance-level\nfeatures. Additionally, problems which involve heterogeneous types of nodes or\nedges are handled through a novel multi-type transformer architecture, where\nthe attention blocks are duplicated to attend the meaningful combinations of\ntypes while relying on the same shared parameters. We train GOAL on a set of\nrouting, scheduling and classic graph problems and show that it is only\nslightly inferior to the specialized baselines while being the first multi-task\nmodel that solves a wide range of COPs. Finally we showcase the strong transfer\nlearning capacity of GOAL by fine-tuning it on several new problems. Our code\nis available at https://github.com/naver/goal-co/.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2024 11:55:20 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2024 16:52:15 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 11:44:20 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Drakulic", "Darko", ""], ["Michel", "Sofia", ""], ["Andreoli", "Jean-Marc", ""]], "extracted_entities": [{"text": "GOAL", "label": "Neural Language Model"}, {"text": "GOAL", "label": "Neural Language Model"}, {"text": "mixed-attention blocks", "label": "Attention mechanism"}, {"text": "attention blocks", "label": "Attention mechanism"}, {"text": "GOAL", "label": "Neural Language Model"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2406.16361", "submitter": "Marlene Turner", "authors": "M. Turner, E. Walter, C. Amoedo, N. Torrado, N. Lopes, A. Sublet, M.\n  Bergamaschi, J. Pucek, J. Mezger, N. van Gils, L. Verra, G. Zevi Della Porta,\n  J. Farmer, A. Clairembaud, F. Pannell, E. Gschwendtner, and P. Muggli and the\n  AWAKE Collaboration", "title": "Experimental Observation of Motion of Ions in a Resonantly Driven Plasma\n  Wakefield Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.plasm-ph physics.acc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show experimentally that an effect of motion of ions, observed in a\nplasma-based accelerator, depends inversely on the plasma ion mass. The effect\nappears within a single wakefield event and manifests itself as a bunch tail,\noccurring only when sufficient motion of ions suppresses wakefields. Wakefields\nare driven resonantly by multiple bunches, and simulation results indicate that\nthe ponderomotive force causes the motion of ions. In this case, the effect is\nalso expected to depend on the amplitude of the wakefields, experimentally\nconfirmed through variations in the drive bunch charge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2024 07:06:40 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2024 14:08:06 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2025 16:10:34 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 16:22:19 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Turner", "M.", ""], ["Walter", "E.", ""], ["Amoedo", "C.", ""], ["Torrado", "N.", ""], ["Lopes", "N.", ""], ["Sublet", "A.", ""], ["Bergamaschi", "M.", ""], ["Pucek", "J.", ""], ["Mezger", "J.", ""], ["van Gils", "N.", ""], ["Verra", "L.", ""], ["Della Porta", "G. Zevi", ""], ["Farmer", "J.", ""], ["Clairembaud", "A.", ""], ["Pannell", "F.", ""], ["Gschwendtner", "E.", ""], ["Muggli", "P.", ""], ["Collaboration", "the AWAKE", ""]], "extracted_entities": [{"text": "Wakefields", "label": "LLMs"}], "human_readable_topic": "Particle Detection and Classification in High Energy Physics"}
{"id": "2406.16666", "submitter": "Jim Zhao", "authors": "Jim Zhao, Aurelien Lucchi, Nikita Doikov", "title": "Cubic regularized subspace Newton for non-convex optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the optimization problem of minimizing non-convex\ncontinuous functions, which is relevant in the context of high-dimensional\nmachine learning applications characterized by over-parametrization. We analyze\na randomized coordinate second-order method named SSCN which can be interpreted\nas applying cubic regularization in random subspaces. This approach effectively\nreduces the computational complexity associated with utilizing second-order\ninformation, rendering it applicable in higher-dimensional scenarios.\nTheoretically, we establish convergence guarantees for non-convex functions,\nwith interpolating rates for arbitrary subspace sizes and allowing inexact\ncurvature estimation. When increasing subspace size, our complexity matches\n$\\mathcal{O}(\\epsilon^{-3/2})$ of the cubic regularization (CR) rate.\nAdditionally, we propose an adaptive sampling scheme ensuring exact convergence\nrate of $\\mathcal{O}(\\epsilon^{-3/2}, \\epsilon^{-3})$ to a second-order\nstationary point, even without sampling all coordinates. Experimental results\ndemonstrate substantial speed-ups achieved by SSCN compared to conventional\nfirst-order methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2024 14:20:02 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 13:56:55 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhao", "Jim", ""], ["Lucchi", "Aurelien", ""], ["Doikov", "Nikita", ""]], "extracted_entities": [{"text": "over-parametrization", "label": "quantisation"}, {"text": "cubic regularization", "label": "quantisation"}], "human_readable_topic": "3D Point Cloud Processing and Learning"}
{"id": "2406.16759", "submitter": "Carlos Fern\\'andez", "authors": "Carlos Fern\\'andez and Stephan Cl\\'emen\\c{c}on", "title": "Anomaly Detection based on Markov Data: A Statistical Depth Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this article is to extend the notion of statistical depth to\nthe case of sample paths of a Markov chain. Initially introduced to define a\ncenter-outward ordering of points in the support of a multivariate\ndistribution, depth functions permit to generalize the notions of quantiles and\n(signed) ranks for observations in $\\mathbb{R}^d$ with $d>1$, as well as\nstatistical procedures based on such quantities. Here we develop a general\ntheoretical framework for evaluating the depth of a Markov sample path and\nrecovering it statistically from an estimate of its transition probability with\n(non-) asymptotic guarantees. We also detail some of its applications, focusing\nparticularly on unsupervised anomaly detection. Beyond the theoretical analysis\ncarried out, numerical experiments are displayed, providing empirical evidence\nof the relevance of the novel concept we introduce here to quantify the degree\nof abnormality of Markov paths of variable length.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2024 16:10:10 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2024 21:52:30 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2024 15:42:04 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2025 09:17:17 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Fern\u00e1ndez", "Carlos", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]], "extracted_entities": [{"text": "Markov chain", "label": "Chain of thought"}], "human_readable_topic": "Out-of-Distribution Detection Methods"}
{"id": "2406.16793", "submitter": "Yushun Zhang", "authors": "Yushun Zhang, Congliang Chen, Ziniu Li, Tian Ding, Chenwei Wu,\n  Diederik P. Kingma, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun", "title": "Adam-mini: Use Fewer Learning Rates To Gain More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Adam-mini, an optimizer that achieves on par or better performance\nthan AdamW with 50% less memory footprint. Adam-mini reduces memory by cutting\ndown the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). By investigating\nthe Hessian structure of neural nets, we find Adam's $v$ might not function at\nits full potential as effectively as we expected. We find that $\\geq$ 99.9% of\nthese learning rates in $v$ could be harmlessly removed if we (1) carefully\npartition the parameters into blocks following our new principle on Hessian\nstructure; (2) assign a single but good learning rate to each parameter block.\nWe then provide one simple way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 39M to 13B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama 2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2024 16:56:41 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2024 17:45:06 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2024 13:03:16 GMT"}, {"version": "v4", "created": "Mon, 1 Jul 2024 17:46:19 GMT"}, {"version": "v5", "created": "Wed, 3 Jul 2024 16:38:17 GMT"}, {"version": "v6", "created": "Mon, 11 Nov 2024 16:59:58 GMT"}, {"version": "v7", "created": "Mon, 24 Feb 2025 11:29:08 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhang", "Yushun", ""], ["Chen", "Congliang", ""], ["Li", "Ziniu", ""], ["Ding", "Tian", ""], ["Wu", "Chenwei", ""], ["Kingma", "Diederik P.", ""], ["Ye", "Yinyu", ""], ["Luo", "Zhi-Quan", ""], ["Sun", "Ruoyu", ""]], "extracted_entities": [{"text": "Adam-mini", "label": "ALBERT"}, {"text": "Adam-mini", "label": "ALBERT"}, {"text": "Hessian structure", "label": "BERT"}, {"text": "Hessian\nstructure", "label": "BERT"}, {"text": "Adam-mini", "label": "ALBERT"}, {"text": "Adam-mini", "label": "ALBERT"}, {"text": "AdamW", "label": "ALBERT"}, {"text": "pre-training", "label": "Few-shot Learning"}, {"text": "supervised fine-tuning", "label": "Fine-tuning"}, {"text": "Adam-mini", "label": "ALBERT"}, {"text": "Adam-mini", "label": "ALBERT"}, {"text": "AdamW", "label": "ALBERT"}, {"text": "Llama 2-7B", "label": "Llama"}], "human_readable_topic": "Optimizing GPU Utilization for Large Language Models"}
{"id": "2406.17619", "submitter": "Chunyin Siu", "authors": "Chunyin Siu", "title": "The Topological Behavior of Preferential Attachment Graphs", "comments": "30 pages, 5 figures, change in v2: fixed typos in bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the higher-order connectivity of scale-free networks using\nalgebraic topology. We model scale-free networks as preferential attachment\ngraphs, and we study the algebraic-topological properties of their clique\ncomplexes. We focus on the Betti numbers and the homotopy-connectedness of\nthese complexes. We determine the asymptotic almost sure orders of magnitude of\nthe Betti numbers. We also establish the occurence of homotopical phase\ntransitions for the infinite complexes, and we determine the critical\nthresholds at which the homotopy-connectivity changes. This partially verifies\nWeinberger's conjecture on the homotopy type of the infinite complexes. We\nconjecture that the mean-normalized Betti numbers converge to power-law\ndistributions, and we present numerical evidence. Our results also highlight\nthe subtlety of the scaling limit of topology, which arises from the tension\nbetween topological operations and analytical limiting process. We discuss such\ntension at the end of the Introduction.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2024 15:02:50 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 02:06:48 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Siu", "Chunyin", ""]], "extracted_entities": [{"text": "Betti numbers", "label": "BERT"}, {"text": "Betti numbers", "label": "BERT"}, {"text": "Betti numbers", "label": "BERT"}, {"text": "power-law\ndistributions", "label": "Scaling law"}], "human_readable_topic": "Scaling Laws in Large Language Models"}
{"id": "2406.17962", "submitter": "Bohao Yang", "authors": "Bohao Yang, Dong Liu, Chenghao Xiao, Kun Zhao, Chen Tang, Chao Li, Lin\n  Yuan, Guang Yang, Lanxiao Huang, Chenghua Lin", "title": "Crafting Customisable Characters with LLMs: Introducing SimsChat, a\n  Persona-Driven Role-Playing Agent Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Language Models (LLMs) demonstrate remarkable ability to comprehend\ninstructions and generate human-like text, enabling sophisticated agent\nsimulation beyond basic behavior replication. However, the potential for\ncreating freely customisable characters remains underexplored. We introduce the\nCustomisable Conversation Agent Framework, which employs LLMs to simulate\nreal-world characters through personalised characteristic feature injection,\nenabling diverse character creation according to user preferences. We propose\nthe SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn\nrole-playing dialogues across 1,360 real-world scenes. Characters are initially\ncustomised using pre-defined elements (career, aspiration, traits, skills),\nthen expanded through personal and social profiles. Building on this, we\npresent SimsChat, a freely customisable role-playing agent incorporating\nvarious realistic settings and topic-specified character interactions.\nExperimental results on both SimsConv and WikiRoleEval datasets demonstrate\nSimsChat's superior performance in maintaining character consistency, knowledge\naccuracy, and appropriate question rejection compared to existing models. Our\nframework provides valuable insights for developing more accurate and\ncustomisable human simulacra. Our data and code are publicly available at\nhttps://github.com/Bernard-Yang/SimsChat.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2024 22:44:17 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2024 21:15:47 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2024 08:48:26 GMT"}, {"version": "v4", "created": "Thu, 16 Jan 2025 15:47:58 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 16:30:21 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Yang", "Bohao", ""], ["Liu", "Dong", ""], ["Xiao", "Chenghao", ""], ["Zhao", "Kun", ""], ["Tang", "Chen", ""], ["Li", "Chao", ""], ["Yuan", "Lin", ""], ["Yang", "Guang", ""], ["Huang", "Lanxiao", ""], ["Lin", "Chenghua", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "SimsChat", "label": "ChatGPT"}, {"text": "SimsChat", "label": "ChatGPT"}, {"text": "SimsChat", "label": "Large Language Model"}], "human_readable_topic": "Role-Playing with Large Language Models"}
{"id": "2406.18696", "submitter": "Quan Mai", "authors": "Quan Mai, Susan Gauch, Douglas Adams, Miaoqing Huang", "title": "Sequence Graph Network for Online Debate Analysis", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online debates involve a dynamic exchange of ideas over time, where\nparticipants need to actively consider their opponents' arguments, respond with\ncounterarguments, reinforce their own points, and introduce more compelling\narguments as the discussion unfolds. Modeling such a complex process is not a\nsimple task, as it necessitates the incorporation of both sequential\ncharacteristics and the capability to capture interactions effectively. To\naddress this challenge, we employ a sequence-graph approach. Building the\nconversation as a graph allows us to effectively model interactions between\nparticipants through directed edges. Simultaneously, the propagation of\ninformation along these edges in a sequential manner enables us to capture a\nmore comprehensive representation of context. We also introduce a Sequence\nGraph Attention layer to illustrate the proposed information update scheme. The\nexperimental results show that sequence graph networks achieve superior results\nto existing methods in online debates.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2024 18:58:23 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 16:33:30 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Mai", "Quan", ""], ["Gauch", "Susan", ""], ["Adams", "Douglas", ""], ["Huang", "Miaoqing", ""]], "extracted_entities": [{"text": "Sequence\nGraph Attention layer", "label": "Attention mechanism"}], "human_readable_topic": "Multi-Agent Debate Frameworks"}
{"id": "2406.18849", "submitter": "Zhongqi Wang", "authors": "Jie Zhang, Zhongqi Wang, Mengqi Lei, Zheng Yuan, Bei Yan, Shiguang\n  Shan, Xilin Chen", "title": "Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception\n  Ability of LVLMs", "comments": "Accepted by ICLR2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Currently many benchmarks have been proposed to evaluate the perception\nability of the Large Vision-Language Models (LVLMs). However, most benchmarks\nconduct questions by selecting images from existing datasets, resulting in the\npotential data leakage. Besides, these benchmarks merely focus on evaluating\nLVLMs on the realistic style images and clean scenarios, leaving the\nmulti-stylized images and noisy scenarios unexplored. In response to these\nchallenges, we propose a dynamic and scalable benchmark named Dysca for\nevaluating LVLMs by leveraging synthesis images. Specifically, we leverage\nStable Diffusion and design a rule-based method to dynamically generate novel\nimages, questions and the corresponding answers. We consider 51 kinds of image\nstyles and evaluate the perception capability in 20 subtasks. Moreover, we\nconduct evaluations under 4 scenarios (i.e., Clean, Corruption, Print Attacking\nand Adversarial Attacking) and 3 question types (i.e., Multi-choices,\nTrue-or-false and Free-form). Thanks to the generative paradigm, Dysca serves\nas a scalable benchmark for easily adding new subtasks and scenarios. A total\nof 24 advanced open-source LVLMs and 2 close-source LVLMs are evaluated on\nDysca, revealing the drawbacks of current LVLMs. The benchmark is released at\nhttps://github.com/Robin-WZQ/Dysca.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2024 02:40:35 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2024 03:18:35 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2025 13:58:49 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 01:56:43 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhang", "Jie", ""], ["Wang", "Zhongqi", ""], ["Lei", "Mengqi", ""], ["Yuan", "Zheng", ""], ["Yan", "Bei", ""], ["Shan", "Shiguang", ""], ["Chen", "Xilin", ""]], "extracted_entities": [{"text": "Large Vision-Language Models", "label": "Large Language Model"}, {"text": "LVLMs", "label": "Large Language Model"}, {"text": "LVLMs", "label": "Large Language Model"}, {"text": "LVLMs", "label": "Large Language Model"}, {"text": "Stable Diffusion", "label": "Generative Pre-trained Transformer (GPT)"}, {"text": "LVLMs", "label": "Large Language Model"}, {"text": "LVLMs", "label": "Large Language Model"}, {"text": "LVLMs", "label": "Large Language Model"}], "human_readable_topic": "Adversarial Attacks on Vision Language Models"}
{"id": "2406.18962", "submitter": "Yixin Zhang", "authors": "Yixin Zhang and Xin Zhou and Qianwen Meng and Fanglin Zhu and Yonghui\n  Xu and Zhiqi Shen and Lizhen Cui", "title": "Multi-modal Food Recommendation using Clustering and Self-supervised\n  Learning", "comments": "Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Food recommendation systems serve as pivotal components in the realm of\ndigital lifestyle services, designed to assist users in discovering recipes and\nfood items that resonate with their unique dietary predilections. Typically,\nmulti-modal descriptions offer an exhaustive profile for each recipe, thereby\nensuring recommendations that are both personalized and accurate. Our\npreliminary investigation of two datasets indicates that pre-trained\nmulti-modal dense representations might precipitate a deterioration in\nperformance compared to ID features when encapsulating interactive\nrelationships. This observation implies that ID features possess a relative\nsuperiority in modeling interactive collaborative signals. Consequently,\ncontemporary cutting-edge methodologies augment ID features with multi-modal\ninformation as supplementary features, overlooking the latent semantic\nrelations between recipes. To rectify this, we present CLUSSL, a novel food\nrecommendation framework that employs clustering and self-supervised learning.\nSpecifically, CLUSSL formulates a modality-specific graph tailored to each\nmodality with discrete/continuous features, thereby transforming semantic\nfeatures into structural representation. Furthermore, CLUSSL procures recipe\nrepresentations pertinent to different modalities via graph convolutional\noperations. A self-supervised learning objective is proposed to foster\nindependence between recipe representations derived from different unimodal\ngraphs. Comprehensive experiments on real-world datasets substantiate that\nCLUSSL consistently surpasses state-of-the-art recommendation benchmarks in\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2024 07:45:17 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 09:41:12 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhang", "Yixin", ""], ["Zhou", "Xin", ""], ["Meng", "Qianwen", ""], ["Zhu", "Fanglin", ""], ["Xu", "Yonghui", ""], ["Shen", "Zhiqi", ""], ["Cui", "Lizhen", ""]], "extracted_entities": [{"text": "self-supervised learning", "label": "Few-shot Learning"}], "human_readable_topic": "Food Computing and Recipe Generation"}
{"id": "2406.19271", "submitter": "Praneeth Vadlapati", "authors": "Praneeth Vadlapati", "title": "AutoPureData: Automated Filtering of Undesirable Web Data to Update LLM\n  Knowledge", "comments": "Final version", "journal-ref": "Journal of Mathematical & Computer Applications, 3 (2024) E121", "doi": "10.47363/JMCA/2024(3)E121", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Up-to-date and reliable language models are consistently sought after and are\nessential in various applications. Typically, models are trained on a fixed\ndataset and then deployed globally. However, the knowledge of the models\nbecomes outdated. Enabling automatic updation of AI knowledge using web data\ninvolves significant concerns regarding the model's safety and quality due to a\nthreat from unsafe and undesirable text across the web. The purity of new data\nwas essential for updating knowledge of language models to maintain their\nreliability. This paper proposes AutoPureData, a system that automatically\ncollects and purifies web data. The system loaded a sample of web data.\nUtilizing existing trusted AI models, it successfully eliminated unsafe text\nwith an accuracy of 97% and undesirable text with an accuracy of 86%,\ndemonstrating the system's effectiveness in purifying the data. The system\nensures that only meaningful and safe text can be used to update LLM knowledge.\nThe pure text was then optimized and stored in a vector database for future\nquerying. It was found that LLM can fetch new data from the vector DB. The LLM\nwrites the RAG query in English, even if the user's query is in another\nlanguage, proving that the system can perform cross-lingual retrieval. This\npaper proposes a method to maintain the accuracy and relevance of up-to-date\nlanguage models by ensuring that only purified data was used to update LLM\nknowledge. This work contributes to updating knowledge of chatbots using\nmeaningful and safe text, enhancing their utility across various industries,\nand potentially reducing the risks associated with outputs caused by unsafe or\nimpure data. Code is available at github.com/Pro-GenAI/AutoPureData.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2024 15:37:57 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 07:17:52 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Vadlapati", "Praneeth", ""]], "extracted_entities": [{"text": "LLM", "label": "LLM"}, {"text": "LLM", "label": "LLM"}, {"text": "RAG", "label": "RAG"}, {"text": "chatbots", "label": "ChatGPT"}], "human_readable_topic": "Data Contamination in Large Language Models"}
{"id": "2406.19859", "submitter": "Zhi-Qi Cheng", "authors": "Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Qi He, Wangmeng\n  Xiang, Hanyuan Chen, Jin-Peng Lan, Xianhui Lin, Kang Zhu, Bin Luo, Yifeng\n  Geng, Xuansong Xie, Alexander G. Hauptmann", "title": "MetaDesigner: Advancing Artistic Typography Through AI-Driven,\n  User-Centric, and Multilingual WordArt Synthesis", "comments": "Accepted by ICLR 2025, Project:\n  https://modelscope.cn/studios/WordArt/WordArt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MetaDesigner introduces a transformative framework for artistic typography\nsynthesis, powered by Large Language Models (LLMs) and grounded in a\nuser-centric design paradigm. Its foundation is a multi-agent system comprising\nthe Pipeline, Glyph, and Texture agents, which collectively orchestrate the\ncreation of customizable WordArt, ranging from semantic enhancements to\nintricate textural elements. A central feedback mechanism leverages insights\nfrom both multimodal models and user evaluations, enabling iterative refinement\nof design parameters. Through this iterative process, MetaDesigner dynamically\nadjusts hyperparameters to align with user-defined stylistic and thematic\npreferences, consistently delivering WordArt that excels in visual quality and\ncontextual resonance. Empirical evaluations underscore the system's versatility\nand effectiveness across diverse WordArt applications, yielding outputs that\nare both aesthetically compelling and context-sensitive.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2024 11:58:26 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2024 15:47:40 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2025 20:28:02 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 08:36:29 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["He", "Jun-Yan", ""], ["Cheng", "Zhi-Qi", ""], ["Li", "Chenyang", ""], ["Sun", "Jingdong", ""], ["He", "Qi", ""], ["Xiang", "Wangmeng", ""], ["Chen", "Hanyuan", ""], ["Lan", "Jin-Peng", ""], ["Lin", "Xianhui", ""], ["Zhu", "Kang", ""], ["Luo", "Bin", ""], ["Geng", "Yifeng", ""], ["Xie", "Xuansong", ""], ["Hauptmann", "Alexander G.", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}], "human_readable_topic": "Assessing Creativity in Large Language Models"}
{"id": "2407.00047", "submitter": "Archit Patke", "authors": "Archit Patke, Dhemath Reddy, Saurabh Jha, Haoran Qiu, Christian Pinto,\n  Chandra Narayanaswami, Zbigniew Kalbarczyk, Ravishankar Iyer", "title": "Queue management for slo-oriented large language model serving", "comments": null, "journal-ref": null, "doi": "10.1145/3698038.369852", "report-no": null, "categories": "cs.DC cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large language model (LLM) serving is becoming an increasingly critical\nworkload for cloud providers. Existing LLM serving systems focus on interactive\nrequests, such as chatbots and coding assistants, with tight latency SLO\nrequirements. However, when such systems execute batch requests that have\nrelaxed SLOs along with interactive requests, it leads to poor multiplexing and\ninefficient resource utilization. To address these challenges, we propose QLM,\na queue management system for LLM serving. QLM maintains batch and interactive\nrequests across different models and SLOs in a request queue. Optimal ordering\nof the request queue is critical to maintain SLOs while ensuring high resource\nutilization. To generate this optimal ordering, QLM uses a Request Waiting Time\n(RWT) Estimator that estimates the waiting times for requests in the request\nqueue. These estimates are used by a global scheduler to orchestrate LLM\nServing Operations (LSOs) such as request pulling, request eviction, load\nbalancing, and model swapping. Evaluation on heterogeneous GPU devices and\nmodels with real-world LLM serving dataset shows that QLM improves SLO\nattainment by 40-90% and throughput by 20-400% while maintaining or improving\ndevice utilization compared to other state-of-the-art LLM serving systems.\nQLM's evaluation is based on the production requirements of a cloud provider.\nQLM is publicly available at https://www.github.com/QLM-project/QLM.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2024 21:17:34 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 17:54:13 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Patke", "Archit", ""], ["Reddy", "Dhemath", ""], ["Jha", "Saurabh", ""], ["Qiu", "Haoran", ""], ["Pinto", "Christian", ""], ["Narayanaswami", "Chandra", ""], ["Kalbarczyk", "Zbigniew", ""], ["Iyer", "Ravishankar", ""]], "extracted_entities": [{"text": "Large language model", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "chatbots", "label": "ChatGPT"}, {"text": "coding assistants", "label": "ChatGPT"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}], "human_readable_topic": "Optimizing GPU Utilization for Large Language Models"}
{"id": "2407.00075", "submitter": "Anton Xue", "authors": "Anton Xue, Avishree Khare, Rajeev Alur, Surbhi Goel, Eric Wong", "title": "Logicbreaks: A Framework for Understanding Subversion of Rule-based\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how to subvert large language models (LLMs) from following\nprompt-specified rules. We first formalize rule-following as inference in\npropositional Horn logic, a mathematical system in which rules have the form\n\"if $P$ and $Q$, then $R$\" for some propositions $P$, $Q$, and $R$. Next, we\nprove that although small transformers can faithfully follow such rules,\nmaliciously crafted prompts can still mislead both theoretical constructions\nand models learned from data. Furthermore, we demonstrate that popular attack\nalgorithms on LLMs find adversarial prompts and induce attention patterns that\nalign with our theory. Our novel logic-based framework provides a foundation\nfor studying LLMs in rule-based settings, enabling a formal analysis of tasks\nlike logical reasoning and jailbreak attacks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2024 19:18:16 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2024 20:42:41 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2025 19:08:08 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 17:49:33 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Xue", "Anton", ""], ["Khare", "Avishree", ""], ["Alur", "Rajeev", ""], ["Goel", "Surbhi", ""], ["Wong", "Eric", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "small transformers", "label": "Transformers"}, {"text": "maliciously crafted prompts", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompts", "label": "Prompting"}, {"text": "attention patterns", "label": "Attention mechanism"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Backdoor Attacks on Large Language Models"}
{"id": "2407.00468", "submitter": "Liang Chen", "authors": "Jinsheng Huang, Liang Chen, Taian Guo, Fu Zeng, Yusheng Zhao, Bohan\n  Wu, Ye Yuan, Haozhe Zhao, Zhihui Guo, Yichi Zhang, Jingyang Yuan, Wei Ju,\n  Luchen Liu, Tianyu Liu, Baobao Chang, Ming Zhang", "title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and\n  Efficient Evaluation", "comments": "18 pages, code released at https://github.com/chenllliang/MMEvalPro,\n  Homepage at https://mmevalpro.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large Multimodal Models (LMMs) exhibit impressive cross-modal understanding\nand reasoning abilities, often assessed through multiple-choice questions\n(MCQs) that include an image, a question, and several options. However, many\nbenchmarks used for such evaluations suffer from systematic biases. Remarkably,\nLarge Language Models (LLMs) without any visual perception capabilities achieve\nnon-trivial performance, undermining the credibility of these evaluations. To\naddress this issue while maintaining the efficiency of MCQ evaluations, we\npropose MMEvalPro, a benchmark designed to avoid Type-I errors through a\ntrilogy evaluation pipeline and more rigorous metrics. For each original\nquestion from existing benchmarks, human annotators augment it by creating one\nperception question and one knowledge anchor question through a meticulous\nannotation process. MMEvalPro comprises $2,138$ question triplets, totaling\n$6,414$ distinct questions. Two-thirds of these questions are manually labeled\nby human experts, while the rest are sourced from existing benchmarks (MMMU,\nScienceQA, and MathVista). Compared with the existing benchmarks, our\nexperiments with the latest LLMs and LMMs demonstrate that MMEvalPro is more\nchallenging (the best LMM lags behind human performance by $31.73\\%$, compared\nto an average gap of $8.03\\%$ in previous benchmarks) and more trustworthy (the\nbest LLM trails the best LMM by $23.09\\%$, whereas the gap for previous\nbenchmarks is just $14.64\\%$). Our in-depth analysis explains the reason for\nthe large performance gap and justifies the trustworthiness of evaluation,\nunderscoring its significant potential for advancing future research.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2024 15:28:45 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 15:10:56 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Huang", "Jinsheng", ""], ["Chen", "Liang", ""], ["Guo", "Taian", ""], ["Zeng", "Fu", ""], ["Zhao", "Yusheng", ""], ["Wu", "Bohan", ""], ["Yuan", "Ye", ""], ["Zhao", "Haozhe", ""], ["Guo", "Zhihui", ""], ["Zhang", "Yichi", ""], ["Yuan", "Jingyang", ""], ["Ju", "Wei", ""], ["Liu", "Luchen", ""], ["Liu", "Tianyu", ""], ["Chang", "Baobao", ""], ["Zhang", "Ming", ""]], "extracted_entities": [{"text": "Large Multimodal Models", "label": "Large Language Model"}, {"text": "LMMs", "label": "Large Language Model"}, {"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "ScienceQA", "label": "Open-source LLMs"}, {"text": "LMMs", "label": "Large Language Model"}], "human_readable_topic": "Evaluating Large Language Models on Multiple Choice Questions"}
{"id": "2407.00717", "submitter": "Xikun Zhang", "authors": "Xikun Zhang, Dongjin Song, Yushan Jiang, Yixin Chen, Dacheng Tao", "title": "Learning System Dynamics without Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observation-based trajectory prediction for systems with unknown dynamics is\nessential in fields such as physics and biology. Most existing approaches are\nlimited to learning within a single system with fixed dynamics patterns.\nHowever, many real-world applications require learning across systems with\nevolving dynamics patterns, a challenge that has been largely overlooked. To\naddress this, we systematically investigate the problem of Continual Dynamics\nLearning (CDL), examining task configurations and evaluating the applicability\nof existing techniques, while identifying key challenges. In response, we\npropose the Mode-switching Graph ODE (MS-GODE) model, which integrates the\nstrengths LG-ODE and sub-network learning with a mode-switching module,\nenabling efficient learning over varying dynamics. Moreover, we construct a\nnovel benchmark of biological dynamic systems for CDL, Bio-CDL, featuring\ndiverse systems with disparate dynamics and significantly enriching the\nresearch field of machine learning for dynamic systems. Our code available at\nhttps://github.com/QueuQ/MS-GODE.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2024 14:55:18 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 03:14:10 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Zhang", "Xikun", ""], ["Song", "Dongjin", ""], ["Jiang", "Yushan", ""], ["Chen", "Yixin", ""], ["Tao", "Dacheng", ""]], "extracted_entities": [{"text": "Continual Dynamics\nLearning", "label": "Few-shot Learning"}], "human_readable_topic": "Machine Learning for Complex Systems Modeling"}
{"id": "2407.01070", "submitter": "Tong Li", "authors": "Chang-Jie Dai, Tong Li, Rui-Jia Zhang", "title": "Dark Photon Dark Matter in Quantum Electromagnetodynamics and Detection\n  at Haloscope Experiments", "comments": "19 pages, 2 figures. version to be published in Chinese Physics C", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ultralight dark photon is one of intriguing dark matter candidates. The\ninteraction between the visible photon and dark photon is introduced by the\ngauge kinetic mixing between the field strength tensors of the Abelian gauge\ngroups in the Standard Model and dark sector. The relativistic electrodynamics\nwas generalized to quantum electromagnetodynamics (QEMD) in the presence of\nboth electric and magnetic charges. The photon is described by two\nfour-potentials corresponding to two $U(1)$ gauge groups and satisfying\nnon-trivial commutation relations. In this work, we construct the low-energy\ndark photon-photon interactions in the framework of QEMD and obtain new dark\nphoton-photon kinetic mixings. The consequent field equations and the new\nMaxwell's equations are derived in this framework. We also investigate the\ndetection strategies of dark photon as light dark matter as well as the generic\nkinetic mixings at haloscope experiments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2024 08:19:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 11:26:12 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Dai", "Chang-Jie", ""], ["Li", "Tong", ""], ["Zhang", "Rui-Jia", ""]], "extracted_entities": [{"text": "Standard Model", "label": "Foundation Model"}], "human_readable_topic": "Uncategorized"}
{"id": "2407.01309", "submitter": "Pierre Wang", "authors": "Pierre Wang and Christoph Kopper", "title": "Triviality proof for mean-field $\\varphi_4^4$-theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The differential equations of the Wilson renormalization group are a powerful\ntool to study the Schwinger functions of Euclidean quantum field theory. In\nparticular renormalization theory can be based entirely on inductively bounding\ntheir perturbatively expanded solutions. Recently the solutions of these\nequations for scalar field theory have been analysed rigorously without\nrecourse to perturbation theory, at the cost of restricting to the mean-field\napproximation. In particular it was shown there that one-component\n$\\varphi^4_4$-theory is trivial if the bare coupling constant of the UV\nregularized theory is not large. This paper presents progress w.r.t. Kopper's\nprevious paper on asymptotically free solutions of the mean-field scalar flow\nequations: 1. The upper bound on the bare coupling is sent to infinity and the\nproof is extended to $O(N)$ vector models. 2. The unphysical infrared cutoff\nused for technical simplicity is replaced by a physical mass.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2024 14:16:55 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2024 16:58:01 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 16:46:27 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Wang", "Pierre", ""], ["Kopper", "Christoph", ""]], "extracted_entities": [{"text": "renormalization theory", "label": "quantisation"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2407.01636", "submitter": "Zenglin Shi", "authors": "Jie Chu, Tong Su, Pei Liu, Yunpeng Wu, Le Zhang, Zenglin Shi, and Meng\n  Wang", "title": "Learning Dual Transformers for All-In-One Image Restoration from a\n  Frequency Perspective", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This work aims to tackle the all-in-one image restoration task, which seeks\nto handle multiple types of degradation with a single model. The primary\nchallenge is to extract degradation representations from the input degraded\nimages and use them to guide the model's adaptation to specific degradation\ntypes. Building on the insight that various degradations affect image content\ndifferently across frequency bands, we propose a new dual-transformer approach\ncomprising two components: a frequency-aware Degradation estimation transformer\n(Dformer) and a degradation-adaptive Restoration transformer (Rformer). The\nDformer captures the essential characteristics of various degradations by\ndecomposing the input into different frequency components. By understanding how\ndegradations affect these frequency components, the Dformer learns robust\npriors that effectively guide the restoration process. The Rformer then employs\na degradation-adaptive self-attention module to selectively focus on the most\naffected frequency components, guided by the learned degradation\nrepresentations. Extensive experimental results demonstrate that our approach\noutperforms existing methods in five representative restoration tasks,\nincluding denoising, deraining, dehazing, deblurring, and low-light\nenhancement. Additionally, our method offers benefits for handling, real-world\ndegradations, spatially variant degradations, and unseen degradation levels.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2024 13:14:44 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 01:27:49 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Chu", "Jie", ""], ["Su", "Tong", ""], ["Liu", "Pei", ""], ["Wu", "Yunpeng", ""], ["Zhang", "Le", ""], ["Shi", "Zenglin", ""], ["Wang", "Meng", ""]], "extracted_entities": [{"text": "degradation-adaptive self-attention module", "label": "Attention mechanism"}], "human_readable_topic": "Deep Learning with Transformers and Attention"}
{"id": "2407.02466", "submitter": "Ignat Georgiev", "authors": "Ignat Georgiev, Varun Giridhar, Nicklas Hansen and Animesh Garg", "title": "PWM: Policy Learning with Multi-Task World Models", "comments": "Visualizations and code available at https://www.imgeorgiev.com/pwm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) has made significant strides in complex tasks but\nstruggles in multi-task settings with different embodiments. World model\nmethods offer scalability by learning a simulation of the environment but often\nrely on inefficient gradient-free optimization methods for policy extraction.\nIn contrast, gradient-based methods exhibit lower variance but fail to handle\ndiscontinuities. Our work reveals that well-regularized world models can\ngenerate smoother optimization landscapes than the actual dynamics,\nfacilitating more effective first-order optimization. We introduce Policy\nlearning with multi-task World Models (PWM), a novel model-based RL algorithm\nfor continuous control. Initially, the world model is pre-trained on offline\ndata, and then policies are extracted from it using first-order optimization in\nless than 10 minutes per task. PWM effectively solves tasks with up to 152\naction dimensions and outperforms methods that use ground-truth dynamics.\nAdditionally, PWM scales to an 80-task setting, achieving up to 27% higher\nrewards than existing baselines without relying on costly online planning.\nVisualizations and code are available at https://www.imgeorgiev.com/pwm/.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2024 17:47:03 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2024 13:24:02 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 06:56:00 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Georgiev", "Ignat", ""], ["Giridhar", "Varun", ""], ["Hansen", "Nicklas", ""], ["Garg", "Animesh", ""]], "extracted_entities": [{"text": "Policy\nlearning", "label": "Few-shot Learning"}], "human_readable_topic": "Offline-to-Online Reinforcement Learning"}
{"id": "2407.02811", "submitter": "Meiyu Zhong", "authors": "Meiyu Zhong, Ravi Tandon", "title": "SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Certifiable robustness gives the guarantee that small perturbations around an\ninput to a classifier will not change the prediction. There are two approaches\nto provide certifiable robustness to adversarial examples: a) explicitly\ntraining classifiers with small Lipschitz constants, and b) Randomized\nsmoothing, which adds random noise to the input to create a smooth classifier.\nWe propose SPLITZ, a practical and novel approach which leverages the\nsynergistic benefits of both the above ideas into a single framework. Our main\nidea is to split a classifier into two halves, constrain the Lipschitz constant\nof the first half, and smooth the second half via randomization. Motivation for\nSPLITZ comes from the observation that many standard deep networks exhibit\nheterogeneity in Lipschitz constants across layers. SPLITZ can exploit this\nheterogeneity while inheriting the scalability of randomized smoothing. We\npresent a principled approach to train SPLITZ and provide theoretical analysis\nto derive certified robustness guarantees during inference. We present a\ncomprehensive comparison of robustness-accuracy trade-offs and show that SPLITZ\nconsistently improves on existing state-of-the-art approaches in the MNIST,\nCIFAR-10 and ImageNet datasets. For instance, with $\\ell_2$ norm perturbation\nbudget of $\\epsilon=1$, SPLITZ achieves $43.2\\%$ top-1 test accuracy on\nCIFAR-10 dataset compared to state-of-art top-1 test accuracy $39.8\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2024 05:13:28 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 05:01:02 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhong", "Meiyu", ""], ["Tandon", "Ravi", ""]], "extracted_entities": [{"text": "Randomized\nsmoothing", "label": "Few-shot Learning"}, {"text": "randomized smoothing", "label": "Few-shot Learning"}, {"text": "MNIST", "label": "Large Language Model"}], "human_readable_topic": "Adversarial Robustness in Deep Learning Models"}
{"id": "2407.02936", "submitter": "Zike Yuan", "authors": "Zike Yuan, Ming Liu, Hui Wang, Bing Qin", "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the graph comprehension and reasoning abilities of Large Language\nModels (LLMs) is challenging and often incomplete. Existing benchmarks focus\nprimarily on pure graph understanding, lacking a comprehensive evaluation\nacross all graph types and detailed capability definitions. This paper presents\nGraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and\nreasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and\ntest models on pure graph and heterogeneous graphs, subdividing capabilities\ninto 10 distinct areas tested through 19 tasks. Our benchmark includes 11\ndatasets with 5,140 graphs of varying complexity. We evaluate four\nclosed-source and eight open-source LLMs, conducting thorough analyses from\nboth ability and task perspectives. Key findings reveal that OpenAI o1 model\nhas amazing comprehension and reasoning capabilities, semantic enrichment\nenhances reasoning performance, node ordering impacts task success, and the\nability to process longer texts does not necessarily improve graph\ncomprehension or reasoning.GraCoRe is open-sourced at\nhttps://github.com/ZIKEYUAN/GraCoRe\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2024 09:12:38 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 09:17:32 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Yuan", "Zike", ""], ["Liu", "Ming", ""], ["Wang", "Hui", ""], ["Qin", "Bing", ""]], "extracted_entities": [{"text": "Large Language\nModels", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "semantic enrichment", "label": "Embedding"}], "human_readable_topic": "Reasoning Capabilities of Large Language Models"}
{"id": "2407.03312", "submitter": "Maike Holthuijzen", "authors": "Maike F. Holthuijzen, Robert B. Gramacy, Cayelan C. Carey, Dave M.\n  Higdon, R. Quinn Thomas", "title": "Synthesizing data products, mathematical models, and observational\n  measurements for lake temperature forecasting", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel forecasting framework for lake water temperature, which is\ncrucial for managing lake ecosystems and drinking water resources. The General\nLake Model (GLM) has been previously used for this purpose, but, similar to\nmany process-based simulation models, it: requires a large number of inputs,\nmany of which are stochastic; presents challenges for uncertainty\nquantification (UQ); and can exhibit model bias. To address these issues, we\npropose a Gaussian process (GP) surrogate-based forecasting approach that\nefficiently handles large, high-dimensional data and accounts for\ninput-dependent variability and systematic GLM bias. We validate the proposed\napproach and compare it with other forecasting methods, including a\nclimatological model and raw GLM simulations. Our results demonstrate that our\nbias-corrected GP surrogate (GPBC) can outperform competing approaches in terms\nof forecast accuracy and UQ up to two weeks into the future.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2024 17:54:57 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2024 17:26:55 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 15:58:48 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Holthuijzen", "Maike F.", ""], ["Gramacy", "Robert B.", ""], ["Carey", "Cayelan C.", ""], ["Higdon", "Dave M.", ""], ["Thomas", "R. Quinn", ""]], "extracted_entities": [{"text": "uncertainty\nquantification (UQ)", "label": "quantisation"}], "human_readable_topic": "Time Series Forecasting with Deep Learning Models"}
{"id": "2407.04916", "submitter": "Tianling Liu", "authors": "Tianling Liu and Hongying Liu and Fanhua Shang and Lequan Yu and Tong\n  Han and Liang Wan", "title": "Completed Feature Disentanglement Learning for Multimodal MRIs Analysis", "comments": "Accept by IEEE JBHI 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal MRIs play a crucial role in clinical diagnosis and treatment.\nFeature disentanglement (FD)-based methods, aiming at learning superior feature\nrepresentations for multimodal data analysis, have achieved significant success\nin multimodal learning (MML). Typically, existing FD-based methods separate\nmultimodal data into modality-shared and modality-specific features, and employ\nconcatenation or attention mechanisms to integrate these features. However, our\npreliminary experiments indicate that these methods could lead to a loss of\nshared information among subsets of modalities when the inputs contain more\nthan two modalities, and such information is critical for prediction accuracy.\nFurthermore, these methods do not adequately interpret the relationships\nbetween the decoupled features at the fusion stage. To address these\nlimitations, we propose a novel Complete Feature Disentanglement (CFD) strategy\nthat recovers the lost information during feature decoupling. Specifically, the\nCFD strategy not only identifies modality-shared and modality-specific\nfeatures, but also decouples shared features among subsets of multimodal\ninputs, termed as modality-partial-shared features. We further introduce a new\nDynamic Mixture-of-Experts Fusion (DMF) module that dynamically integrates\nthese decoupled features, by explicitly learning the local-global relationships\namong the features. The effectiveness of our approach is validated through\nclassification tasks on three multimodal MRI datasets. Extensive experimental\nresults demonstrate that our approach outperforms other state-of-the-art MML\nmethods with obvious margins, showcasing its superior performance.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2024 01:49:38 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 04:49:25 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liu", "Tianling", ""], ["Liu", "Hongying", ""], ["Shang", "Fanhua", ""], ["Yu", "Lequan", ""], ["Han", "Tong", ""], ["Wan", "Liang", ""]], "extracted_entities": [{"text": "attention mechanisms", "label": "Attention mechanism"}], "human_readable_topic": "Multimodal Learning for Medical Prediction"}
{"id": "2407.06172", "submitter": "Jin Peng Zhou", "authors": "Jin Peng Zhou, Christian K. Belardi, Ruihan Wu, Travis Zhang, Carla P.\n  Gomes, Wen Sun, Kilian Q. Weinberger", "title": "On Speeding Up Language Model Evaluation", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing prompt-based methods with Large Language Models (LLMs) requires\nmaking numerous decisions, which give rise to a combinatorial search problem\nover hyper-parameters. This exhaustive evaluation can be time-consuming and\ncostly. In this paper, we propose an $\\textit{adaptive}$ approach to explore\nthis space. We are exploiting the fact that often only few samples are needed\nto identify clearly superior or inferior settings, and that many evaluation\ntests are highly correlated. We lean on multi-armed bandits to sequentially\nidentify the next (method, validation sample)-pair to evaluate and utilize\nlow-rank matrix factorization to fill in missing evaluations. We carefully\nassess the efficacy of our approach on several competitive benchmark problems\nand show that it can identify the top-performing method using only 5-15% of the\ntypical resources -- resulting in 85-95% LLM cost savings. Our code is\navailable at https://github.com/kilian-group/banditeval.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2024 17:48:42 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2024 22:31:35 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 21:53:59 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhou", "Jin Peng", ""], ["Belardi", "Christian K.", ""], ["Wu", "Ruihan", ""], ["Zhang", "Travis", ""], ["Gomes", "Carla P.", ""], ["Sun", "Wen", ""], ["Weinberger", "Kilian Q.", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}], "human_readable_topic": "Large Language Model Evaluation Benchmarks"}
{"id": "2407.06723", "submitter": "Yu-Guan Hsieh", "authors": "Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis B\\'ethune, Hadi\n  Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel\n  Tuzel, Marco Cuturi", "title": "Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting\n  Region Captions", "comments": "59 pages, 42 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans describe complex scenes with compositionality, using simple text\ndescriptions enriched with links and relationships. While vision-language\nresearch has aimed to develop models with compositional understanding\ncapabilities, this is not reflected yet in existing datasets which, for the\nmost part, still use plain text to describe images. In this work, we propose a\nnew annotation strategy, graph-based captioning (GBC) that describes an image\nusing a labeled graph structure, with nodes of various types. The nodes in GBC\nare created through a two-stage process: first, identifying and describing\nentity nodes; second, linking these nodes by highlighting \\textit{compositions}\nand \\textit{relations} among them. Since \\textit{all} GBC nodes hold plain text\ndescriptions, GBC retains the flexibility found in natural language, but can\nalso encode hierarchical information in its edges. We demonstrate that GBC can\nbe produced automatically, using off-the-shelf multimodal LLMs and object\ndetection models, by building a new dataset GBC10M that gathers GBC annotations\nfor about 10M images of the CC12M dataset. Through CLIP training on GBC10M, we\nshow that leveraging GBC nodes' annotations -- particularly those in\ncomposition and relation nodes -- significantly boosts the model's performance\nacross various benchmarks compared to when other annotations are used. To\nfurther explore the opportunities provided by GBC, we also investigate the use\nof GBC as middleware for text-to-image generation, and show the extra benefits\nof incorporating the graph structure in this task. Our code and datasets are\nreleased at https://github.com/apple/ml-gbc and\nhttps://huggingface.co/graph-based-captions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2024 09:55:04 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 22:54:53 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Hsieh", "Yu-Guan", ""], ["Hsieh", "Cheng-Yu", ""], ["Yeh", "Shih-Ying", ""], ["B\u00e9thune", "Louis", ""], ["Ansari", "Hadi Pour", ""], ["Vasu", "Pavan Kumar Anasosalu", ""], ["Li", "Chun-Liang", ""], ["Krishna", "Ranjay", ""], ["Tuzel", "Oncel", ""], ["Cuturi", "Marco", ""]], "extracted_entities": [{"text": "multimodal LLMs", "label": "LLMs"}], "human_readable_topic": "Multimodal Image Captioning Models"}
{"id": "2407.06894", "submitter": "Chaorong Zhang", "authors": "Chaorong Zhang, Hui Xu, Benjamin K. Ng, Chan-Tong Lam, Ke Wang", "title": "RIS-Assisted Received Adaptive Spatial Modulation for Wireless\n  Communications", "comments": "This manuscript has been accepted by IEEE Wireless Communications and\n  Networking Conference (WCNC) 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel wireless transmission scheme, as named the reconfigurable intelligent\nsurface (RIS)-assisted received adaptive spatial modulation (RASM) scheme, is\nproposed in this paper. In this scheme, the adaptive spatial modulation\n(ASM)-based antennas selection works at the receiver by employing the\ncharacteristics of the RIS in each time slot, where the signal-to-noise ratio\nat specific selected antennas can be further enhanced with near few powers.\nBesides for the bits from constellation symbols, the extra bits can be mapped\ninto the indices of receive antenna combinations and conveyed to the receiver\nthrough the ASM-based antenna-combination selection, thus providing higher\nspectral efficiency. To explicitly present the RASM scheme, the analytical\nperformance of bit error rate of it is discussed in this paper. As a trade-off\nselection, the proposed scheme shows higher spectral efficiency and remains the\nsatisfactory error performance. Simulation and analytical results demonstrate\nthe better performance and exhibit more potential to apply in practical\nwireless communication.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2024 14:25:47 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2024 06:20:07 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2024 04:10:23 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2025 16:30:01 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2025 03:19:16 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Zhang", "Chaorong", ""], ["Xu", "Hui", ""], ["Ng", "Benjamin K.", ""], ["Lam", "Chan-Tong", ""], ["Wang", "Ke", ""]], "extracted_entities": [{"text": "near few powers", "label": "LLM-powered"}], "human_readable_topic": "Massive MIMO Channel Prediction and Reconstruction"}
{"id": "2407.07064", "submitter": "Nicolas E. Diaz Ferreyra PhD", "authors": "Catherine Tony, Nicol\\'as E. D\\'iaz Ferreyra, Markus Mutas, Salem\n  Dhiff and Riccardo Scandariato", "title": "Prompting Techniques for Secure Code Generation: A Systematic\n  Investigation", "comments": "Work partially supported by the EU-funded project Sec4AI4Sec:\n  Cybersecurity for AI-Augmented Systems (grant no. 101120393) - ACCEPTED at\n  ACM Transactions on Software Engineering and Methodology (Feb. 2025)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large Language Models (LLMs) are gaining momentum in software development\nwith prompt-driven programming enabling developers to create code from natural\nlanguage (NL) instructions. However, studies have questioned their ability to\nproduce secure code and, thereby, the quality of prompt-generated software.\nAlongside, various prompting techniques that carefully tailor prompts have\nemerged to elicit optimal responses from LLMs. Still, the interplay between\nsuch prompting strategies and secure code generation remains under-explored and\ncalls for further investigations. OBJECTIVE: In this study, we investigate the\nimpact of different prompting techniques on the security of code generated from\nNL instructions by LLMs. METHOD: First we perform a systematic literature\nreview to identify the existing prompting techniques that can be used for code\ngeneration tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,\nand GPT-4 models for secure code generation. For this, we used an existing\ndataset consisting of 150 NL security-relevant code-generation prompts.\nRESULTS: Our work (i) classifies potential prompting techniques for code\ngeneration (ii) adapts and evaluates a subset of the identified techniques for\nsecure code generation tasks and (iii) observes a reduction in security\nweaknesses across the tested LLMs, especially after using an existing technique\ncalled Recursive Criticism and Improvement (RCI), contributing valuable\ninsights to the ongoing discourse on LLM-generated code security.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2024 17:38:03 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 14:28:11 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Tony", "Catherine", ""], ["Ferreyra", "Nicol\u00e1s E. D\u00edaz", ""], ["Mutas", "Markus", ""], ["Dhiff", "Salem", ""], ["Scandariato", "Riccardo", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "prompting techniques", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompting techniques", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompting techniques", "label": "Prompting"}, {"text": "GPT-3", "label": "GPT"}, {"text": "GPT-3", "label": "GPT"}, {"text": "GPT-4", "label": "GPT"}, {"text": "prompting techniques", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Improving Code Generation with Large Language Models"}
{"id": "2407.07310", "submitter": "Jayanth Bhargav", "authors": "Jayanth Bhargav, Mahsa Ghasemi and Shreyas Sundaram", "title": "Optimal Sensor and Actuator Selection for Factored Markov Decision\n  Processes: Complexity, Approximability and Algorithms", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CC cs.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Factored Markov Decision Processes (fMDPs) are a class of Markov Decision\nProcesses (MDPs) in which the states (and actions) can be factored into a set\nof state (and action) variables and can be encoded compactly using a factored\nrepresentation. In this paper, we consider a setting where the state of the\nfMDP is not directly observable, and the agent relies on a set of potential\nsensors to gather information. Each sensor has a selection cost and the\ndesigner must select a subset of sensors under a limited budget. We formulate\nthe problem of selecting a set of sensors for fMDPs (under a budget) to\nmaximize the infinite-horizon discounted return provided by the optimal policy.\nWe show the fundamental result that it is NP-hard to approximate this problem\nto within any non-trivial factor. Our inapproximability results for optimal\nsensor selection also extend to a general class of Partially Observable MDPs\n(POMDPs). We then study the dual problem of budgeted actuator selection (at\ndesign-time) to maximize the expected return under the optimal policy. Again,\nwe show that it is NP-hard to approximate this problem to within any\nnon-trivial factor. Furthermore, with explicit examples, we show the failure of\ngreedy algorithms for both the sensor and actuator selection problems and\nprovide insights into the factors that cause these problems to be challenging.\nDespite this, through extensive simulations, we show the practical\neffectiveness and near-optimal performance of the greedy algorithm for actuator\nand sensor selection in many real-world and randomly generated instances.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2024 02:09:51 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 16:14:58 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Bhargav", "Jayanth", ""], ["Ghasemi", "Mahsa", ""], ["Sundaram", "Shreyas", ""]], "extracted_entities": [{"text": "Factored Markov Decision Processes", "label": "LLMs"}, {"text": "fMDPs", "label": "LLMs"}], "human_readable_topic": "Large Language Models for Planning Tasks"}
{"id": "2407.08056", "submitter": "Nikolaos Dimitriadis", "authors": "Nikolaos Dimitriadis, Pascal Frossard, Francois Fleuret", "title": "Pareto Low-Rank Adapters: Efficient Multi-Task Learning with Preferences", "comments": "Accepted at ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task trade-offs in machine learning can be addressed via Pareto Front\nLearning (PFL) methods that parameterize the Pareto Front (PF) with a single\nmodel. PFL permits to select the desired operational point during inference,\ncontrary to traditional Multi-Task Learning (MTL) that optimizes for a single\ntrade-off decided prior to training. However, recent PFL methodologies suffer\nfrom limited scalability, slow convergence, and excessive memory requirements,\nwhile exhibiting inconsistent mappings from preference to objective space. We\nintroduce PaLoRA, a novel parameter-efficient method that addresses these\nlimitations in two ways. First, we augment any neural network architecture with\ntask-specific low-rank adapters and continuously parameterize the PF in their\nconvex hull. Our approach steers the original model and the adapters towards\nlearning general and task-specific features, respectively. Second, we propose a\ndeterministic sampling schedule of preference vectors that reinforces this\ndivision of labor, enabling faster convergence and strengthening the validity\nof the mapping from preference to objective space throughout training. Our\nexperiments show that PaLoRA outperforms state-of-the-art MTL and PFL baselines\nacross various datasets, scales to large networks, reducing the memory overhead\n$23.8-31.7$ times compared with competing PFL baselines in scene understanding\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2024 21:25:51 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 17:56:57 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Dimitriadis", "Nikolaos", ""], ["Frossard", "Pascal", ""], ["Fleuret", "Francois", ""]], "extracted_entities": [{"text": "Pareto Front\nLearning", "label": "Few-shot Learning"}, {"text": "PFL", "label": "Few-shot Learning"}, {"text": "Multi-Task Learning", "label": "Few-shot Learning"}, {"text": "PFL", "label": "Few-shot Learning"}, {"text": "task-specific low-rank adapters", "label": "Transformers"}], "human_readable_topic": "Parameter-Efficient Transfer Learning and Pre-Training"}
{"id": "2407.08410", "submitter": "Robbie Holland", "authors": "Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl,\n  Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip\n  M\\\"uller, Hendrik P. N. Scholl, Hrvoje Bogunovi\\'c, Ursula Schmidt-Erfurth,\n  Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten (on\n  behalf of the PINNACLE consortium)", "title": "Specialized curricula for training vision-language models in retinal\n  image analysis", "comments": "Under review at npj Digital Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinicians spend a significant amount of time reviewing medical images and\ntranscribing their findings regarding patient diagnosis, referral and treatment\nin text form. Vision-language models (VLMs), which automatically interpret\nimages and summarize their findings as text, have enormous potential to\nalleviate clinical workloads and increase patient access to high-quality\nmedical care. While foundational models have stirred considerable interest in\nthe medical community, it is unclear whether their general capabilities\ntranslate to real-world clinical utility. In this work, we demonstrate that\nOpenAI's ChatGPT-4o model, in addition to two foundation VLMs designed for\nmedical use, markedly underperform compared to practicing ophthalmologists on\nspecialist tasks crucial to the care of patients with age-related macular\ndegeneration (AMD). To address this, we initially identified the essential\ncapabilities required for image-based clinical decision-making, and then\ndeveloped a curriculum to selectively train VLMs in these skills. The resulting\nmodel, RetinaVLM, can be instructed to write reports that significantly\noutperform those written by leading foundation medical VLMs and ChatGPT-4o in\ndisease staging (F1 score of 0.63 vs. 0.33) and patient referral (0.67 vs.\n0.50), and approaches the diagnostic performance of junior ophthalmologists\n(who achieve 0.77 and 0.78 on the respective tasks). Furthermore, in a\nsingle-blind reader study two senior ophthalmologists with up to 32 years of\nexperience found RetinaVLM's reports were found to be substantially more\naccurate than those by ChatGPT-4o (64.3% vs. 14.3%). These results reinforce\nthat our curriculum-based approach provides a blueprint towards specializing\nfoundation medical VLMs for real-world clinical tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2024 11:31:48 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 01:54:59 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Holland", "Robbie", "", "on\n  behalf of the PINNACLE consortium"], ["Taylor", "Thomas R. P.", "", "on\n  behalf of the PINNACLE consortium"], ["Holmes", "Christopher", "", "on\n  behalf of the PINNACLE consortium"], ["Riedl", "Sophie", "", "on\n  behalf of the PINNACLE consortium"], ["Mai", "Julia", "", "on\n  behalf of the PINNACLE consortium"], ["Patsiamanidi", "Maria", "", "on\n  behalf of the PINNACLE consortium"], ["Mitsopoulou", "Dimitra", "", "on\n  behalf of the PINNACLE consortium"], ["Hager", "Paul", "", "on\n  behalf of the PINNACLE consortium"], ["M\u00fcller", "Philip", "", "on\n  behalf of the PINNACLE consortium"], ["Scholl", "Hendrik P. N.", "", "on\n  behalf of the PINNACLE consortium"], ["Bogunovi\u0107", "Hrvoje", "", "on\n  behalf of the PINNACLE consortium"], ["Schmidt-Erfurth", "Ursula", "", "on\n  behalf of the PINNACLE consortium"], ["Rueckert", "Daniel", "", "on\n  behalf of the PINNACLE consortium"], ["Sivaprasad", "Sobha", "", "on\n  behalf of the PINNACLE consortium"], ["Lotery", "Andrew J.", "", "on\n  behalf of the PINNACLE consortium"], ["Menten", "Martin J.", "", "on\n  behalf of the PINNACLE consortium"]], "extracted_entities": [{"text": "OpenAI", "label": "Open-source LLMs"}, {"text": "ChatGPT-4o", "label": "ChatGPT"}, {"text": "RetinaVLM", "label": "Foundation Model"}, {"text": "ChatGPT-4o", "label": "ChatGPT"}, {"text": "RetinaVLM", "label": "Foundation Model"}, {"text": "ChatGPT-4o", "label": "ChatGPT"}], "human_readable_topic": "Vision Language Models (VLMs)"}
{"id": "2407.09774", "submitter": "Sixiao Zheng", "authors": "Sixiao Zheng, Yanwei Fu", "title": "ContextualStory: Consistent Visual Storytelling with Spatially-Enhanced\n  and Storyline Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual storytelling involves generating a sequence of coherent frames from a\ntextual storyline while maintaining consistency in characters and scenes.\nExisting autoregressive methods, which rely on previous frame-sentence pairs,\nstruggle with high memory usage, slow generation speeds, and limited context\nintegration. To address these issues, we propose ContextualStory, a novel\nframework designed to generate coherent story frames and extend frames for\nvisual storytelling. ContextualStory utilizes Spatially-Enhanced Temporal\nAttention to capture spatial and temporal dependencies, handling significant\ncharacter movements effectively. Additionally, we introduce a Storyline\nContextualizer to enrich context in storyline embedding, and a StoryFlow\nAdapter to measure scene changes between frames for guiding the model.\nExtensive experiments on PororoSV and FlintstonesSV datasets demonstrate that\nContextualStory significantly outperforms existing SOTA methods in both story\nvisualization and continuation. Code is available at\nhttps://github.com/sixiaozheng/ContextualStory.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2024 05:02:42 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2024 14:17:31 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 14:02:08 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zheng", "Sixiao", ""], ["Fu", "Yanwei", ""]], "extracted_entities": [{"text": "ContextualStory", "label": "contextual Embedding"}, {"text": "ContextualStory", "label": "contextual Embedding"}, {"text": "Spatially-Enhanced Temporal\nAttention", "label": "Attention mechanism"}, {"text": "Storyline\nContextualizer", "label": "contextual Embedding"}, {"text": "storyline embedding", "label": "Embedding"}, {"text": "ContextualStory", "label": "contextual Embedding"}, {"text": "ContextualStory", "label": "contextual Embedding"}], "human_readable_topic": "Text-to-Motion Generation and Animation"}
{"id": "2407.10059", "submitter": "Bin Zhou", "authors": "Bin Zhou and Jun Gao", "title": "The impact of data from future lepton colliders on light hadrons\n  fragmentation functions", "comments": "32 pages, 10 figures, 2 tables. Code is available at\n  https://fmnlo.sjtu.edu.cn/~fmnlo/. version accepted for publication in JHEP", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the constraining power of future lepton colliders on\nfragmentation functions (FFs) to light charged hadrons from quarks and gluon in\nthe framework of QCD collinear factorization. We perform analyses of FFs at NLO\nby including a wide range of pseudo--data from future lepton colliders, such as\nmeasurements on hadron multiplicities in the production of two jets and $W$\nboson pairs, at various center of mass energies, and from hadronic decays of\nthe Higgs boson, including both to heavy quarks and to gluons. The high\nluminosity and high energies of future lepton colliders allow for quark flavor\nseparations and ensure a precise determination of FFs based solely on data from\nelectron-positron collisions. We find that either the CEPC, FCC-$ee$ or ILC can\nsignificantly reduce the uncertainties of FFs in a wide kinematic range,\ncompared to the NPC23 set obtained with a global analysis to current world\ndata. We also discuss the impact of higher-order QCD corrections, and the\npotential constraints from measurements of three-jet production. Furthermore,\nwe describe an update of the FMNLO program allowing for calculating hadron\nproduction cross sections at next-to-next-to-leading order in QCD, which is\nused in this study.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2024 03:11:26 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 09:15:47 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Zhou", "Bin", ""], ["Gao", "Jun", ""]], "extracted_entities": [{"text": "FFs", "label": "LLMs"}, {"text": "FFs", "label": "LLMs"}, {"text": "FFs", "label": "LLMs"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2407.10099", "submitter": "Yang Liu", "authors": "Yang Liu and Zhiyong Zhang", "title": "STGFormer: Spatio-Temporal GraphFormer for 3D Human Pose Estimation in\n  Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current methods of video-based 3D human pose estimation have achieved\nsignificant progress.However, they still face pressing challenges, such as the\nunderutilization of spatiotemporal bodystructure features in transformers and\nthe inadequate granularity of spatiotemporal interaction modeling in graph\nconvolutional networks, which leads to pervasive depth ambiguity in monocular\n3D human pose estimation. To address these limitations, this paper presents the\nSpatio-Temporal GraphFormer framework (STGFormer) for 3D human pose estimation\nin videos. First, we introduce a Spatio-Temporal criss-cross Graph (STG)\nattention mechanism, designed to more effectively leverage the inherent graph\npriors of the human body within continuous sequence distributions while\ncapturing spatiotemporal long-range dependencies. Next, we present a dual-path\nModulated Hop-wise Regular GCN (MHR-GCN) to independently process temporal and\nspatial dimensions in parallel, preserving features rich in temporal dynamics\nand the original or high-dimensional representations of spatial structures.\nFurthermore, the module leverages modulation to optimize parameter efficiency\nand incorporates spatiotemporal hop-wise skip connections to capture\nhigher-order information. Finally, we demonstrate that our method achieves\nstate-of-the-art performance on the Human3.6M and MPIINF-3DHP datasets.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2024 06:45:27 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 07:56:48 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Zhiyong", ""]], "extracted_entities": [{"text": "transformers", "label": "Transformers"}, {"text": "Spatio-Temporal criss-cross Graph (STG)\nattention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "3D Human Pose Estimation"}
{"id": "2407.11231", "submitter": "Itay Hen", "authors": "Amir Kalev and Itay Hen", "title": "Feynman path integrals for discrete-variable systems: Walks on\n  Hamiltonian graphs", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a natural, parameter-free, discrete-variable formulation of\nFeynman path integrals. We show that for discrete-variable quantum systems,\nFeynman path integrals take the form of walks on the graph whose weighted\nadjacency matrix is the Hamiltonian. By working out expressions for the\npartition function and transition amplitudes of discretized versions of\ncontinuous-variable quantum systems, and then taking the continuum limit, we\nexplicitly recover Feynman's continuous-variable path integrals. We also\ndiscuss the implications of our result.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2024 20:44:02 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 16:29:50 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Kalev", "Amir", ""], ["Hen", "Itay", ""]], "extracted_entities": [{"text": "Feynman path integrals", "label": "LLMs"}, {"text": "Feynman path integrals", "label": "LLMs"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2407.11598", "submitter": "Susanne Pumpluen", "authors": "Susanne Pumpluen", "title": "A classification of the division algebras that are isotopic to a cyclic\n  Galois field extension", "comments": "The last section of previous version has been removed, the rest is\n  rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We classify all division algebras that are principal Albert isotopes of a\ncyclic Galois field extension of degree $n>2$ up to isomorphisms. We achieve a\n``tight'' classification when the cyclic Galois field extension is cubic. The\nclassification is ``tight'' in the sense that the list of algebras has features\nthat make it easy to distinguish non-isomorphic ones.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2024 10:54:38 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 18:21:00 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Pumpluen", "Susanne", ""]], "extracted_entities": [{"text": "Albert", "label": "ALBERT"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2407.11672", "submitter": "Tong Jiang", "authors": "Tong Jiang, Jinghong Zhang, Moritz K. A. Baumgarten, Meng-Fu Chen,\n  Hieu Q. Dinh, Aadithya Ganeshram, Nishad Maskara, Anton Ni, Joonho Lee", "title": "Walking through Hilbert Space with Quantum Computers", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computations of chemical systems' equilibrium properties and non-equilibrium\ndynamics have been suspected of being a \"killer app\" for quantum computers.\nThis review highlights the recent advancements of quantum algorithms tackling\ncomplex sampling tasks in the key areas of computational chemistry: ground\nstate, thermal state properties, and quantum dynamics calculations. We review a\nbroad range of quantum algorithms, from hybrid quantum-classical to fully\nquantum, focusing on the traditional Monte Carlo family, including Markov chain\nMonte Carlo, variational Monte Carlo, projector Monte Carlo, path integral\nMonte Carlo, etc. We also cover other relevant techniques involving complex\nsampling tasks, such as quantum-selected configuration interaction, minimally\nentangled typical thermal states, entanglement forging, and Monte\nCarlo-flavored Lindbladian dynamics. We provide a comprehensive overview of\nthese algorithms' classical and quantum counterparts, detailing their\ntheoretical frameworks and discussing the potentials and challenges in\nachieving quantum computational advantages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2024 12:43:44 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 19:18:53 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Jiang", "Tong", ""], ["Zhang", "Jinghong", ""], ["Baumgarten", "Moritz K. A.", ""], ["Chen", "Meng-Fu", ""], ["Dinh", "Hieu Q.", ""], ["Ganeshram", "Aadithya", ""], ["Maskara", "Nishad", ""], ["Ni", "Anton", ""], ["Lee", "Joonho", ""]], "extracted_entities": [{"text": "entanglement forging", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2407.11728", "submitter": "Praful Gagrani", "authors": "Praful Gagrani and David Baum", "title": "The evolution of complexity and the transition to biochemical life", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While modern physics and biology satisfactorily explain the passage from the\nBig Bang to the formation of Earth and the first cells to present-day life,\nrespectively, the origins of biochemical life still remain an open question.\nSince life, as we know it, requires extremely long genetic polymers, any answer\nto the question must explain how an evolving system of polymers of\never-increasing length could come about on a planet that otherwise consisted\nonly of small molecular building blocks. In this work, we show that, under\nrealistic constraints, an abstract polymer model can exhibit dynamics such that\nattractors in the polymer population space with a higher average polymer length\nare also more probable. We generalize from the model and formalize the notions\nof complexity and evolution for chemical reaction networks with multiple\nattractors. The complexity of a species is defined as the minimum number of\nreactions needed to produce it from a set of building blocks, which in turn is\nused to define a measure of complexity for an attractor. A transition between\nattractors is considered to be a progressive evolution if the attractor with\nthe higher probability also has a higher complexity. In an environment where\nonly monomers are readily available, the attractor with a higher average\npolymer length is more complex. Thus, our abstract polymer model can exhibit\nprogressive evolution for a range of thermodynamically plausible rate\nconstants. We also formalize criteria for open-ended and\nhistorically-contingent evolution and explain the role of autocatalysis in\nobtaining them. Our work provides a basis for searching for prebiotically\nplausible scenarios in which long polymers can emerge and yield populations\nwith even longer polymers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2024 13:49:39 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2024 12:39:48 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 06:32:01 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Gagrani", "Praful", ""], ["Baum", "David", ""]], "extracted_entities": [{"text": "abstract polymer model", "label": "Foundation Model"}, {"text": "abstract polymer model", "label": "Foundation Model"}], "human_readable_topic": "Evolutionary Algorithms with Large Language Models"}
{"id": "2407.12040", "submitter": "Ranjan Sapkota", "authors": "Ranjan Sapkota, Zhichao Meng, Martin Churuvija, Xiaoqiang Du, Zenghong\n  Ma, Manoj Karkee", "title": "Comprehensive Performance Evaluation of YOLOv12, YOLO11, YOLOv10, YOLOv9\n  and YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments", "comments": "16 figures, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study systematically performed an extensive real-world evaluation of the\nperformances of all configurations of YOLOv8, YOLOv9, YOLOv10, YOLO11( or\nYOLOv11), and YOLOv12 object detection algorithms in terms of precision,\nrecall, mean Average Precision at 50\\% Intersection over Union (mAP@50), and\ncomputational speeds including pre-processing, inference, and post-processing\ntimes immature green apple (or fruitlet) detection in commercial orchards.\nAdditionally, this research performed and validated in-field counting of the\nfruitlets using an iPhone and machine vision sensors. Among the configurations,\nYOLOv12l recorded the highest recall rate at 0.90, compared to all other\nconfigurations of YOLO models. Likewise, YOLOv10x achieved the highest\nprecision score of 0.908, while YOLOv9 Gelan-c attained a precision of 0.903.\nAnalysis of mAP@0.50 revealed that YOLOv9 Gelan-base and YOLOv9 Gelan-e reached\npeak scores of 0.935, with YOLO11s and YOLOv12l following closely at 0.933 and\n0.931, respectively. For counting validation using images captured with an\niPhone 14 Pro, the YOLO11n configuration demonstrated outstanding accuracy,\nrecording RMSE values of 4.51 for Honeycrisp, 4.59 for Cosmic Crisp, 4.83 for\nScilate, and 4.96 for Scifresh; corresponding MAE values were 4.07, 3.98, 7.73,\nand 3.85. Similar performance trends were observed with RGB-D sensor data.\nMoreover, sensor-specific training on Intel Realsense data significantly\nenhanced model performance. YOLOv11n achieved highest inference speed of 2.4\nms, outperforming YOLOv8n (4.1 ms), YOLOv9 Gelan-s (11.5 ms), YOLOv10n (5.5\nms), and YOLOv12n (4.6 ms), underscoring its suitability for real-time object\ndetection applications. (YOLOv12 architecture, YOLOv11 Architecture, YOLOv12\nobject detection, YOLOv11 object detecion, YOLOv12 segmentation)\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2024 17:59:55 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2024 01:58:57 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2024 16:25:47 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2024 17:28:33 GMT"}, {"version": "v5", "created": "Thu, 17 Oct 2024 16:11:43 GMT"}, {"version": "v6", "created": "Mon, 27 Jan 2025 00:57:19 GMT"}, {"version": "v7", "created": "Tue, 25 Feb 2025 23:00:05 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Sapkota", "Ranjan", ""], ["Meng", "Zhichao", ""], ["Churuvija", "Martin", ""], ["Du", "Xiaoqiang", ""], ["Ma", "Zenghong", ""], ["Karkee", "Manoj", ""]], "extracted_entities": [{"text": "YOLOv9", "label": "AI model"}, {"text": "YOLOv10", "label": "AI model"}, {"text": "YOLOv12l", "label": "AI model"}, {"text": "YOLOv10x", "label": "AI model"}, {"text": "YOLOv9 Gelan-c", "label": "AI model"}, {"text": "YOLO11s", "label": "AI model"}, {"text": "YOLOv12l", "label": "AI model"}, {"text": "YOLO11n", "label": "AI model"}, {"text": "Scilate", "label": "AI model"}, {"text": "Scifresh", "label": "AI model"}, {"text": "sensor-specific training", "label": "Few-shot Learning"}, {"text": "YOLOv11n", "label": "AI model"}, {"text": "YOLOv8n", "label": "AI model"}, {"text": "YOLOv9 Gelan-s", "label": "AI model"}, {"text": "YOLOv10n", "label": "AI model"}, {"text": "YOLOv12n", "label": "AI model"}], "human_readable_topic": "Few-Shot Object Detection"}
{"id": "2407.12069", "submitter": "Thomas De Min", "authors": "Thomas De Min, Massimiliano Mancini, St\\'ephane Lathuili\\`ere,\n  Subhankar Roy, and Elisa Ricci", "title": "Unlearning Personal Data from a Single Image", "comments": "Published in Transactions on Machine Learning Research (TMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine unlearning aims to erase data from a model as if the latter never saw\nthem during training. While existing approaches unlearn information from\ncomplete or partial access to the training data, this access can be limited\nover time due to privacy regulations. Currently, no setting or benchmark exists\nto probe the effectiveness of unlearning methods in such scenarios. To fill\nthis gap, we propose a novel task we call One-Shot Unlearning of Personal\nIdentities (1-SHUI) that evaluates unlearning models when the training data is\nnot available. We focus on unlearning identity data, which is specifically\nrelevant due to current regulations requiring personal data deletion after\ntraining. To cope with data absence, we expect users to provide a portraiting\npicture to aid unlearning. We design requests on CelebA, CelebA-HQ, and MUFAC\nwith different unlearning set sizes to evaluate applicable methods in 1-SHUI.\nMoreover, we propose MetaUnlearn, an effective method that meta-learns to\nforget identities from a single image. Our findings indicate that existing\napproaches struggle when data availability is limited, especially when there is\na dissimilarity between the provided samples and the training data. Source code\navailable at https://github.com/tdemin16/one-shui.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2024 10:00:54 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 17:16:34 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["De Min", "Thomas", ""], ["Mancini", "Massimiliano", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Roy", "Subhankar", ""], ["Ricci", "Elisa", ""]], "extracted_entities": [{"text": "privacy regulations", "label": "AI Ethics"}, {"text": "current regulations", "label": "AI Ethics"}], "human_readable_topic": "Machine Unlearning in Large Language Models"}
{"id": "2407.13296", "submitter": "Max Menssen", "authors": "Max Menssen, Jonathan Rathjens", "title": "Prediction intervals for overdispersed binomial endpoints and their\n  application to toxicological historical control data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For toxicology studies, the validation of the concurrent control group by\nhistorical control data (HCD) has become requirements. This validation is\nusually done by historical control limits (HCL), which should cover the\nobservations of the concurrent control with a predefined level of confidence.\nIn many applications, HCL are applied to dichotomous data, e.g. the number of\nrats with a tumor vs. the number of rats without a tumor (carcinogenicity\nstudies) or the number of cells with a micronucleus out of a total number of\ncells. Dichotomous HCD may be overdispersed and can be heavily right- (or\nleft-) skewed, which is usually not taken into account in the practical\napplications of HCL. To overcome this problem, four different prediction\nintervals (two frequentist, two Bayesian), that can be applied to such data,\nare proposed. Based on comprehensive Monte-Carlo simulations, the coverage\nprobabilities of the proposed prediction intervals were compared to heuristical\nHCL typically used in daily toxicological routine (historical range, limits of\nthe np-chart, mean plus minus 2 SD). Our simulations reveal, that frequentist\nbootstrap calibrated prediction intervals control the type-1-error best, but,\nalso prediction intervals calculated based on Bayesian generalized linear mixed\nmodels appear to be practically applicable. Contrary, all heuristics fail to\ncontrol the type-1-error. The application of HCL is demonstrated based on a\nreal life data set containing historical controls from long-term\ncarcinogenicity studies run on behalf of the U.S. National Toxicology Program.\nThe proposed frequentist prediction intervals are publicly available from the R\npackage predint, whereas R code for the computation of the two Bayesian\nprediction intervals is provided via GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2024 08:54:45 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2024 07:43:37 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 11:52:42 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Menssen", "Max", ""], ["Rathjens", "Jonathan", ""]], "extracted_entities": [{"text": "GitHub", "label": "Open-source LLMs"}], "human_readable_topic": "Uncategorized"}
{"id": "2407.13522", "submitter": "Abhishek Kumar Singh", "authors": "Abhishek Kumar Singh, Vishwajeet kumar, Rudra Murthy, Jaydeep Sen,\n  Ashish Mittal, Ganesh Ramakrishnan", "title": "INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question\n  Answering capability of LLMs for Indic Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large Language Models (LLMs) perform well on unseen tasks in English, but\ntheir abilities in non English languages are less explored due to limited\nbenchmarks and training data. To bridge this gap, we introduce the Indic QA\nBenchmark, a large dataset for context grounded question answering in 11 major\nIndian languages, covering both extractive and abstractive tasks. Evaluations\nof multilingual LLMs, including instruction finetuned versions, revealed weak\nperformance in low resource languages due to a strong English language bias in\ntheir training data. We also investigated the Translate Test paradigm,where\ninputs are translated to English for processing and the results are translated\nback into the source language for output. This approach outperformed\nmultilingual LLMs, particularly in low resource settings. By releasing Indic\nQA, we aim to promote further research into LLMs question answering\ncapabilities in low resource languages. This benchmark offers a critical\nresource to address existing limitations and foster multilingual understanding.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2024 13:57:16 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 05:37:48 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Singh", "Abhishek Kumar", ""], ["kumar", "Vishwajeet", ""], ["Murthy", "Rudra", ""], ["Sen", "Jaydeep", ""], ["Mittal", "Ashish", ""], ["Ramakrishnan", "Ganesh", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Evaluating Language Models for Question Answering Tasks"}
{"id": "2407.14716", "submitter": "Jian Wang", "authors": "Hai Tao Li, Zong-Guo Si, Jian Wang, Xiao Zhang, Dan Zhao", "title": "Improved constraints on Higgs boson self-couplings with quartic and\n  cubic power dependencies of the cross section", "comments": "13 pages, 4 figures; v2: discussion on the application of HEFT added,\n  version published in Chin.Phys.C", "journal-ref": "Chin.Phys.C 49 (2025) 2, 023107", "doi": "10.1088/1674-1137/ad9d1d", "report-no": null, "categories": "hep-ph hep-ex", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Precise determination of the Higgs boson self-couplings is essential for\nunderstanding the mechanism underlying electroweak symmetry breaking. However,\nowing to the limited number of Higgs boson pair events at the LHC, only loose\nconstraints have been established to date. Current constraints are based on the\nassumption that the cross section is a quadratic function of the trilinear\nHiggs self-coupling within the $\\kappa$ framework. Incorporating higher-order\nquantum corrections from virtual Higgs bosons would significantly alter this\nfunctional form, introducing new quartic and cubic power dependencies on the\ntrilinear Higgs self-coupling. To derive this new functional form, we propose a\nspecialized renormalization procedure that tracks all Higgs self-couplings at\neach calculation step. Additionally, we introduce renormalization constants for\ncoupling modifiers within the $\\kappa$ framework to ensure the cancellation of\nall ultraviolet divergences. With new functional forms of the cross sections in\nboth the gluon-gluon fusion and vector boson fusion channels, the upper limit\nof $\\kappa_{\\lambda_{\\rm 3H}}=\\lambda_{\\rm 3H}/\\lambda_{\\rm 3H}^{\\rm SM}$ set\nby the ATLAS (CMS) collaboration is reduced from 6.6 (6.49) to 5.4 (5.37).\nHowever, extracting a meaningful constraint on the quartic Higgs self-coupling\n$\\lambda_{\\rm 4H}$ from Higgs boson pair production data remains challenging.\nWe also present the invariant mass distributions of the Higgs boson pair at\ndifferent values of $\\kappa_{\\lambda}$, which could assist in setting optimal\ncuts for experimental analysis.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2024 01:00:55 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 13:44:49 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Li", "Hai Tao", ""], ["Si", "Zong-Guo", ""], ["Wang", "Jian", ""], ["Zhang", "Xiao", ""], ["Zhao", "Dan", ""]], "extracted_entities": [{"text": "higher-order\nquantum corrections", "label": "quantisation"}], "human_readable_topic": "Modular Symmetry in Quark Flavor Models"}
{"id": "2407.14845", "submitter": "Arun Verma", "authors": "Ze Yu Zhang, Arun Verma, Finale Doshi-Velez, Bryan Kian Hsiang Low", "title": "Understanding the Relationship between Prompts and Response Uncertainty\n  in Large Language Models", "comments": "22 pages, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large language models (LLMs) are widely used in decision-making, but their\nreliability, especially in critical tasks like healthcare, is not\nwell-established. Therefore, understanding how LLMs reason and make decisions\nis crucial for their safe deployment. This paper investigates how the\nuncertainty of responses generated by LLMs relates to the information provided\nin the input prompt. Leveraging the insight that LLMs learn to infer latent\nconcepts during pretraining, we propose a prompt-response concept model that\nexplains how LLMs generate responses and helps understand the relationship\nbetween prompts and response uncertainty. We show that the uncertainty\ndecreases as the prompt's informativeness increases, similar to epistemic\nuncertainty. Our detailed experimental results on real-world datasets validate\nour proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2024 11:19:58 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2024 02:23:12 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 17:06:21 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Zhang", "Ze Yu", ""], ["Verma", "Arun", ""], ["Doshi-Velez", "Finale", ""], ["Low", "Bryan Kian Hsiang", ""]], "extracted_entities": [{"text": "Large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompt", "label": "Prompting"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompt", "label": "Prompting"}], "human_readable_topic": "Prompt Engineering for Large Language Models"}
{"id": "2407.15073", "submitter": "Hao Duong Le", "authors": "Hao Duong Le, Xin Xia and Zhang Chen", "title": "Multi-Agent Causal Discovery Using Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery aims to identify causal relationships between variables and\nis a critical research area in machine learning. Traditional methods focus on\nstatistical or machine learning algorithms to uncover causal links from\nstructured data, often overlooking the valuable contextual information provided\nby metadata. Large language models (LLMs) have shown promise in creating\nunified causal discovery frameworks by incorporating both structured data and\nmetadata. However, their potential in multi-agent settings remains largely\nunexplored. To address this gap, we introduce the Multi-Agent Causal Discovery\nFramework (MAC), which consists of two key modules: the Debate-Coding Module\n(DCM) and the Meta-Debate Module (MDM). The DCM begins with a multi-agent\ndebating and coding process, where agents use both structured data and metadata\nto collaboratively select the most suitable statistical causal discovery (SCD)\nmethod. The selected SCD is then applied to the structured data to generate an\ninitial causal graph. This causal graph is transformed into causal metadata\nthrough the Meta Fusion mechanism. With all the metadata, MDM then refines the\ncausal structure by leveraging a multi-agent debating framework. Extensive\nexperiments across five datasets demonstrate that MAC outperforms both\ntraditional statistical causal discovery methods and existing LLM-based\napproaches, achieving state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2024 06:21:47 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2024 02:48:42 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 02:47:56 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Le", "Hao Duong", ""], ["Xia", "Xin", ""], ["Chen", "Zhang", ""]], "extracted_entities": [{"text": "Large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "Meta Fusion mechanism", "label": "Embedding"}, {"text": "MDM", "label": "LLM"}, {"text": "MAC", "label": "LLM"}, {"text": "existing LLM-based\napproaches", "label": "LLM"}], "human_readable_topic": "Multi-Agent Debate Frameworks"}
{"id": "2407.16233", "submitter": "Lachlan Simpson", "authors": "Lachlan Simpson, Federico Costanza, Kyle Millar, Adriel Cheng,\n  Cheng-Chew Lim, Hong Gunn Chew", "title": "Algebraic Adversarial Attacks on Integrated Gradients", "comments": "To appear in the proceedings of the International Conference on\n  Machine Learning and Cybernetics (ICMLC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial attacks on explainability models have drastic consequences when\nexplanations are used to understand the reasoning of neural networks in safety\ncritical systems. Path methods are one such class of attribution methods\nsusceptible to adversarial attacks. Adversarial learning is typically phrased\nas a constrained optimisation problem. In this work, we propose algebraic\nadversarial examples and study the conditions under which one can generate\nadversarial examples for integrated gradients. Algebraic adversarial examples\nprovide a mathematically tractable approach to adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2024 07:17:45 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 00:13:57 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Simpson", "Lachlan", ""], ["Costanza", "Federico", ""], ["Millar", "Kyle", ""], ["Cheng", "Adriel", ""], ["Lim", "Cheng-Chew", ""], ["Chew", "Hong Gunn", ""]], "extracted_entities": [{"text": "Adversarial learning", "label": "Few-shot Learning"}], "human_readable_topic": "Backdoor Attacks and Defenses in Deep Learning"}
{"id": "2407.17054", "submitter": "Matteo Baggioli", "authors": "Matteo Baggioli, Kyoung-Bum Huh, Hyun-Sik Jeong, Keun-Young Kim, Juan\n  F. Pedraza", "title": "Krylov complexity as an order parameter for quantum chaotic-integrable\n  transitions", "comments": "[v4] matching the published version to appear in PRR", "journal-ref": null, "doi": null, "report-no": "IFT-UAM/CSIC-24-107", "categories": "hep-th nlin.CD quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Krylov complexity has recently emerged as a new paradigm to characterize\nquantum chaos in many-body systems. However, which features of Krylov\ncomplexity are prerogative of quantum chaotic systems and how they relate to\nmore standard probes, such as spectral statistics or out-of-time-order\ncorrelators (OTOCs), remain open questions. Recent insights have revealed that\nin quantum chaotic systems Krylov state complexity exhibits a distinct peak\nduring time evolution before settling into a well-understood late-time plateau.\nIn this work, we propose that this Krylov complexity peak (KCP) is a hallmark\nof quantum chaotic systems and suggest that its height could serve as an `order\nparameter' for quantum chaos. We demonstrate that the KCP effectively\nidentifies chaotic-integrable transitions in two representative quantum\nmechanical models at both infinite and finite temperature: the mass-deformed\nSachdev-Ye-Kitaev model and the sparse Sachdev-Ye-Kitaev model. Our findings\nalign with established results from spectral statistics and OTOCs, while\nintroducing an operator-independent diagnostic for quantum chaos, offering more\n`universal' insights and a deeper understanding of the general properties of\nquantum chaotic systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2024 07:32:27 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2024 10:54:25 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2024 09:22:34 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2025 08:00:19 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Baggioli", "Matteo", ""], ["Huh", "Kyoung-Bum", ""], ["Jeong", "Hyun-Sik", ""], ["Kim", "Keun-Young", ""], ["Pedraza", "Juan F.", ""]], "extracted_entities": [{"text": "OTOCs", "label": "LLMs"}, {"text": "OTOCs", "label": "LLMs"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2407.17329", "submitter": "Erell Gachon", "authors": "Erell Gachon, J\\'er\\'emie Bigot, Elsa Cazelles, Audrey Bidet,\n  Jean-Philippe Vial, Pierre-Yves Dumas, Aguirre Mimoun", "title": "Low dimensional representation of multi-patient flow cytometry datasets\n  using optimal transport for minimal residual disease detection in leukemia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Representing and quantifying Minimal Residual Disease (MRD) in Acute Myeloid\nLeukemia (AML), a type of cancer that affects the blood and bone marrow, is\nessential in the prognosis and follow-up of AML patients. As traditional\ncytological analysis cannot detect leukemia cells below 5\\%, the analysis of\nflow cytometry dataset is expected to provide more reliable results. In this\npaper, we explore statistical learning methods based on optimal transport (OT)\nto achieve a relevant low-dimensional representation of multi-patient flow\ncytometry measurements (FCM) datasets considered as high-dimensional\nprobability distributions. Using the framework of OT, we justify the use of the\nK-means algorithm for dimensionality reduction of multiple large-scale point\nclouds through mean measure quantization by merging all the data into a single\npoint cloud. After this quantization step, the visualization of the intra and\ninter-patients FCM variability is carried out by embedding low-dimensional\nquantized probability measures into a linear space using either Wasserstein\nPrincipal Component Analysis (PCA) through linearized OT or log-ratio PCA of\ncompositional data. Using a publicly available FCM dataset and a FCM dataset\nfrom Bordeaux University Hospital, we demonstrate the benefits of our approach\nover the popular kernel mean embedding technique for statistical learning from\nmultiple high-dimensional probability distributions. We also highlight the\nusefulness of our methodology for low-dimensional projection and clustering\npatient measurements according to their level of MRD in AML from FCM. In\nparticular, our OT-based approach allows a relevant and informative\ntwo-dimensional representation of the results of the FlowSom algorithm, a\nstate-of-the-art method for the detection of MRD in AML using multi-patient\nFCM.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2024 14:53:01 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2024 08:09:01 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 08:11:39 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Gachon", "Erell", ""], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Cazelles", "Elsa", ""], ["Bidet", "Audrey", ""], ["Vial", "Jean-Philippe", ""], ["Dumas", "Pierre-Yves", ""], ["Mimoun", "Aguirre", ""]], "extracted_entities": [{"text": "mean measure quantization", "label": "quantisation"}], "human_readable_topic": "Manifold Learning and Dimensionality Reduction"}
{"id": "2407.18772", "submitter": "Serina Chang", "authors": "Serina Chang, Zhiyin Lin, Benjamin Yan, Swapnil Bembde, Qi Xiu, Chi\n  Heem Wong, Yu Qin, Frank Kloster, Alex Luo, Raj Palleti, Jure Leskovec", "title": "Learning production functions for supply chains with graph neural\n  networks", "comments": "This is the extended version of a paper accepted to AAAI 2025, AI for\n  Social Impact Track (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global economy relies on the flow of goods over supply chain networks,\nwith nodes as firms and edges as transactions between firms. While we may\nobserve these external transactions, they are governed by unseen production\nfunctions, which determine how firms internally transform the input products\nthey receive into output products that they sell. In this setting, it can be\nextremely valuable to infer these production functions, to improve supply chain\nvisibility and to forecast future transactions more accurately. However,\nexisting graph neural networks (GNNs) cannot capture these hidden relationships\nbetween nodes' inputs and outputs. Here, we introduce a new class of models for\nthis setting by combining temporal GNNs with a novel inventory module, which\nlearns production functions via attention weights and a special loss function.\nWe evaluate our models extensively on real supply chains data and data\ngenerated from our new open-source simulator, SupplySim. Our models\nsuccessfully infer production functions, outperforming the strongest baseline\nby 6%-50% (across datasets), and forecast future transactions, outperforming\nthe strongest baseline by 11%-62%\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2024 14:32:18 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2024 18:02:08 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 22:32:49 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Chang", "Serina", ""], ["Lin", "Zhiyin", ""], ["Yan", "Benjamin", ""], ["Bembde", "Swapnil", ""], ["Xiu", "Qi", ""], ["Wong", "Chi Heem", ""], ["Qin", "Yu", ""], ["Kloster", "Frank", ""], ["Luo", "Alex", ""], ["Palleti", "Raj", ""], ["Leskovec", "Jure", ""]], "extracted_entities": [{"text": "attention weights", "label": "Attention mechanism"}, {"text": "SupplySim", "label": "Open-source LLMs"}], "human_readable_topic": "Graph Transformers and Neural Networks"}
{"id": "2407.19271", "submitter": "Zhijie Sui", "authors": "Gang Pan, Chen Wang, Zhijie Sui, Shuai Guo, Yaozhi Lv, Honglie Li, Di\n  Sun, Zixia Xia", "title": "Sewer Image Super-Resolution with Depth Priors and Its Lightweight\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quick-view (QV) technique serves as a primary method for detecting\ndefects within sewerage systems. However, the effectiveness of QV is impeded by\nthe limited visual range of its hardware, resulting in suboptimal image quality\nfor distant portions of the sewer network. Image super-resolution is an\neffective way to improve image quality and has been applied in a variety of\nscenes. However, research on super-resolution for sewer images remains\nconsiderably unexplored. In response, this study leverages the inherent depth\nrelationships present within QV images and introduces a novel Depth-guided,\nReference-based Super-Resolution framework denoted as DSRNet. It comprises two\ncore components: a depth extraction module and a depth information matching\nmodule (DMM). DSRNet utilizes the adjacent frames of the low-resolution image\nas reference images and helps them recover texture information based on the\ncorrelation. By combining these modules, the integration of depth priors\nsignificantly enhances both visual quality and performance benchmarks. Besides,\nin pursuit of computational efficiency and compactness, a super-resolution\nknowledge distillation model based on an attention mechanism is introduced.\nThis mechanism facilitates the acquisition of feature similarity between a more\ncomplex teacher model and a streamlined student model, with the latter being a\nlightweight version of DSRNet. Experimental results demonstrate that DSRNet\nsignificantly improves PSNR and SSIM compared with other methods. This study\nalso conducts experiments on sewer defect semantic segmentation, object\ndetection, and classification on the Pipe dataset and Sewer-ML dataset.\nExperiments show that the method can improve the performance of low-resolution\nsewer images in these tasks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2024 14:45:34 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2024 06:34:00 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 13:06:46 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Pan", "Gang", ""], ["Wang", "Chen", ""], ["Sui", "Zhijie", ""], ["Guo", "Shuai", ""], ["Lv", "Yaozhi", ""], ["Li", "Honglie", ""], ["Sun", "Di", ""], ["Xia", "Zixia", ""]], "extracted_entities": [{"text": "super-resolution\nknowledge distillation", "label": "Knowledge distillation"}, {"text": "attention mechanism", "label": "Attention mechanism"}], "human_readable_topic": "Image Super-Resolution Methods"}
{"id": "2407.19520", "submitter": "Wu Tz-Ying", "authors": "Tz-Ying Wu, Kyle Min, Subarna Tripathi, Nuno Vasconcelos", "title": "Ego-VPA: Egocentric Video Understanding with Parameter-efficient\n  Adaptation", "comments": "Accepted to WACV 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video understanding typically requires fine-tuning the large backbone when\nadapting to new domains. In this paper, we leverage the egocentric video\nfoundation models (Ego-VFMs) based on video-language pre-training and propose a\nparameter-efficient adaptation for egocentric video tasks, namely Ego-VPA. It\nemploys a local sparse approximation for each video frame/text feature using\nthe basis prompts, and the selected basis prompts are used to synthesize\nvideo/text prompts. Since the basis prompts are shared across frames and\nmodalities, it models context fusion and cross-modal transfer in an efficient\nfashion. Experiments show that Ego-VPA excels in lightweight adaptation (with\nonly 0.84% learnable parameters), largely improving over baselines and reaching\nthe performance of full fine-tuning.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2024 16:01:32 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 02:37:53 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Wu", "Tz-Ying", ""], ["Min", "Kyle", ""], ["Tripathi", "Subarna", ""], ["Vasconcelos", "Nuno", ""]], "extracted_entities": [{"text": "egocentric video\nfoundation models", "label": "Foundation Model"}, {"text": "Ego-VFMs", "label": "Foundation Model"}, {"text": "basis prompts", "label": "Prompting"}, {"text": "basis prompts", "label": "Prompting"}, {"text": "video/text prompts", "label": "Prompting"}, {"text": "basis prompts", "label": "Prompting"}, {"text": "context fusion", "label": "contextual Embedding"}, {"text": "full fine-tuning", "label": "Fine-tuning"}], "human_readable_topic": "Video Understanding with Large Multimodal Models"}
{"id": "2407.20142", "submitter": "Aparajita Bhattacharyya", "authors": "Aparajita Bhattacharyya and Ujjwal Sen", "title": "Precision in estimating independent local fields: attainable bound and\n  indispensability of genuine multiparty entanglement", "comments": "9 pages, Results modified based on a full-rank positive semi-definite\n  weight matrix. Presentation improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of local quantum fields is a crucial aspect of quantum metrology\napplications, and often also forms the test-bed to analyze the utility of\nquantum resources, like entanglement. However, so far, this has been analyzed\nusing the same local field for all the probes, and so, although the encoding\nprocess utilizes a local Hamiltonian, there is an inherent \"nonlocality\" in the\nencoding process in the form of a common local field applied on all the probes.\nWe show that estimation of even independent multiple field strengths of a local\nHamiltonian, i.e., one formed by a sum of single-party terms, necessitates the\nutility of genuine multipartite entangled state as the input probe. The feature\ndepends on the choice of the weight matrix considered, which is full-rank and\ncontains non-vanishing off-diagonal terms. We obtain this result by providing a\nlower bound on the precision of multiparameter estimation, optimized over input\nprobes, for an arbitrary positive semi-definite weight matrix. We show that\nthere exists a weight matrix for which this bound is always attainable by the\nGreenberger-Horne-Zeilinger (GHZ) state, chosen in a certain basis.\nFurthermore, we find the parametric form of the most general optimal state for\nthree parties. We also show that no pure product state can achieve the lower\nbound. Finally, for an arbitrary weight matrix and an arbitrary multiparty\nlocal encoding Hamiltonian, we prove that using a probe that is in any mixed\nstate provides a precision lower than that obtainable using pure states. To\nemphasize the importance of the weight matrix considered, we also prove that\nthe choice of identity operator as the same - thereby ignoring the\n\"off-diagonal\" covariances in the precision matrix - does not require the use\nof genuine multiparty entanglement in input probes for attaining the best\nprecision, and the optimal probe can be a pure product.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2024 16:12:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2024 16:02:12 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 16:29:14 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Bhattacharyya", "Aparajita", ""], ["Sen", "Ujjwal", ""]], "extracted_entities": [{"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2407.20603", "submitter": "Marco Falconi", "authors": "Marco Falconi and Lorenzo Fratini", "title": "Abstract semiclassical analysis of the van Hove model", "comments": "39 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.FA math.MP math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the semiclassical limit $\\hslash\\to 0$ of a completely\nsolvable model in quantum field theory: the van Hove model, describing a scalar\nfield created and annihilated by an immovable source. Despite its simplicity,\nthe van Hove model possesses many characterizing features of quantum fields,\nespecially in the infrared region. In particular, the existence of non-Fock\nground and equilibrium states in the presence of infrared singular sources\nmakes a representation-independent algebraic approach of utmost importance. We\nmake use of recent representation-independent techniques of infinite\ndimensional semiclassical analysis to establish the Bohr correspondence\nprinciple for the dynamics, equilibrium states, and long-time asymptotics in\nthe van Hove model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2024 07:27:31 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:30:17 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Falconi", "Marco", ""], ["Fratini", "Lorenzo", ""]], "extracted_entities": [{"text": "van Hove model", "label": "AI model"}, {"text": "van Hove model", "label": "AI model"}, {"text": "Bohr correspondence\nprinciple", "label": "quantisation"}, {"text": "van Hove model", "label": "AI model"}], "human_readable_topic": "Quantum Systems and Hamiltonian Dynamics"}
{"id": "2407.20827", "submitter": "Nicolas Fabre", "authors": "Thomas Pousset, Maxime Federico, Romain All\\'eaume and Nicolas Fabre", "title": "Kramers-Kronig detection in the quantum regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the quantization of Kramers-Kronig detection technique\ninitially developped for classical optical communications. It consists in\nmixing the unknown field with a strong monochromatic local oscillator on an\nunbalanced beamsplitter. A single output of the beamsplitter undergoes a direct\ndetection of the optical intensity by means of a single photodiode. When the\nmeasured output verifies signal processing constraints, namely, the minimal\nphase and the single sideband constraints, Kramers-Kronig detection\nreconstructs the phase of the signal from the intensity measurements via a\ndigitally computed Hilbert transform. The local oscillator being known,\nKramers-Kronig detection allows for reconstructing the quadratures of the\nunknown field. We show that this result holds in the quantum regime up to first\norder in the local oscillator amplitude and thus that Kramers-Kronig detection\nacts as a coherent detection able to measure both quadratures, making it a\nGaussian measurement similar to double homodyne detection. We also study in\ndetails the phase information measured by Kramers-Kronig detection for bosonic\ncoherent states, monomode pure states and mixed states. Finally, we propose and\ninvestigate a spectral tomography protocol for single-photon states that is\ninspired by Kramers-Kronig detection and relies on a spectral engineering of\nthe single-photon.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2024 13:47:31 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 12:56:35 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Pousset", "Thomas", ""], ["Federico", "Maxime", ""], ["All\u00e9aume", "Romain", ""], ["Fabre", "Nicolas", ""]], "extracted_entities": [{"text": "quantization", "label": "quantisation"}], "human_readable_topic": "Binarization of Vision Transformers"}
{"id": "2407.20966", "submitter": "Tarik Dzanic", "authors": "Tarik Dzanic and Luigi Martinelli", "title": "High-order limiting methods using maximum principle bounds derived from\n  the Boltzmann equation I: Euler equations", "comments": null, "journal-ref": "Journal of Computational Physics, 530, 113895, 2025", "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of limiting methods for high-order numerical approximations of\nhyperbolic conservation laws generally requires defining an admissible\nregion/bounds for the solution. In this work, we present a novel approach for\ncomputing solution bounds and limiting for the Euler equations through the\nkinetic representation provided by the Boltzmann equation, which allows for\nextending limiters designed for linear advection directly to the Euler\nequations. Given an arbitrary set of solution values to compute bounds over\n(e.g., numerical stencil) and a desired linear advection limiter, the proposed\napproach yields an analytic expression for the admissible region of particle\ndistribution function values, which may be numerically integrated to yield a\nset of bounds for the density, momentum, and total energy. These solution\nbounds are shown to preserve positivity of density/pressure/internal energy\nand, when paired with a limiting technique, can robustly resolve strong\ndiscontinuities while recovering high-order accuracy in smooth regions without\nany ad hoc corrections (e.g., relaxing the bounds). This approach is\ndemonstrated in the context of an explicit unstructured high-order\ndiscontinuous Galerkin/flux reconstruction scheme for a variety of difficult\nproblems in gas dynamics, including cases with extreme shocks and shock-vortex\ninteractions. Furthermore, this work presents a foundation for limiting\ntechniques for more complex macroscopic governing equations that can be derived\nfrom an underlying kinetic representation for which admissible solution bounds\nare not well-understood.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2024 16:48:11 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2025 02:04:37 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 17:47:27 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Dzanic", "Tarik", ""], ["Martinelli", "Luigi", ""]], "extracted_entities": [{"text": "hyperbolic conservation laws", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2407.21018", "submitter": "Yuhui Xu", "authors": "Yuhui Xu, Zhanming Jie, Hanze Dong, Lei Wang, Xudong Lu, Aojun Zhou,\n  Amrita Saha, Caiming Xiong, Doyen Sahoo", "title": "ThinK: Thinner Key Cache by Query-Driven Pruning", "comments": "ICLR 2025 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, achieving unprecedented performance across a variety of\napplications. However, their increased computational and memory demands present\nsignificant challenges, especially when handling long sequences. This paper\nfocuses on the long-context scenario, addressing the inefficiencies in KV cache\nmemory consumption during inference. Unlike existing approaches that optimize\nthe memory based on the sequence length, we identify substantial redundancy in\nthe channel dimension of the KV cache, as indicated by an uneven magnitude\ndistribution and a low-rank structure in the attention weights. In response, we\npropose ThinK, a novel query-dependent KV cache pruning method designed to\nminimize attention weight loss while selectively pruning the least significant\nchannels. Our approach not only maintains or enhances model accuracy but also\nachieves a reduction in KV cache memory costs by over 20% compared with vanilla\nKV cache eviction and quantization methods. For instance, ThinK integrated with\nKIVI can achieve a 2.8x reduction in peak memory usage while maintaining nearly\nthe same quality, enabling up to a 5x increase in batch size when using a\nsingle GPU. Extensive evaluations on the LLaMA and Mistral models across\nvarious long-sequence datasets verified the efficiency of ThinK, establishing a\nnew baseline algorithm for efficient LLM deployment without compromising\nperformance. Our code has been made available at\nhttps://github.com/SalesforceAIResearch/ThinK.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2024 17:59:08 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2024 03:03:29 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 12:30:43 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Xu", "Yuhui", ""], ["Jie", "Zhanming", ""], ["Dong", "Hanze", ""], ["Wang", "Lei", ""], ["Lu", "Xudong", ""], ["Zhou", "Aojun", ""], ["Saha", "Amrita", ""], ["Xiong", "Caiming", ""], ["Sahoo", "Doyen", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "attention weights", "label": "Attention mechanism"}, {"text": "Mistral", "label": "Mistral"}], "human_readable_topic": "Optimizing KV Cache for Large Language Models"}
{"id": "2407.21426", "submitter": "Ahmad Sheykhi", "authors": "Ahmad Sheykhi, Leila Liravi, Kimet Jusufi", "title": "Thermodynamical properties of nonsingular universe", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We disclose the thermodynamical properties of the apparent horizon in a\nnonsingular universe. We take into account the zero-point length correction to\nthe gravitational potential and derive the modified entropy expression that\nincludes zero-point length correction terms. We apply the first law of\nthermodynamics on the apparent horizon as well as the emergent gravity scenario\nto derive the modified Friedmann equations. Further, we examine the time\nevolution of the total entropy, including the entropy of the apparent horizon\nand the matter field entropy inside the horizon and find out that the\ngeneralized second law of thermodynamics is satisfied. We also investigate the\ncosmological implications of the modified cosmology through zero-point length.\nWe observe that the zero-point length correction does not change the general\nprofile of the universe evolution, however, it shifts the time of the phase\ntransition in a universe filled with matter and cosmological constant. We\nexplore the age of the universe for our model and observe that the predicted\nage of the universe becomes larger compared to the standard cosmology. By\ncalculating the explicit form of Ricci and Kretchmann invariants, we confirm\nthat in our model, the initial singularity of the universe is removed. This is\nan expected result, because the main motivation for considering zero-point\nlength correction in the gravitational potential is to remove singularity at\nthe origin.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2024 08:20:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:28:56 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Sheykhi", "Ahmad", ""], ["Liravi", "Leila", ""], ["Jusufi", "Kimet", ""]], "extracted_entities": [{"text": "first law of\nthermodynamics", "label": "Scaling law"}], "human_readable_topic": "Uncategorized"}
{"id": "2408.00391", "submitter": "Alexander Schenkel", "authors": "Cameron Kemp, Robert Laugwitz, Alexander Schenkel", "title": "Infinitesimal 2-braidings from 2-shifted Poisson structures", "comments": "v2: 39 pages. Final version accepted for publication in Journal of\n  Geometry and Physics", "journal-ref": null, "doi": "10.1016/j.geomphys.2025.105456", "report-no": null, "categories": "math.QA math-ph math.AG math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that every $2$-shifted Poisson structure on a finitely generated\nsemi-free commutative differential graded algebra $A$ defines a very explicit\ninfinitesimal $2$-braiding on the homotopy $2$-category of the symmetric\nmonoidal dg-category of finitely generated semi-free $A$-dg-modules. This\nprovides a concrete realization, to first order in the deformation parameter\n$\\hbar$, of the abstract deformation quantization results in derived algebraic\ngeometry due to Calaque, Pantev, To\\\"en, Vaqui\\'e and Vezzosi. Of particular\ninterest is the case when $A$ is the Chevalley-Eilenberg algebra of a Lie\n$N$-algebra, where the braided monoidal deformations developed in this paper\nmay be interpreted as candidates for representation categories of `higher\nquantum groups'.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2024 08:59:34 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 09:21:58 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Kemp", "Cameron", ""], ["Laugwitz", "Robert", ""], ["Schenkel", "Alexander", ""]], "extracted_entities": [{"text": "deformation quantization", "label": "quantisation"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2408.01353", "submitter": "Forrest Hilton", "authors": "Forrest M. Hilton", "title": "Finite Dynamical Laminations", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed several combinatorial notions about laminations some with clear\nimplications for parameter space. We introduce a simplified class of\nlaminations called finite dynamical laminations (FDL). In order to count FDL,\nwe introduce sibling portraits, of which we provide a comprehensive counting\ntheorem. We provide a characterization of which periodic polygons appear in\ninvariant laminations. We introduce the pullback tree. The base of the pullback\ntree is a set of laminations, and we show that those laminations are proper and\ninvariant and have a restriction on its critical leaves, so all laminations in\nthe base of the pullback tree correspond to a polynomial. We define the\ngenerational FDL graph, and it provides a summary of the combinatorial\ninformation we provide about polynomial parameter space.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2024 16:02:18 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 04:39:33 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Hilton", "Forrest M.", ""]], "extracted_entities": [{"text": "finite dynamical laminations", "label": "LLMs"}, {"text": "laminations", "label": "LLMs"}, {"text": "FDL", "label": "LLMs"}], "human_readable_topic": "Planar Graph Algorithms and Properties"}
{"id": "2408.02340", "submitter": "Zong-Gan Chen", "authors": "Guo-Yun Lin, Zong-Gan Chen, Chuanbin Liu, Yuncheng Jiang, Sam Kwong,\n  Jun Zhang, Zhi-Hui Zhan", "title": "A Landscape-Aware Differential Evolution for Multimodal Optimization\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to simultaneously locate multiple global peaks and achieve certain\naccuracy on the found peaks are two key challenges in solving multimodal\noptimization problems (MMOPs). In this paper, a landscape-aware differential\nevolution (LADE) algorithm is proposed for MMOPs, which utilizes landscape\nknowledge to maintain sufficient diversity and provide efficient search\nguidance. In detail, the landscape knowledge is efficiently utilized in the\nfollowing three aspects. First, a landscape-aware peak exploration helps each\nindividual evolve adaptively to locate a peak and simulates the regions of the\nfound peaks according to search history to avoid an individual locating a found\npeak. Second, a landscape-aware peak distinction distinguishes whether an\nindividual locates a new global peak, a new local peak, or a found peak.\nAccuracy refinement can thus only be conducted on the global peaks to enhance\nthe search efficiency. Third, a landscape-aware reinitialization specifies the\ninitial position of an individual adaptively according to the distribution of\nthe found peaks, which helps explore more peaks. The experiments are conducted\non 20 widely-used benchmark MMOPs. Experimental results show that LADE obtains\ngenerally better or competitive performance compared with seven well-performed\nalgorithms proposed recently and four winner algorithms in the IEEE CEC\ncompetitions for multimodal optimization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2024 09:37:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 13:32:36 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Lin", "Guo-Yun", ""], ["Chen", "Zong-Gan", ""], ["Liu", "Chuanbin", ""], ["Jiang", "Yuncheng", ""], ["Kwong", "Sam", ""], ["Zhang", "Jun", ""], ["Zhan", "Zhi-Hui", ""]], "extracted_entities": [{"text": "MMOPs", "label": "LLMs"}, {"text": "MMOPs", "label": "LLMs"}], "human_readable_topic": "Meta-Learning and Optimization Algorithms"}
{"id": "2408.02454", "submitter": "Daeun Song", "authors": "Daeun Song, Jing Liang, Xuesu Xiao, Dinesh Manocha", "title": "VL-TGS: Trajectory Generation and Selection using Vision Language Models\n  in Mapless Outdoor Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-modal trajectory generation and selection algorithm for\nreal-world mapless outdoor navigation in human-centered environments. Such\nenvironments contain rich features like crosswalks, grass, and curbs, which are\neasily interpretable by humans, but not by mobile robots. We aim to compute\nsuitable trajectories that (1) satisfy the environment-specific traversability\nconstraints and (2) generate human-like paths while navigating on crosswalks,\nsidewalks, etc. Our formulation uses a Conditional Variational Autoencoder\n(CVAE) generative model enhanced with traversability constraints to generate\nmultiple candidate trajectories for global navigation. We develop a visual\nprompting approach and leverage the Visual Language Model's (VLM) zero-shot\nability of semantic understanding and logical reasoning to choose the best\ntrajectory given the contextual information about the task. We evaluate our\nmethod in various outdoor scenes with wheeled robots and compare the\nperformance with other global navigation algorithms. In practice, we observe an\naverage improvement of 20.81% in satisfying traversability constraints and\n28.51% in terms of human-like navigation in four different outdoor navigation\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2024 13:25:27 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2024 13:39:27 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2024 09:26:27 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2025 17:32:32 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Song", "Daeun", ""], ["Liang", "Jing", ""], ["Xiao", "Xuesu", ""], ["Manocha", "Dinesh", ""]], "extracted_entities": [{"text": "visual\nprompting approach", "label": "Prompting"}, {"text": "Visual Language Model", "label": "Neural Language Model"}], "human_readable_topic": "Generative AI for Urban Mobility and Transportation"}
{"id": "2408.02487", "submitter": "Weiwei Xu", "authors": "Weiwei Xu, Kai Gao, Hao He, Minghui Zhou", "title": "LiCoEval: Evaluating LLMs on License Compliance in Code Generation", "comments": "The 47th International Conference on Software Engineering(ICSE 2025)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2024 14:09:30 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2024 10:03:37 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 08:58:05 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Xu", "Weiwei", ""], ["Gao", "Kai", ""], ["He", "Hao", ""], ["Zhou", "Minghui", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "existing open-source\nimplementations", "label": "Open-source LLMs"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLM", "label": "LLM"}], "human_readable_topic": "Large Language Models and Copyright Infringement"}
{"id": "2408.02922", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang, Qiqi Bao, Qinpeng Cui, Wenming Yang, Qingmin Liao", "title": "Pose Magic: Efficient and Temporally Consistent Human Pose Estimation\n  with a Hybrid Mamba-GCN Network", "comments": "This work has been accepted by AAAI 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art (SOTA) methods in 3D Human Pose Estimation (HPE) are\nprimarily based on Transformers. However, existing Transformer-based 3D HPE\nbackbones often encounter a trade-off between accuracy and computational\nefficiency. To resolve the above dilemma, in this work, we leverage recent\nadvances in state space models and utilize Mamba for high-quality and efficient\nlong-range modeling. Nonetheless, Mamba still faces challenges in precisely\nexploiting local dependencies between joints. To address these issues, we\npropose a new attention-free hybrid spatiotemporal architecture named Hybrid\nMamba-GCN (Pose Magic). This architecture introduces local enhancement with GCN\nby capturing relationships between neighboring joints, thus producing new\nrepresentations to complement Mamba's outputs. By adaptively fusing\nrepresentations from Mamba and GCN, Pose Magic demonstrates superior capability\nin learning the underlying 3D structure. To meet the requirements of real-time\ninference, we also provide a fully causal version. Extensive experiments show\nthat Pose Magic achieves new SOTA results ($\\downarrow 0.9 mm$) while saving\n$74.1\\%$ FLOPs. In addition, Pose Magic exhibits optimal motion consistency and\nthe ability to generalize to unseen sequence lengths.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2024 03:15:18 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2024 06:44:24 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 03:17:49 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhang", "Xinyi", ""], ["Bao", "Qiqi", ""], ["Cui", "Qinpeng", ""], ["Yang", "Wenming", ""], ["Liao", "Qingmin", ""]], "extracted_entities": [{"text": "Transformers", "label": "Transformers"}, {"text": "GCN", "label": "Transformers"}, {"text": "GCN", "label": "Transformers"}, {"text": "Pose Magic", "label": "Transformer-based model"}, {"text": "Pose Magic", "label": "Transformer-based model"}, {"text": "Pose Magic", "label": "Transformer-based model"}], "human_readable_topic": "3D Human Pose Estimation"}
{"id": "2408.03463", "submitter": "Vincent Jeanselme", "authors": "Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica\n  Barrett", "title": "Identifying treatment response subgroups in observational time-to-event\n  data", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying patient subgroups with different treatment responses is an\nimportant task to inform medical recommendations, guidelines, and the design of\nfuture clinical trials. Existing approaches for treatment effect estimation\nprimarily rely on Randomised Controlled Trials (RCTs), which are often limited\nby insufficient power, multiple comparisons, and unbalanced covariates. In\naddition, RCTs tend to feature more homogeneous patient groups, making them\nless relevant for uncovering subgroups in the population encountered in\nreal-world clinical practice. Subgroup analyses established for RCTs suffer\nfrom significant statistical biases when applied to observational studies,\nwhich benefit from larger and more representative populations. Our work\nintroduces a novel, outcome-guided, subgroup analysis strategy for identifying\nsubgroups of treatment response in both RCTs and observational studies alike.\nIt hence positions itself in-between individualised and average treatment\neffect estimation to uncover patient subgroups with distinct treatment\nresponses, critical for actionable insights that may influence treatment\nguidelines. In experiments, our approach significantly outperforms the current\nstate-of-the-art method for subgroup analysis in both randomised and\nobservational treatment regimes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2024 22:38:14 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2024 14:34:07 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2024 07:32:18 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2025 00:33:14 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Jeanselme", "Vincent", ""], ["Yoon", "Chang Ho", ""], ["Falck", "Fabian", ""], ["Tom", "Brian", ""], ["Barrett", "Jessica", ""]], "extracted_entities": [{"text": "insufficient power", "label": "LLM-powered"}, {"text": "multiple comparisons", "label": "Model Bias and Fairness"}, {"text": "unbalanced covariates", "label": "Model Bias and Fairness"}], "human_readable_topic": "Uncategorized"}
{"id": "2408.03773", "submitter": "Kostya Trachenko", "authors": "K. Trachenko", "title": "Fundamental physical constants, operation of physical phenomena and\n  entropy increase", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech hep-th nucl-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaching the problem of understanding fundamental physical constants\n(FPCs) started with discussing the role these constants play in high-energy\nnuclear physics and astrophysics. Condensed matter physics was relatively\nunexplored in this regard. More recently, it was realised that FPCs set lower\nor upper bounds on key condensed matter properties. Here, we discuss a much\nwider role played by FPCs in condensed matter physics: at given environmental\nconditions, FPCs set the observability and operation of entire physical effects\nand phenomena. We discuss structural and superconducting phase transitions and\ntransitions between different states of matter, with implications for life\nprocesses. We also discuss metastable states, transitions between them,\nchemical reactions and their products. A byproduct of this discussion is that\nthe order of magnitude of the transition temperature can be calculated from\nFPCs only. We show that the new states emerging as a result of various\ntransitions increase the phase space and entropy. Were FPCs to take different\nvalues, these transitions would become inoperative at our environmental\nconditions and the new states due to these transitions would not emerge. This\nsuggests that the current values of FPCs, by enabling various transitions and\nreactions which give rise to new states, promote entropy increase. Based on\nthis entropy increase and the associated increase of statistical probability,\nwe conjecture that entropy increase is a selection principle for FPCs\nconsidered to be variable in earlier discussions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2024 13:50:00 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2024 13:49:29 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2024 12:39:44 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2024 16:17:58 GMT"}, {"version": "v5", "created": "Mon, 25 Nov 2024 15:24:47 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2025 17:36:09 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Trachenko", "K.", ""]], "extracted_entities": [{"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}, {"text": "FPCs", "label": "LLMs"}], "human_readable_topic": "Uncategorized"}
{"id": "2408.03885", "submitter": "Xiaoqi Wang", "authors": "Xiaoqi Wang, Yun Zhang", "title": "No-Reference Image Quality Assessment with Global-Local Progressive\n  Integration and Semantic-Aligned Quality Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate measurement of image quality without reference signals remains a\nfundamental challenge in low-level visual perception applications. In this\npaper, we propose a global-local progressive integration model that addresses\nthis challenge through three key contributions: 1) We develop a\ndual-measurement framework that combines vision Transformer (ViT)-based global\nfeature extractor and convolutional neural networks (CNNs)-based local feature\nextractor to comprehensively capture and quantify image distortion\ncharacteristics at different granularities. 2) We propose a progressive feature\nintegration scheme that utilizes multi-scale kernel configurations to align\nglobal and local features, and progressively aggregates them via an interactive\nstack of channel-wise self-attention and spatial interaction modules for\nmulti-grained quality-aware representations. 3) We introduce a semantic-aligned\nquality transfer method that extends the training data by automatically\nlabeling the quality scores of diverse image content with subjective opinion\nscores. Experimental results demonstrate that our model yields 5.04% and 5.40%\nimprovements in Spearman's rank-order correlation coefficient (SROCC) for\ncross-authentic and cross-synthetic dataset generalization tests, respectively.\nFurthermore, the proposed semantic-aligned quality transfer further yields\n2.26% and 13.23% performance gains in evaluations on single-synthetic and\ncross-synthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2024 16:34:32 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 09:19:26 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wang", "Xiaoqi", ""], ["Zhang", "Yun", ""]], "extracted_entities": [{"text": "channel-wise self-attention", "label": "Attention mechanism"}], "human_readable_topic": "Video Understanding with Large Multimodal Models"}
{"id": "2408.04665", "submitter": "Lei Shi", "authors": "Lei Shi, Zhimeng Liu, Yi Yang, Weize Wu, Yuyang Zhang, Hongbo Zhang,\n  Jing Lin, Siyu Wu, Zihan Chen, Ruiming Li, Nan Wang, Zipeng Liu, Huobin Tan,\n  Hongyi Gao, Yue Zhang, Ge Wang", "title": "LLM-based MOFs Synthesis Condition Extraction using Few-Shot\n  Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of Metal-Organic Frameworks (MOFs) synthesis route from\nliterature has been crucial for the logical MOFs design with desirable\nfunctionality. The recent advent of large language models (LLMs) provides\ndisruptively new solution to this long-standing problem. While the latest\nresearches mostly stick to primitive zero-shot LLMs lacking specialized\nmaterial knowledge, we introduce in this work the few-shot LLM in-context\nlearning paradigm. First, a human-AI interactive data curation approach is\nproposed to secure high-quality demonstrations. Second, an information\nretrieval algorithm is applied to pick and quantify few-shot demonstrations for\neach extraction. Over three datasets randomly sampled from nearly 90,000\nwell-defined MOFs, we conduct triple evaluations to validate our method. The\nsynthesis extraction, structure inference, and material design performance of\nthe proposed few-shot LLMs all significantly outplay zero-shot LLM and baseline\nmethods. The lab-synthesized material guided by LLM surpasses 91.1%\nhigh-quality MOFs of the same class reported in the literature, on the key\nphysical property of specific surface area.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2024 14:53:25 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 15:20:58 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Shi", "Lei", ""], ["Liu", "Zhimeng", ""], ["Yang", "Yi", ""], ["Wu", "Weize", ""], ["Zhang", "Yuyang", ""], ["Zhang", "Hongbo", ""], ["Lin", "Jing", ""], ["Wu", "Siyu", ""], ["Chen", "Zihan", ""], ["Li", "Ruiming", ""], ["Wang", "Nan", ""], ["Liu", "Zipeng", ""], ["Tan", "Huobin", ""], ["Gao", "Hongyi", ""], ["Zhang", "Yue", ""], ["Wang", "Ge", ""]], "extracted_entities": [{"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Tool Learning with Large Language Models"}
{"id": "2408.04963", "submitter": "Hong Liu", "authors": "Hong Liu, Liren Shan, Han Bao, Ronghui You, Yuhao Yi, Jiancheng Lv", "title": "LiD-FL: Towards List-Decodable Federated Learning", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is often used in environments with many unverified\nparticipants. Therefore, federated learning under adversarial attacks receives\nsignificant attention. This paper proposes an algorithmic framework for\nlist-decodable federated learning, where a central server maintains a list of\nmodels, with at least one guaranteed to perform well. The framework has no\nstrict restriction on the fraction of honest workers, extending the\napplicability of Byzantine federated learning to the scenario with more than\nhalf adversaries. Under proper assumptions on the loss function, we prove a\nconvergence theorem for our method. Experimental results, including image\nclassification tasks with both convex and non-convex losses, demonstrate that\nthe proposed algorithm can withstand the malicious majority under various\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2024 09:29:02 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2024 08:26:56 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 02:47:31 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Liu", "Hong", ""], ["Shan", "Liren", ""], ["Bao", "Han", ""], ["You", "Ronghui", ""], ["Yi", "Yuhao", ""], ["Lv", "Jiancheng", ""]], "extracted_entities": [{"text": "Federated learning", "label": "Few-shot Learning"}, {"text": "federated learning", "label": "Few-shot Learning"}, {"text": "federated learning", "label": "Few-shot Learning"}, {"text": "federated learning", "label": "Few-shot Learning"}], "human_readable_topic": "Federated Learning for Private Data"}
{"id": "2408.06722", "submitter": "Rashi Jain", "authors": "Rashi Jain and Satyabrata Adhikari", "title": "Quantum cloning transformation unlocks the potential of W class of\n  states in a quantum secure direct communication protocol", "comments": "25 pages, 3 figures", "journal-ref": "Phys. Scr. 100, 035113(2025)", "doi": "10.1088/1402-4896/adb35c", "report-no": null, "categories": "quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a controlled quantum secure direct communication (Controlled QSDC)\nprotocol between three parties, the sender sends the encoded secured message to\none of the two receivers, which can be decoded only when the other receiver\nagrees to cooperate. A lot of studies have been done on it using the\nthree-qubit GHZ state, and only a few works have involved the W state. In this\nwork, we introduce a controlled QSDC protocol exploiting a three-qubit W class\nof state shared between three parties, Alice (Sender), Bob (Controller), and\nCharlie (Receiver). In the proposed protocol, the shared state parameters and\nthe secret are linked in such a way that it is very difficult to factor them.\nWe will show that these parameters can be factored out easily if the receiver\nuses a quantum cloning machine (QCM) and thus can retrieve the secret. We find\nthat the protocol is probabilistic and have calculated the probability of\nsuccess of the protocol. Further, we establish the relation between the success\nprobability and the efficiency of the QCM. In general, we find that the\nefficiency of the constructed QCM is greater than or equal to $\\frac{1}{3}$,\nbut we have shown that its efficiency can be enhanced when the parameters of\nthe shared state are used as the parameters of the QCM. Moreover, we derived\nthe linkage between the probability of success and the amount of entanglement\nin the shared W class of state. We analyzed the obtained result and found that\neven a less entangled W class of state can also play a vital role in the\nproposed controlled QSDC scheme.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2024 08:27:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 09:37:25 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Jain", "Rashi", ""], ["Adhikari", "Satyabrata", ""]], "extracted_entities": [{"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2408.07397", "submitter": "Zhuohui Zhang", "authors": "Zhuohui Zhang, Bin He, Bin Cheng, Gang Li", "title": "Bridging Training and Execution via Dynamic Directed Graph-Based\n  Communication in Cooperative Multi-Agent Systems", "comments": "9 pages, 7 figures", "journal-ref": "The 39th AAAI Conference on Artificial Intelligence (AAAI 2025)", "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems must learn to communicate and understand interactions\nbetween agents to achieve cooperative goals in partially observed tasks.\nHowever, existing approaches lack a dynamic directed communication mechanism\nand rely on global states, thus diminishing the role of communication in\ncentralized training. Thus, we propose the Transformer-based graph coarsening\nnetwork (TGCNet), a novel multi-agent reinforcement learning (MARL) algorithm.\nTGCNet learns the topological structure of a dynamic directed graph to\nrepresent the communication policy and integrates graph coarsening networks to\napproximate the representation of global state during training. It also\nutilizes the Transformer decoder for feature extraction during execution.\nExperiments on multiple cooperative MARL benchmarks demonstrate\nstate-of-the-art performance compared to popular MARL algorithms. Further\nablation studies validate the effectiveness of our dynamic directed graph\ncommunication mechanism and graph coarsening networks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2024 09:16:42 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2024 06:50:02 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 23:15:57 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Zhang", "Zhuohui", ""], ["He", "Bin", ""], ["Cheng", "Bin", ""], ["Li", "Gang", ""]], "extracted_entities": [{"text": "TGCNet", "label": "Transformer-based model"}, {"text": "TGCNet", "label": "Transformer-based model"}], "human_readable_topic": "Graph Transformers and Neural Networks"}
{"id": "2408.07413", "submitter": "Chenhui Hu", "authors": "Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao", "title": "Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge\n  Editing for Large Language Models", "comments": "To be published in AAAI 2025 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge editing aims to update outdated or incorrect knowledge in large\nlanguage models (LLMs). However, current knowledge editing methods have limited\nscalability for lifelong editing. This study explores the fundamental reason\nwhy knowledge editing fails in lifelong editing. We begin with the closed-form\nsolution derived from linear associative memory, which underpins\nstate-of-the-art knowledge editing methods. We extend the solution from single\nediting to lifelong editing, and through rigorous mathematical derivation,\nidentify an interference term in the final solution, suggesting that editing\nknowledge may impact irrelevant knowledge. Further analysis of the interference\nterm reveals a close relationship with superposition between knowledge\nrepresentations. When knowledge superposition does not exist in language\nmodels, the interference term vanishes, allowing for lossless knowledge\nediting. Experiments across numerous language models reveal that knowledge\nsuperposition is universal, exhibiting high kurtosis, zero mean, and\nheavy-tailed distributions with clear scaling laws. Ultimately, by combining\ntheory and experiments, we demonstrate that knowledge superposition is the\nfundamental reason for the failure of lifelong editing. Moreover, this is the\nfirst study to investigate knowledge editing from the perspective of\nsuperposition and provides a comprehensive observation of superposition across\nnumerous real-world language models. Code available at\nhttps://github.com/ChenhuiHu/knowledge_in_superposition.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2024 09:43:32 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2025 06:07:15 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 09:13:06 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Hu", "Chenhui", ""], ["Cao", "Pengfei", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]], "extracted_entities": [{"text": "large\nlanguage models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "clear scaling laws", "label": "Scaling law"}], "human_readable_topic": "Knowledge Editing in Large Language Models"}
{"id": "2408.09327", "submitter": "Jiancheng Dong", "authors": "Jiancheng Dong, Lei Jiang, Wei Jin, Lu Cheng", "title": "Threshold Filtering Packing for Supervised Fine-Tuning: Training Related\n  Samples within Packs", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packing for Supervised Fine-Tuning (SFT) in autoregressive models involves\nconcatenating data points of varying lengths until reaching the designed\nmaximum length to facilitate GPU processing. However, randomly concatenating\ndata points can lead to cross-contamination of sequences due to the significant\ndifference in their subject matter. The mainstream approaches in SFT ensure\nthat each token in the attention calculation phase only focuses on tokens\nwithin its own short sequence, without providing additional learning signals\nfor the preceding context. To address these challenges, we introduce Threshold\nFiltering Packing (TFP), a method that selects samples with related context\nwhile maintaining sufficient diversity within the same pack. Our experiments\nshow that TFP offers a simple-to-implement and scalable approach that\nsignificantly enhances SFT performance, with observed improvements of up to 7\\%\non GSM8K, 4\\% on HumanEval. Furthermore, results from bias benchmark datasets\nhighlight TFP's promising performance in improving fairness while also boosting\nprediction accuracy by 15\\%.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2024 01:59:41 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 05:16:14 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Dong", "Jiancheng", ""], ["Jiang", "Lei", ""], ["Jin", "Wei", ""], ["Cheng", "Lu", ""]], "extracted_entities": [{"text": "fairness", "label": "Model Bias and Fairness"}], "human_readable_topic": "Optimizing GPU Utilization for Large Language Models"}
{"id": "2408.09517", "submitter": "Jacqueline Monkiewicz", "authors": "Timothy Carleton and Jacqueline Monkiewicz", "title": "Extreme Metallicity Dwarf Galaxies in IllustrisTNG", "comments": "18 pages, 28 figures. Accepted by MNRAS", "journal-ref": "Monthly Notices of the Royal Astronomical Society, Volume 537,\n  Issue 3, March 2025, Pages 2819-2834", "doi": "10.1093/mnras/staf158", "report-no": null, "categories": "astro-ph.GA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The use of extremely metal-deficient dwarf galaxies (XMDs) as nearby analogs\nfor high-redshift protogalaxies is generating renewed interest due to recent\nJWST observations studying these protogalaxies. However, the existence of a\npopulation of unenriched galaxies at $z\\sim0$ raises fundamental questions\nabout how galaxies with such pristine gas reservoirs could be formed. To\naddress these questions we study XMDs in the IllustrisTNG simulation. We find\nthat XMDs at $z=0$ are not relics of the first galaxies, but dwarf galaxies\nthat experience a dramatic $\\sim0.3$ dex drop in their gas-phase metallicity in\nthe past few Gyr. We investigate possible causes of this drop in metallicity\nincluding high gas fractions, outflow efficiency or inflow/outflow rates,\nunique environments, pristine inflow metallicity, and inflow/SFR interactions.\nOf these, we find that inflow/outflow interactions, parameterized by the\ncumulative regional SFR experienced by inflows, has the strongest correlation\nwith dwarf galaxy metallicity and XMD formation. In other words, inefficient\ngas enrichment during the short time between its accretion from the CGM and the\ninitiation of star formation is the most important cause of XMD formation in\nthe simulation. Observationally, we identify differences in star formation\nhistory between XMDs and non-XMDs (with XMDs having significantly decreased\nstar formation rates on $1-5$ Gyr timescales) and differences in galaxy size\n(with XMDs having a more extended young stellar population) as the primary\ndifferences between the two populations. These results highlight the importance\nof inflow enrichment efficiency as a possible driver of dwarf galaxy\nmetallicities.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2024 15:49:06 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 19:34:43 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Carleton", "Timothy", ""], ["Monkiewicz", "Jacqueline", ""]], "extracted_entities": [{"text": "XMDs", "label": "LLMs"}, {"text": "XMDs", "label": "LLMs"}, {"text": "XMDs", "label": "LLMs"}, {"text": "XMDs", "label": "LLMs"}, {"text": "XMDs", "label": "LLMs"}, {"text": "XMDs", "label": "LLMs"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2408.09886", "submitter": "Haixia Bi", "authors": "Sihan Yang, Xuande Mi, Jiadong Feng, Haixia Bi, Hai Zhang and Jian Sun", "title": "Improved Baselines with Synchronized Encoding for Universal Medical\n  Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large foundation models, known for their strong zero-shot generalization\ncapabilities, can be applied to a wide range of downstream tasks. However,\ndeveloping foundation models for medical image segmentation poses a significant\nchallenge due to the domain gap between natural and medical images. While\nfine-tuning techniques based on the Segment Anything Model (SAM) have been\nexplored, they primarily focus on scaling up data or refining inference\nstrategies without incorporating domain-specific architectural designs,\nlimiting their zero-shot performance. To optimize segmentation performance\nunder standard inference settings and provide a strong baseline for future\nresearch, we introduce SyncSAM, which employs a synchronized dual-branch\nencoder that integrates convolution and Transformer features in a synchronized\nmanner to enhance medical image encoding, and a multi-scale dual-branch decoder\nto preserve image details. SyncSAM is trained on two of the largest medical\nimage segmentation datasets, SA-Med2D-20M and IMed-361M, resulting in a series\nof pre-trained models for universal medical image segmentation. Experimental\nresults demonstrate that SyncSAM not only achieves state-of-the-art performance\non test sets but also exhibits strong zero-shot capabilities on unseen\ndatasets. The code and model weights are available at\nhttps://github.com/Hhankyangg/SyncSAM.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2024 11:01:00 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 15:24:27 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Yang", "Sihan", ""], ["Mi", "Xuande", ""], ["Feng", "Jiadong", ""], ["Bi", "Haixia", ""], ["Zhang", "Hai", ""], ["Sun", "Jian", ""]], "extracted_entities": [{"text": "fine-tuning techniques", "label": "Fine-tuning"}], "human_readable_topic": "Medical Image Segmentation with Transformers and CNNs"}
{"id": "2408.10006", "submitter": "Yaxuan Kong", "authors": "Yaxuan Kong, Zepu Wang, Yuqi Nie, Tian Zhou, Stefan Zohren, Yuxuan\n  Liang, Peng Sun, Qingsong Wen", "title": "Unlocking the Power of LSTM for Long Term Time Series Forecasting", "comments": "Accepted by 39th Annual AAAI Conference on Artificial Intelligence\n  (AAAI 2025)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional recurrent neural network architectures, such as long short-term\nmemory neural networks (LSTM), have historically held a prominent role in time\nseries forecasting (TSF) tasks. While the recently introduced sLSTM for Natural\nLanguage Processing (NLP) introduces exponential gating and memory mixing that\nare beneficial for long term sequential learning, its potential short memory\nissue is a barrier to applying sLSTM directly in TSF. To address this, we\npropose a simple yet efficient algorithm named P-sLSTM, which is built upon\nsLSTM by incorporating patching and channel independence. These modifications\nsubstantially enhance sLSTM's performance in TSF, achieving state-of-the-art\nresults. Furthermore, we provide theoretical justifications for our design, and\nconduct extensive comparative and analytical experiments to fully validate the\nefficiency and superior performance of our model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2024 13:59:26 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 18:01:55 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Kong", "Yaxuan", ""], ["Wang", "Zepu", ""], ["Nie", "Yuqi", ""], ["Zhou", "Tian", ""], ["Zohren", "Stefan", ""], ["Liang", "Yuxuan", ""], ["Sun", "Peng", ""], ["Wen", "Qingsong", ""]], "extracted_entities": [{"text": "long term sequential learning", "label": "Few-shot Learning"}], "human_readable_topic": "Recurrent Neural Networks for Sequence Modeling"}
{"id": "2408.10272", "submitter": "Reza Hamzeh Hofi", "authors": "Reza Hamzehofi", "title": "Entanglement Measures for Many-Body Quantum Systems: Limitations and New\n  Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, the entanglement within two entangled n-qubit systems is\nanalyzed using the one-tangle, two-tangle, and {\\pi}-tangle. The findings\nindicate that for certain quantum states, such as the generalized W state,\nwhere the probability coefficients depend on the number of qubits, increasing\nthe number of particles causes these measures to approach zero, with the\nmonogamy of entanglement converging to equality. This implies that for quantum\nstates whose probability coefficients are dependent on the number of qubits,\nthe one-tangle and {\\pi}-tangle become ineffective in capturing entanglement as\nthe system size increases. To address this, we introduced three alternative\nmeasures: the sum of two-tangles, the sum of squared one-tangles, and the\ngeneralized residual entanglement. Unlike the one-tangle and {\\pi}-tangle,\nthese measures do not diminish to zero as the number of particles increases.\nFurthermore, we proposed a strong monogamy of entanglement that does not\nconverge to equality as the number of particles grows.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2024 06:33:16 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2025 12:21:11 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Hamzehofi", "Reza", ""]], "extracted_entities": [{"text": "entanglement", "label": "quantisation"}, {"text": "one-tangle", "label": "quantisation"}, {"text": "{\\pi}-tangle", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}, {"text": "one-tangle", "label": "quantisation"}, {"text": "{\\pi}-tangle", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}, {"text": "one-tangle", "label": "quantisation"}, {"text": "{\\pi}-tangle", "label": "quantisation"}, {"text": "entanglement", "label": "quantisation"}], "human_readable_topic": "Quantum Entanglement and Generalised Probabilistic Theories"}
{"id": "2408.10560", "submitter": "Jiaze Gao", "authors": "Jiaze Gao, Yun Chen and Lixin Xu", "title": "Optimizing the $L$-$\\sigma$ Relation of HII Galaxies for improving\n  cosmological application", "comments": "8 pages, 1 table, 2 figures. The models and figures are updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The basic premise of using HII starburst galaxies (HIIGs) as cosmic\n``standard candles'' is the significant correlation between the H$\\beta$\nluminosity ($L$) and the velocity dispersion ($\\sigma$) of the ionized gas from\nHIIGs measurements, which can be called as the empirical $L$ - $\\sigma$\nrelation. However, the classic scaling $L$ - $\\sigma$ relation well-calibrated\nwith the low-redshift HIIGs is unfitted for the high-redshift ones. To solve\nthis problem, we try to explore new relational expression for the $L$ -\n$\\sigma$ relation, which is expected to be suitable for both the low and high\nredshift HIIGs. After reconstructing the Hubble diagram with the Gaussian\nprocess method from the Pantheon+ supernovae Ia sample, we compare three\ndifferent revised forms of the $L$ - $\\sigma$ relation with the classic scaling\none. By using the Bayesian evidence to do the comparison, we find that the\nlogarithmic redshift-dependent correction is the most competitive option for\nthe $L$ - $\\sigma$ relation. Then, we conduct the cosmological analysis with a\njoint sample of HIIGs and local giant extragalactic HII regions (GEHRs) in the\ncase of choosing the logarithmic redshift-dependent form for the $L$ - $\\sigma$\nrelation, and find that the power of HIIGs $+$ GEHRs on constraining the Hubble\nconstant is almost compatible with that of the observational Hubble parameter\ndata. It suggests that the appropriate optimization to the classic $L$ -\n$\\sigma$ relation should be taken into account when the HIIGs are used as a\nkind of promising cosmological probes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2024 05:59:57 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 02:48:55 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Gao", "Jiaze", ""], ["Chen", "Yun", ""], ["Xu", "Lixin", ""]], "extracted_entities": [{"text": "HIIGs", "label": "LLMs"}, {"text": "HIIGs", "label": "LLMs"}, {"text": "HIIGs", "label": "LLMs"}, {"text": "$L$ - $\\sigma$ relation", "label": "Scaling law"}, {"text": "HIIGs", "label": "LLMs"}, {"text": "HIIGs", "label": "LLMs"}, {"text": "HIIGs", "label": "LLMs"}], "human_readable_topic": "Galaxy Classification in Astronomy"}
{"id": "2408.10573", "submitter": "Junhao Chen", "authors": "Junhao Chen and Bowen Wang and Zhouqiang Jiang and Yuta Nakashima", "title": "Putting People in LLMs' Shoes: Generating Better Answers via Question\n  Rewriter", "comments": "7 pages, 4 figures, 5 tables and accepted at AAAI 2025 Main\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large Language Models (LLMs) have demonstrated significant capabilities,\nparticularly in the domain of question answering (QA). However, their\neffectiveness in QA is often undermined by the vagueness of user questions. To\naddress this issue, we introduce single-round instance-level prompt\noptimization, referred to as question rewriter. By enhancing the\nintelligibility of human questions for black-box LLMs, our question rewriter\nimproves the quality of generated answers. The rewriter is optimized using\ndirect preference optimization based on feedback collected from automatic\ncriteria for evaluating generated answers; therefore, its training does not\nrequire costly human annotations. The experiments across multiple black-box\nLLMs and long-form question answering (LFQA) datasets demonstrate the efficacy\nof our method. This paper provides a practical framework for training question\nrewriters and sets a precedent for future explorations in prompt optimization\nwithin LFQA tasks. Code is available at\nhttps://github.com/3244we/Question-Rewriter.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2024 06:24:47 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 03:13:27 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Chen", "Junhao", ""], ["Wang", "Bowen", ""], ["Jiang", "Zhouqiang", ""], ["Nakashima", "Yuta", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "single-round instance-level prompt\noptimization", "label": "Fine-tuning"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "direct preference optimization", "label": "Fine-tuning"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "prompt optimization", "label": "Prompting"}], "human_readable_topic": "Evaluating Language Models for Question Answering Tasks"}
{"id": "2408.10593", "submitter": "Eui Jun Hwang", "authors": "Eui Jun Hwang, Sukmin Cho, Junmyeong Lee, Jong C. Park", "title": "An Efficient Sign Language Translation Using Spatial Configuration and\n  Motion Dynamics with LLMs", "comments": "Accepted to NAACL 2025 main", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gloss-free Sign Language Translation (SLT) converts sign videos directly into\nspoken language sentences without relying on glosses. Recently, Large Language\nModels (LLMs) have shown remarkable translation performance in gloss-free\nmethods by harnessing their powerful natural language generation capabilities.\nHowever, these methods often rely on domain-specific fine-tuning of visual\nencoders to achieve optimal results. By contrast, this paper emphasizes the\nimportance of capturing the spatial configurations and motion dynamics inherent\nin sign language. With this in mind, we introduce Spatial and Motion-based Sign\nLanguage Translation (SpaMo), a novel LLM-based SLT framework. The core idea of\nSpaMo is simple yet effective. We first extract spatial and motion features\nusing off-the-shelf visual encoders and then input these features into an LLM\nwith a language prompt. Additionally, we employ a visual-text alignment process\nas a warm-up before the SLT supervision. Our experiments demonstrate that SpaMo\nachieves state-of-the-art performance on two popular datasets, PHOENIX14T and\nHow2Sign.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2024 07:10:40 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2024 06:18:53 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 06:04:45 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Hwang", "Eui Jun", ""], ["Cho", "Sukmin", ""], ["Lee", "Junmyeong", ""], ["Park", "Jong C.", ""]], "extracted_entities": [{"text": "Large Language\nModels", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "domain-specific fine-tuning", "label": "Fine-tuning"}, {"text": "language prompt", "label": "Prompting"}], "human_readable_topic": "Sign Language Understanding and Retrieval"}
{"id": "2408.11093", "submitter": "James Gillanders", "authors": "J. H. Gillanders and S. J. Smartt", "title": "Analysis of the JWST spectra of the kilonova AT 2023vfi accompanying GRB\n  230307A", "comments": "Updated to match version accepted for publication in MNRAS. Main\n  text: 22 pages, 14 figures, 3 tables. Appendices: 7 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kilonovae are key to advancing our understanding of r-process\nnucleosynthesis. To date, only two kilonovae have been spectroscopically\nobserved, AT 2017gfo and AT 2023vfi. Here, we present an analysis of the James\nWebb Space Telescope (JWST) spectra obtained +29 and +61 days post-merger for\nAT 2023vfi (the kilonova associated with GRB 230307A). After re-reducing and\nphotometrically flux-calibrating the data, we empirically model the observed\nX-ray to mid-infrared continua with a power law and a blackbody, to replicate\nthe non-thermal afterglow and apparent thermal continuum $\\gtrsim 2 \\, \\mu$m.\nWe fit Gaussians to the apparent emission features, obtaining line centroids of\n$20218_{-38}^{+37}$, $21874 \\pm 89$ and $44168_{-152}^{+153}$\\,\\AA, and\nvelocity widths spanning $0.057 - 0.110$\\,c. These line centroid constraints\nfacilitated a detailed forbidden line identification search, from which we\nshortlist a number of r-process species spanning all three r-process peaks. We\nrule out Ba II and Ra II as candidates and propose Te I-III, Er I-III and W III\nas the most promising ions for further investigation, as they plausibly produce\nmultiple emission features from one (W III) or multiple (Te I-III, Er I-III)\nion stages. We compare to the spectra of AT 2017gfo, which also exhibit\nprominent emission at $\\sim 2.1 \\, \\mu$m, and conclude that [Te III]\n$\\lambda$21050 remains the most plausible cause of the observed $\\sim 2.1 \\,\n\\mu$m emission in both kilonovae. However, the observed line centroids are not\nconsistent between both objects, and they are significantly offset from [Te\nIII] $\\lambda$21050. The next strongest [Te III] transition at 29290\\,\\AA\\ is\nnot observed, and we quantify its detectability. Further study is required,\nwith particular emphasis on expanding the available atomic data to enable\nquantitative non-LTE spectral modelling.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2024 18:00:01 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 14:41:24 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Gillanders", "J. H.", ""], ["Smartt", "S. J.", ""]], "extracted_entities": [{"text": "power law", "label": "Scaling law"}], "human_readable_topic": "Astronomy and Astrophysics Research"}
{"id": "2408.11188", "submitter": "Hossein Movasati", "authors": "Hossein Movasati", "title": "Local-global principle for leaf schemes", "comments": "The article is now a section of the new long article \"Leaf scheme and\n  Hodge Loci\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG math.CV math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study Hodge loci as leaf schemes of foliations. The main ingredient is the\nGauss-Manin connection matrix of families of projective varieties. We also aim\nto investigate a conjecture on the ring of definition of leaf schemes and its\nconsequences such as the algebraicity of leaf schemes (Cattani-Deligne-Kaplan\ntheorem in the case of Hodge loci). This conjecture is a consequence of a\nlocal-global principle for leaf schemes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2024 20:45:05 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2024 20:39:02 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 20:07:34 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Movasati", "Hossein", ""]], "extracted_entities": [{"text": "Hodge loci", "label": "LLMs"}], "human_readable_topic": "Algebraic Geometry and Representation Theory"}
{"id": "2408.11843", "submitter": "Ruizhe Chen", "authors": "Ruizhe Chen, Yichen Li, Jianfei Yang, Joey Tianyi Zhou, Jian Wu,\n  Zuozhu Liu", "title": "Identifying and Mitigating Social Bias Knowledge in Language Models", "comments": "NAACL 2025 Findings. arXiv admin note: substantial text overlap with\n  arXiv:2405.09341", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating fair and accurate predictions plays a pivotal role in deploying\nlarge language models (LLMs) in the real world. However, existing debiasing\nmethods inevitably generate unfair or incorrect predictions as they are\ndesigned and evaluated to achieve parity across different social groups but\nleave aside individual commonsense facts, resulting in modified knowledge that\nelicits unreasonable or undesired predictions. In this paper, we first\nestablish a new bias mitigation benchmark, BiaScope, which systematically\nassesses performance by leveraging newly constructed datasets and metrics on\nknowledge retention and generalization. Then, we propose a novel debiasing\napproach, Fairness Stamp (FAST), which enables fine-grained calibration of\nindividual social biases. FAST identifies the decisive layer responsible for\nstoring social biases and then calibrates its outputs by integrating a small\nmodular network, considering both bias mitigation and knowledge-preserving\ndemands. Comprehensive experiments demonstrate that FAST surpasses\nstate-of-the-art baselines with superior debiasing performance while not\ncompromising the overall model capability for knowledge retention and\ndownstream predictions. This highlights the potential of fine-grained debiasing\nstrategies to achieve fairness in LLMs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2024 17:14:58 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2025 10:11:06 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Chen", "Ruizhe", ""], ["Li", "Yichen", ""], ["Yang", "Jianfei", ""], ["Zhou", "Joey Tianyi", ""], ["Wu", "Jian", ""], ["Liu", "Zuozhu", ""]], "extracted_entities": [{"text": "large language models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "fine-grained calibration", "label": "Fine-tuning"}, {"text": "LLMs", "label": "Large Language Model"}], "human_readable_topic": "Fairness in Large Language Models"}
{"id": "2408.12083", "submitter": "Wade Naylor Dr", "authors": "Anna Chrysostomou, Alan S. Cornell, and Wade Naylor", "title": "Dominant misconceptions and alluvial flows between Engineering and\n  Physical Science students", "comments": "28 pages, 8 figures, 8 tables, APA7; BibTeX issues resolved", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we assess the comprehension of physics concepts by Physical\nScience and Engineering students enrolled in their first semester at the\nUniversity of Johannesburg (UJ), South Africa ($2022$). We employ different\ngraphical measures to explore similarities and differences using the results of\nboth pre- and post-test data from the Force Concept Inventory assessment tool,\nfrom which we calculate dominant misconceptions (DMs) and gains. We also use\nalluvial diagrams to track the choices made by these two groups of students\nfrom pre- to post-test stages. In our analysis, we find that DM results\nindicate that participating Engineering students outperformed Physical Science\nstudents on average, however, the same types of normalised DMs persist at the\npost-test level. We call these DMs \"persistent misconceptions.\" This is very\nuseful when tracking persistent misconceptions, where when using repeated\nmeasures and alluvial diagrams with smaller groups of students, we find that\nPhysical Science students tend to make more chaotic choices.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2024 02:43:04 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2024 13:07:48 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 12:32:49 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Chrysostomou", "Anna", ""], ["Cornell", "Alan S.", ""], ["Naylor", "Wade", ""]], "extracted_entities": [{"text": "DMs", "label": "LLMs"}, {"text": "DMs", "label": "LLMs"}], "human_readable_topic": "AI Performance on Standardized Exams and Educational Assessments"}
{"id": "2408.12526", "submitter": "Weiyan Wang", "authors": "Weiyan Wang, Yilun Jin, Yiming Zhang, Victor Junqiu Wei, Han Tian, Li\n  Chen, Jinbao Xue, Yangyu Tao, Di Wang, Kai Chen", "title": "Exploiting Student Parallelism for Efficient GPU Inference of BERT-like\n  Models in Online Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to high accuracy, BERT-like models have been widely adopted by text\nmining and web searching. However, large BERT-like models suffer from\ninefficient online inference, facing the following two problems on GPUs: (1)\ntheir high accuracy relies on the large model depth, which linearly increases\nthe sequential computation on GPUs; (2) stochastic and dynamic online workloads\ncause extra costs from batching and paddings. Therefore, we present \\sys for\nthe real-world setting of GPU inference on online workloads. At its core, \\sys\nadopts stacking distillation and boosting ensemble, distilling the original\ndeep model into a group of shallow but virtually stacked student models running\nin parallel. This enables \\sys to achieve a lower model depth (e.g., two\nlayers) than the others and the lowest inference latency while maintaining\naccuracy. In addition, adaptive student pruning realizes dynamic student\nnumbers according to changing online workloads. Especially for occasional\nworkload bursts, it can temporarily decrease the student number with minimal\naccuracy loss to improve system throughput. We conduct comprehensive\nexperiments to verify the effectiveness, whose results show that \\sys\noutperforms the baselines by $4.1\\times\\sim 1.6\\times$ in latency while\nmaintaining accuracy and achieves up to $22.27\\times$ higher throughput for\nworkload bursts.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2024 16:31:32 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2025 12:08:13 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Wang", "Weiyan", ""], ["Jin", "Yilun", ""], ["Zhang", "Yiming", ""], ["Wei", "Victor Junqiu", ""], ["Tian", "Han", ""], ["Chen", "Li", ""], ["Xue", "Jinbao", ""], ["Tao", "Yangyu", ""], ["Wang", "Di", ""], ["Chen", "Kai", ""]], "extracted_entities": [{"text": "stacking distillation", "label": "Knowledge distillation"}], "human_readable_topic": "Optimizing GPU Utilization for Large Language Models"}
{"id": "2408.12588", "submitter": "Xuanlei Zhao", "authors": "Xuanlei Zhao and Xiaolong Jin and Kai Wang and Yang You", "title": "Real-Time Video Generation with Pyramid Attention Broadcast", "comments": "ICLR 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Pyramid Attention Broadcast (PAB), a real-time, high quality and\ntraining-free approach for DiT-based video generation. Our method is founded on\nthe observation that attention difference in the diffusion process exhibits a\nU-shaped pattern, indicating significant redundancy. We mitigate this by\nbroadcasting attention outputs to subsequent steps in a pyramid style. It\napplies different broadcast strategies to each attention based on their\nvariance for best efficiency. We further introduce broadcast sequence parallel\nfor more efficient distributed inference. PAB demonstrates up to 10.5x speedup\nacross three models compared to baselines, achieving real-time generation for\nup to 720p videos. We anticipate that our simple yet effective method will\nserve as a robust baseline and facilitate future research and application for\nvideo generation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2024 17:54:21 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2025 16:02:14 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2025 07:00:30 GMT"}], "update_date": "2025-02-28", "authors_parsed": [["Zhao", "Xuanlei", ""], ["Jin", "Xiaolong", ""], ["Wang", "Kai", ""], ["You", "Yang", ""]], "extracted_entities": [{"text": "attention difference", "label": "Attention mechanism"}], "human_readable_topic": "Diffusion-Based Video Generation"}
{"id": "2408.12594", "submitter": "Xingtong Yu", "authors": "Xingtong Yu, Jie Zhang, Yuan Fang, Renhe Jiang", "title": "Non-Homophilic Graph Pre-Training and Prompt Learning", "comments": "Accepted by KDD 2025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are ubiquitous for modeling complex relationships between objects\nacross various fields. Graph neural networks (GNNs) have become a mainstream\ntechnique for graph-based applications, but their performance heavily relies on\nabundant labeled data. To reduce labeling requirement, pre-training and prompt\nlearning has become a popular alternative. However, most existing prompt\nmethods do not differentiate homophilic and heterophilic characteristics of\nreal-world graphs. In particular, many real-world graphs are non-homophilic,\nnot strictly or uniformly homophilic with mixing homophilic and heterophilic\npatterns, exhibiting varying non-homophilic characteristics across graphs and\nnodes. In this paper, we propose ProNoG, a novel pre-training and prompt\nlearning framework for such non-homophilic graphs. First, we analyze existing\ngraph pre-training methods, providing theoretical insights into the choice of\npre-training tasks. Second, recognizing that each node exhibits unique\nnon-homophilic characteristics, we propose a conditional network to\ncharacterize the node-specific patterns in downstream tasks. Finally, we\nthoroughly evaluate and analyze ProNoG through extensive experiments on ten\npublic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2024 17:57:31 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2024 08:23:53 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2024 10:55:58 GMT"}, {"version": "v4", "created": "Sat, 7 Dec 2024 04:28:09 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2025 04:43:11 GMT"}, {"version": "v6", "created": "Wed, 26 Feb 2025 06:58:51 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Yu", "Xingtong", ""], ["Zhang", "Jie", ""], ["Fang", "Yuan", ""], ["Jiang", "Renhe", ""]], "extracted_entities": [{"text": "prompt\nlearning", "label": "Prompting"}, {"text": "prompt\nlearning", "label": "Prompting"}], "human_readable_topic": "Graph Prompting for Pre-trained Graph Models"}
{"id": "2408.13704", "submitter": "Yicheng Wang", "authors": "Yicheng Wang, Jiayi Yuan, Yu-Neng Chuang, Zhuoer Wang, Yingchi Liu,\n  Mark Cusick, Param Kulkarni, Zhengping Ji, Yasser Ibrahim, Xia Hu", "title": "DHP Benchmark: Are LLMs Good NLG Evaluators?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Language Models (LLMs) are increasingly serving as evaluators in\nNatural Language Generation (NLG) tasks; this is often referred to as\n``LLM-as-a-judge'' paradigm. However, the capabilities of LLMs in evaluating\nNLG quality remain underexplored. Current studies depend on human assessments\nand simple metrics that fail to capture the discernment of LLMs across diverse\nNLG tasks. To address this gap, we propose the Discernment of Hierarchical\nPerturbation (DHP) benchmarking framework, which provides quantitative\ndiscernment scores for LLMs. This framework leverages hierarchically perturbed\ntext data and statistical tests to systematically measure the NLG evaluation\ncapabilities of LLMs. We re-established six evaluation datasets for this\nbenchmark, covering four NLG tasks: Summarization, Story Completion, Question\nAnswering, and Translation. Our comprehensive benchmarking of five major LLM\nfamilies provides critical insight into their strengths and limitations as NLG\nevaluators. Our dataset is available at\nhttps://huggingface.co/datasets/YCWANGVINCE/DHP_Benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2024 02:01:38 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2025 01:51:06 GMT"}], "update_date": "2025-02-26", "authors_parsed": [["Wang", "Yicheng", ""], ["Yuan", "Jiayi", ""], ["Chuang", "Yu-Neng", ""], ["Wang", "Zhuoer", ""], ["Liu", "Yingchi", ""], ["Cusick", "Mark", ""], ["Kulkarni", "Param", ""], ["Ji", "Zhengping", ""], ["Ibrahim", "Yasser", ""], ["Hu", "Xia", ""]], "extracted_entities": [{"text": "Large Language Models", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLMs", "label": "Large Language Model"}, {"text": "LLM", "label": "Large Language Model"}], "human_readable_topic": "Evaluating Large Language Models for NLG Tasks"}
{"id": "2408.13721", "submitter": "Zhong-Xia Shang", "authors": "Zhong-Xia Shang and Qi Zhao", "title": "Entanglement-induced exponential advantage in amplitude estimation via\n  state matrixization", "comments": "7+18 pages, 1+2 figures. Big update on title and presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating quantum amplitude, or the overlap between two quantum states, is a\nfundamental task in quantum computing and underpins numerous quantum\nalgorithms. In this work, we introduce a novel algorithmic framework for\nquantum amplitude estimation by transforming pure states into their matrix\nforms (Matrixization) and encoding them into non-diagonal blocks of density\noperators and diagonal blocks of unitary operators. Utilizing the construction\ndetails of state preparation circuits, we systematically reconstruct amplitude\nestimation algorithms within the novel matrixization framework through a\ntechnique known as channel block encoding. Compared with the standard approach,\namplitude estimation through matrixization can have a different complexity that\ndepends on the entanglement properties of the two quantum states. Specifically,\nour new algorithm can have exponentially smaller gate complexity when one of\nthe two quantum states is prepared by a linear-depth quantum circuit that is\nbelow maximal entanglement under a certain bi-partition and the other state is\nmaximally entangled. We later generalize this result to broader regimes and\ndiscuss implications. Our results demonstrate that the near-optimal performance\nof the standard amplitude estimation algorithm can be surpassed in specific\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2024 04:35:53 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2024 04:21:21 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2025 07:10:53 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Shang", "Zhong-Xia", ""], ["Zhao", "Qi", ""]], "extracted_entities": [{"text": "Matrixization", "label": "quantisation"}, {"text": "matrixization", "label": "quantisation"}, {"text": "channel block encoding", "label": "quantisation"}, {"text": "matrixization", "label": "quantisation"}], "human_readable_topic": "Quantum Machine Learning and Neural Networks"}
{"id": "2408.14690", "submitter": "James Liu", "authors": "James Liu, Pragaash Ponnusamy, Tianle Cai, Han Guo, Yoon Kim, Ben\n  Athiwaratkun", "title": "Training-Free Activation Sparsity in Large Language Models", "comments": "Rev. 2: ICLR 2025 Acceptance (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activation sparsity can enable practical inference speedups in large language\nmodels (LLMs) by reducing the compute and memory-movement required for matrix\nmultiplications during the forward pass. However, existing methods face\nlimitations that inhibit widespread adoption. Some approaches are tailored\ntowards older models with ReLU-based sparsity, while others require extensive\ncontinued pre-training on up to hundreds of billions of tokens. This paper\ndescribes TEAL, a simple training-free method that applies magnitude-based\nactivation sparsity to hidden states throughout the entire model. TEAL achieves\n40-50% model-wide sparsity with minimal performance degradation across Llama-2,\nLlama-3, and Mistral families, with sizes varying from 7B to 70B. We improve\nexisting sparse kernels and demonstrate wall-clock decoding speed-ups of up to\n1.53$\\times$ and 1.8$\\times$ at 40% and 50% model-wide sparsity. TEAL is\ncompatible with weight quantization, enabling further efficiency gains.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2024 23:30:15 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2024 20:02:15 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2025 21:00:50 GMT"}], "update_date": "2025-02-27", "authors_parsed": [["Liu", "James", ""], ["Ponnusamy", "Pragaash", ""], ["Cai", "Tianle", ""], ["Guo", "Han", ""], ["Kim", "Yoon", ""], ["Athiwaratkun", "Ben", ""]], "extracted_entities": [{"text": "TEAL", "label": "LLM-based"}, {"text": "Llama-3", "label": "GPT-3"}, {"text": "Mistral", "label": "Mistral"}, {"text": "weight quantization", "label": "quantisation"}], "human_readable_topic": "Sparse Activations in Large Language Models"}
{"id": "2408.15753", "submitter": "Omer Rochman-Sharabi", "authors": "Omer Rochman Sharabi and Sacha Lewin and Gilles Louppe", "title": "A Neural Material Point Method for Particle-based Emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mesh-free Lagrangian methods are widely used for simulating fluids, solids,\nand their complex interactions due to their ability to handle large\ndeformations and topological changes. These physics simulators, however,\nrequire substantial computational resources for accurate simulations. To\naddress these issues, deep learning emulators promise faster and scalable\nsimulations, yet they often remain expensive and difficult to train, limiting\ntheir practical use. Inspired by the Material Point Method (MPM), we present\nNeuralMPM, a neural emulation framework for particle-based simulations.\nNeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes\nupdates on grid nodes using image-to-image neural networks, and interpolates\nback to the particles. Similarly to MPM, NeuralMPM benefits from the regular\nvoxelized representation to simplify the computation of the state dynamics,\nwhile avoiding the drawbacks of mesh-based Eulerian methods. We demonstrate the\nadvantages of NeuralMPM on several datasets, including fluid dynamics and\nfluid-solid interactions. Compared to existing methods, NeuralMPM reduces\ntraining times from days to hours, while achieving comparable or superior\nlong-term accuracy, making it a promising approach for practical forward and\ninverse problems. A project page is available at https://neuralmpm.isach.be\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2024 12:39:51 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2024 08:44:12 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2025 12:41:06 GMT"}], "update_date": "2025-02-25", "authors_parsed": [["Sharabi", "Omer Rochman", ""], ["Lewin", "Sacha", ""], ["Louppe", "Gilles", ""]], "extracted_entities": [{"text": "NeuralMPM", "label": "Neural Language Model"}, {"text": "NeuralMPM", "label": "Neural Language Model"}, {"text": "NeuralMPM", "label": "Neural Language Model"}, {"text": "NeuralMPM", "label": "Neural Language Model"}, {"text": "NeuralMPM", "label": "Neural Language Model"}, {"text": "neuralmpm", "label": "Neural Language Model"}], "human_readable_topic": "Seismic Data Analysis with Deep Learning"}
